[0m17:58:26.078132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f961f65c5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9623271d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96232713d0>]}


============================== 17:58:26.082596 | df718c7b-aafa-4abf-b0e4-9db617448b37 ==============================
[0m17:58:26.082596 [info ] [MainThread]: Running with dbt=1.8.8
[0m17:58:26.083592 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'indirect_selection': 'eager', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'warn_error': 'None', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'use_experimental_parser': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'printer_width': '80', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'log_cache_events': 'False', 'profiles_dir': '/Users/david/.dbt', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt seed', 'partial_parse': 'True'}
[0m17:58:31.297537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'df718c7b-aafa-4abf-b0e4-9db617448b37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9627582e80>]}
[0m17:58:31.406454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'df718c7b-aafa-4abf-b0e4-9db617448b37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f961c17f310>]}
[0m17:58:31.407461 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m17:58:31.451017 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m17:58:31.453100 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:58:31.453924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'df718c7b-aafa-4abf-b0e4-9db617448b37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9627cac970>]}
[0m17:58:33.686607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'df718c7b-aafa-4abf-b0e4-9db617448b37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9628390eb0>]}
[0m17:58:33.870408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'df718c7b-aafa-4abf-b0e4-9db617448b37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9628361b80>]}
[0m17:58:33.871199 [info ] [MainThread]: Found 2 models, 2 seeds, 4 data tests, 479 macros
[0m17:58:33.871750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df718c7b-aafa-4abf-b0e4-9db617448b37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f962822d190>]}
[0m17:58:33.873660 [info ] [MainThread]: 
[0m17:58:33.874479 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m17:58:33.881678 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m17:58:33.882540 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:58:36.847070 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:58:36.847868 [debug] [MainThread]: Connection 'list_steam-outlet-209412' was properly closed.
[0m17:58:36.848460 [info ] [MainThread]: 
[0m17:58:36.849066 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 2.97 seconds (2.97s).
[0m17:58:36.850158 [error] [MainThread]: Encountered an error:
Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  Reauthentication is needed. Please run `gcloud auth application-default login` to reauthenticate.
[0m17:58:36.850953 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_wall_clock_time": 10.922649, "process_user_time": 6.880285, "process_kernel_time": 1.091449, "process_mem_max_rss": "231182336", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m17:58:36.851843 [debug] [MainThread]: Command `dbt seed` failed at 17:58:36.851687 after 10.92 seconds
[0m17:58:36.852467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f961f65c5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f962808c0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96286e73a0>]}
[0m17:58:36.853066 [debug] [MainThread]: Flushing usage events
[0m18:00:23.357323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18ea24580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd190a30c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd190a30160>]}


============================== 18:00:23.363069 | e978a034-bced-49a7-9e0f-a46b366fe15b ==============================
[0m18:00:23.363069 [info ] [MainThread]: Running with dbt=1.8.8
[0m18:00:23.364032 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'version_check': 'True', 'quiet': 'False', 'profiles_dir': '/Users/david/.dbt', 'cache_selected_only': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'printer_width': '80', 'introspect': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'invocation_command': 'dbt seed', 'fail_fast': 'False', 'empty': 'None', 'static_parser': 'True', 'use_colors': 'True', 'target_path': 'None', 'no_print': 'None', 'warn_error': 'None', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager'}
[0m18:00:28.064688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e978a034-bced-49a7-9e0f-a46b366fe15b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd19445afa0>]}
[0m18:00:28.152113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e978a034-bced-49a7-9e0f-a46b366fe15b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd194d5a250>]}
[0m18:00:28.153112 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m18:00:28.185772 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m18:00:28.546533 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:00:28.547147 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:00:28.632872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e978a034-bced-49a7-9e0f-a46b366fe15b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd195117130>]}
[0m18:00:28.818906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e978a034-bced-49a7-9e0f-a46b366fe15b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd194f9c5e0>]}
[0m18:00:28.819760 [info ] [MainThread]: Found 2 models, 2 seeds, 4 data tests, 479 macros
[0m18:00:28.820336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e978a034-bced-49a7-9e0f-a46b366fe15b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1950e9040>]}
[0m18:00:28.822371 [info ] [MainThread]: 
[0m18:00:28.823244 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m18:00:28.829975 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m18:00:28.831605 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:00:32.192319 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now create_steam-outlet-209412_os-creditrisk)
[0m18:00:32.195741 [debug] [ThreadPool]: Creating schema "database: "steam-outlet-209412"
schema: "os-creditrisk"
"
[0m18:00:32.219131 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:00:32.219884 [debug] [ThreadPool]: On create_steam-outlet-209412_os-creditrisk: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "create_steam-outlet-209412_os-creditrisk"} */
create schema if not exists `steam-outlet-209412`.`os-creditrisk`
  
[0m18:00:33.115635 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:c5302909-11df-47d6-a912-0e75643b230f&page=queryresults
[0m18:00:33.448560 [debug] [ThreadPool]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Invalid dataset ID "os-creditrisk". Dataset IDs must be alphanumeric (plus underscores) and must be at most 1024 characters long.; reason: invalid, message: Invalid dataset ID "os-creditrisk". Dataset IDs must be alphanumeric (plus underscores) and must be at most 1024 characters long.')
[0m18:00:34.002655 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:c347b154-f2f0-48c1-a7bb-a1f7dff08834&page=queryresults
[0m18:00:34.309487 [error] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:c347b154-f2f0-48c1-a7bb-a1f7dff08834&page=queryresults
[0m18:00:34.310387 [debug] [ThreadPool]: BigQuery adapter: Unhandled error while running:
macro create_schema
[0m18:00:34.310933 [debug] [ThreadPool]: BigQuery adapter: Database Error
  Invalid dataset ID "os-creditrisk". Dataset IDs must be alphanumeric (plus underscores) and must be at most 1024 characters long.
[0m18:00:34.312128 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:00:34.312636 [debug] [MainThread]: Connection 'create_steam-outlet-209412_os-creditrisk' was properly closed.
[0m18:00:34.313198 [info ] [MainThread]: 
[0m18:00:34.314986 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 5.49 seconds (5.49s).
[0m18:00:34.315913 [error] [MainThread]: Encountered an error:
Database Error
  Invalid dataset ID "os-creditrisk". Dataset IDs must be alphanumeric (plus underscores) and must be at most 1024 characters long.
[0m18:00:34.316836 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_wall_clock_time": 11.068038, "process_user_time": 5.619461, "process_kernel_time": 1.189519, "process_mem_max_rss": "223653888", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:00:34.318006 [debug] [MainThread]: Command `dbt seed` failed at 18:00:34.317707 after 11.07 seconds
[0m18:00:34.319289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18ea24580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1950e9850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd195779550>]}
[0m18:00:34.321049 [debug] [MainThread]: Flushing usage events
[0m18:02:23.858417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd74422f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd746267b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd746267250>]}


============================== 18:02:23.863863 | bdb00794-8a55-4dac-b439-3d72c6dc85bb ==============================
[0m18:02:23.863863 [info ] [MainThread]: Running with dbt=1.8.8
[0m18:02:23.864889 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'indirect_selection': 'eager', 'printer_width': '80', 'partial_parse': 'True', 'invocation_command': 'dbt seed', 'version_check': 'True', 'target_path': 'None', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'static_parser': 'True', 'write_json': 'True', 'warn_error': 'None', 'debug': 'False', 'introspect': 'True', 'empty': 'None', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/david/.dbt'}
[0m18:02:29.120289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bdb00794-8a55-4dac-b439-3d72c6dc85bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd749c193d0>]}
[0m18:02:29.192462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bdb00794-8a55-4dac-b439-3d72c6dc85bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7460ffaf0>]}
[0m18:02:29.193363 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m18:02:29.291883 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m18:02:29.669227 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:02:29.669884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'bdb00794-8a55-4dac-b439-3d72c6dc85bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7454a00d0>]}
[0m18:02:32.014912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bdb00794-8a55-4dac-b439-3d72c6dc85bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd74a602b80>]}
[0m18:02:32.193725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bdb00794-8a55-4dac-b439-3d72c6dc85bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd74ab78fa0>]}
[0m18:02:32.194524 [info ] [MainThread]: Found 2 models, 2 seeds, 4 data tests, 479 macros
[0m18:02:32.195063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bdb00794-8a55-4dac-b439-3d72c6dc85bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd74ac06940>]}
[0m18:02:32.196968 [info ] [MainThread]: 
[0m18:02:32.197777 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m18:02:32.204705 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m18:02:32.205657 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:02:35.542253 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now create_steam-outlet-209412_oscreditrisk)
[0m18:02:35.544880 [debug] [ThreadPool]: Creating schema "database: "steam-outlet-209412"
schema: "oscreditrisk"
"
[0m18:02:35.560450 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:02:35.561200 [debug] [ThreadPool]: On create_steam-outlet-209412_oscreditrisk: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "create_steam-outlet-209412_oscreditrisk"} */
create schema if not exists `steam-outlet-209412`.`oscreditrisk`
  
[0m18:02:36.508984 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:d54e1972-4355-4954-b1cb-1b1b05993754&page=queryresults
[0m18:02:38.281506 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_steam-outlet-209412_oscreditrisk, now list_steam-outlet-209412_oscreditrisk)
[0m18:02:38.282202 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:02:39.144926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bdb00794-8a55-4dac-b439-3d72c6dc85bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd74abf2f70>]}
[0m18:02:39.146017 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:02:39.146596 [info ] [MainThread]: 
[0m18:02:39.151322 [debug] [Thread-1  ]: Began running node seed.creditrisk.loans
[0m18:02:39.159950 [info ] [Thread-1  ]: 1 of 2 START seed file oscreditrisk.loans ...................................... [RUN]
[0m18:02:39.161054 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now seed.creditrisk.loans)
[0m18:02:39.161830 [debug] [Thread-1  ]: Began compiling node seed.creditrisk.loans
[0m18:02:39.162504 [debug] [Thread-1  ]: Began executing node seed.creditrisk.loans
[0m18:02:39.955661 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:02:44.562140 [debug] [Thread-1  ]: BigQuery adapter: Unhandled error while running:
LOAD TABLE
[0m18:02:44.563876 [debug] [Thread-1  ]: BigQuery adapter: Runtime Error
  Error while reading data, error message: CSV table encountered too many errors, giving up. Rows: 100; errors: 100. Please look into the errors[] collection for more details.
  Error while reading data, error message: CSV processing encountered too many errors, giving up. Rows: 100; errors: 100; max bad: 0; error percent: 0
  Error while reading data, error message: Unable to parse; line_number: 2 byte_offset_to_start_of_line: 93 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 3 byte_offset_to_start_of_line: 163 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 4 byte_offset_to_start_of_line: 233 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 5 byte_offset_to_start_of_line: 303 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 6 byte_offset_to_start_of_line: 373 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 7 byte_offset_to_start_of_line: 443 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 8 byte_offset_to_start_of_line: 513 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 9 byte_offset_to_start_of_line: 583 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 10 byte_offset_to_start_of_line: 653 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2846400.0"
  Error while reading data, error message: Unable to parse; line_number: 11 byte_offset_to_start_of_line: 723 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 12 byte_offset_to_start_of_line: 793 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 13 byte_offset_to_start_of_line: 863 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2855920.0"
  Error while reading data, error message: Unable to parse; line_number: 14 byte_offset_to_start_of_line: 933 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 15 byte_offset_to_start_of_line: 1003 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 16 byte_offset_to_start_of_line: 1073 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 17 byte_offset_to_start_of_line: 1143 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2573120.0"
  Error while reading data, error message: Unable to parse; line_number: 18 byte_offset_to_start_of_line: 1213 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2566400.0"
  Error while reading data, error message: Unable to parse; line_number: 19 byte_offset_to_start_of_line: 1283 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 20 byte_offset_to_start_of_line: 1353 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 21 byte_offset_to_start_of_line: 1423 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2846400.0"
  Error while reading data, error message: Unable to parse; line_number: 22 byte_offset_to_start_of_line: 1493 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 23 byte_offset_to_start_of_line: 1563 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2480000.0"
  Error while reading data, error message: Unable to parse; line_number: 24 byte_offset_to_start_of_line: 1638 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "4000000.0"
  Error while reading data, error message: Unable to parse; line_number: 25 byte_offset_to_start_of_line: 1708 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 26 byte_offset_to_start_of_line: 1778 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 27 byte_offset_to_start_of_line: 1848 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 28 byte_offset_to_start_of_line: 1918 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 29 byte_offset_to_start_of_line: 1988 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 30 byte_offset_to_start_of_line: 2058 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2480000.0"
  Error while reading data, error message: Unable to parse; line_number: 31 byte_offset_to_start_of_line: 2133 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 32 byte_offset_to_start_of_line: 2203 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 33 byte_offset_to_start_of_line: 2273 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2766400.0"
  Error while reading data, error message: Unable to parse; line_number: 34 byte_offset_to_start_of_line: 2343 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 35 byte_offset_to_start_of_line: 2413 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2711800.0"
  Error while reading data, error message: Unable to parse; line_number: 36 byte_offset_to_start_of_line: 2483 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2770600.0"
  Error while reading data, error message: Unable to parse; line_number: 37 byte_offset_to_start_of_line: 2553 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 38 byte_offset_to_start_of_line: 2623 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 39 byte_offset_to_start_of_line: 2693 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 40 byte_offset_to_start_of_line: 2763 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 41 byte_offset_to_start_of_line: 2833 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2240000.0"
  Error while reading data, error message: Unable to parse; line_number: 42 byte_offset_to_start_of_line: 2908 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "1840000.0"
  Error while reading data, error message: Unable to parse; line_number: 43 byte_offset_to_start_of_line: 2983 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 44 byte_offset_to_start_of_line: 3053 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2770600.0"
  Error while reading data, error message: Unable to parse; line_number: 45 byte_offset_to_start_of_line: 3123 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 46 byte_offset_to_start_of_line: 3193 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2240000.0"
  Error while reading data, error message: Unable to parse; line_number: 47 byte_offset_to_start_of_line: 3268 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 48 byte_offset_to_start_of_line: 3338 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 49 byte_offset_to_start_of_line: 3409 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 50 byte_offset_to_start_of_line: 3480 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2766400.0"
  Error while reading data, error message: Unable to parse; line_number: 51 byte_offset_to_start_of_line: 3551 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 52 byte_offset_to_start_of_line: 3622 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 53 byte_offset_to_start_of_line: 3693 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2240000.0"
  Error while reading data, error message: Unable to parse; line_number: 54 byte_offset_to_start_of_line: 3769 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 55 byte_offset_to_start_of_line: 3840 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 56 byte_offset_to_start_of_line: 3911 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 57 byte_offset_to_start_of_line: 3982 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 58 byte_offset_to_start_of_line: 4053 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 59 byte_offset_to_start_of_line: 4124 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 60 byte_offset_to_start_of_line: 4195 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 61 byte_offset_to_start_of_line: 4265 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 62 byte_offset_to_start_of_line: 4335 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 63 byte_offset_to_start_of_line: 4405 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 64 byte_offset_to_start_of_line: 4475 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2774000.0"
  Error while reading data, error message: Unable to parse; line_number: 65 byte_offset_to_start_of_line: 4545 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 66 byte_offset_to_start_of_line: 4615 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 67 byte_offset_to_start_of_line: 4685 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 68 byte_offset_to_start_of_line: 4755 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 69 byte_offset_to_start_of_line: 4825 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 70 byte_offset_to_start_of_line: 4895 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 71 byte_offset_to_start_of_line: 4965 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 72 byte_offset_to_start_of_line: 5035 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 73 byte_offset_to_start_of_line: 5105 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 74 byte_offset_to_start_of_line: 5175 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 75 byte_offset_to_start_of_line: 5245 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 76 byte_offset_to_start_of_line: 5315 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 77 byte_offset_to_start_of_line: 5385 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 78 byte_offset_to_start_of_line: 5455 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 79 byte_offset_to_start_of_line: 5525 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 80 byte_offset_to_start_of_line: 5595 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 81 byte_offset_to_start_of_line: 5665 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 82 byte_offset_to_start_of_line: 5735 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 83 byte_offset_to_start_of_line: 5805 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 84 byte_offset_to_start_of_line: 5875 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 85 byte_offset_to_start_of_line: 5945 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 86 byte_offset_to_start_of_line: 6015 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 87 byte_offset_to_start_of_line: 6085 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 88 byte_offset_to_start_of_line: 6155 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 89 byte_offset_to_start_of_line: 6225 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 90 byte_offset_to_start_of_line: 6295 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 91 byte_offset_to_start_of_line: 6365 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2700800.0"
  Error while reading data, error message: Unable to parse; line_number: 92 byte_offset_to_start_of_line: 6435 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 93 byte_offset_to_start_of_line: 6505 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2712000.0"
  Error while reading data, error message: Unable to parse; line_number: 94 byte_offset_to_start_of_line: 6575 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 95 byte_offset_to_start_of_line: 6645 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 96 byte_offset_to_start_of_line: 6715 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 97 byte_offset_to_start_of_line: 6785 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2609200.0"
  Error while reading data, error message: Unable to parse; line_number: 98 byte_offset_to_start_of_line: 6855 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 99 byte_offset_to_start_of_line: 6925 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 100 byte_offset_to_start_of_line: 6995 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 101 byte_offset_to_start_of_line: 7065 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  You are loading data without specifying data format, data will be treated as CSV format by default. If this is not what you mean, please specify data format by --source_format.
[0m18:02:44.574678 [debug] [Thread-1  ]: Runtime Error in seed loans (seeds/loans.csv)
  Error while reading data, error message: CSV table encountered too many errors, giving up. Rows: 100; errors: 100. Please look into the errors[] collection for more details.
  Error while reading data, error message: CSV processing encountered too many errors, giving up. Rows: 100; errors: 100; max bad: 0; error percent: 0
  Error while reading data, error message: Unable to parse; line_number: 2 byte_offset_to_start_of_line: 93 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 3 byte_offset_to_start_of_line: 163 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 4 byte_offset_to_start_of_line: 233 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 5 byte_offset_to_start_of_line: 303 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 6 byte_offset_to_start_of_line: 373 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 7 byte_offset_to_start_of_line: 443 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 8 byte_offset_to_start_of_line: 513 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 9 byte_offset_to_start_of_line: 583 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 10 byte_offset_to_start_of_line: 653 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2846400.0"
  Error while reading data, error message: Unable to parse; line_number: 11 byte_offset_to_start_of_line: 723 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 12 byte_offset_to_start_of_line: 793 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 13 byte_offset_to_start_of_line: 863 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2855920.0"
  Error while reading data, error message: Unable to parse; line_number: 14 byte_offset_to_start_of_line: 933 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 15 byte_offset_to_start_of_line: 1003 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 16 byte_offset_to_start_of_line: 1073 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 17 byte_offset_to_start_of_line: 1143 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2573120.0"
  Error while reading data, error message: Unable to parse; line_number: 18 byte_offset_to_start_of_line: 1213 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2566400.0"
  Error while reading data, error message: Unable to parse; line_number: 19 byte_offset_to_start_of_line: 1283 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 20 byte_offset_to_start_of_line: 1353 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 21 byte_offset_to_start_of_line: 1423 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2846400.0"
  Error while reading data, error message: Unable to parse; line_number: 22 byte_offset_to_start_of_line: 1493 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 23 byte_offset_to_start_of_line: 1563 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2480000.0"
  Error while reading data, error message: Unable to parse; line_number: 24 byte_offset_to_start_of_line: 1638 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "4000000.0"
  Error while reading data, error message: Unable to parse; line_number: 25 byte_offset_to_start_of_line: 1708 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 26 byte_offset_to_start_of_line: 1778 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 27 byte_offset_to_start_of_line: 1848 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 28 byte_offset_to_start_of_line: 1918 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 29 byte_offset_to_start_of_line: 1988 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 30 byte_offset_to_start_of_line: 2058 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2480000.0"
  Error while reading data, error message: Unable to parse; line_number: 31 byte_offset_to_start_of_line: 2133 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 32 byte_offset_to_start_of_line: 2203 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 33 byte_offset_to_start_of_line: 2273 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2766400.0"
  Error while reading data, error message: Unable to parse; line_number: 34 byte_offset_to_start_of_line: 2343 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 35 byte_offset_to_start_of_line: 2413 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2711800.0"
  Error while reading data, error message: Unable to parse; line_number: 36 byte_offset_to_start_of_line: 2483 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2770600.0"
  Error while reading data, error message: Unable to parse; line_number: 37 byte_offset_to_start_of_line: 2553 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 38 byte_offset_to_start_of_line: 2623 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 39 byte_offset_to_start_of_line: 2693 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 40 byte_offset_to_start_of_line: 2763 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 41 byte_offset_to_start_of_line: 2833 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2240000.0"
  Error while reading data, error message: Unable to parse; line_number: 42 byte_offset_to_start_of_line: 2908 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "1840000.0"
  Error while reading data, error message: Unable to parse; line_number: 43 byte_offset_to_start_of_line: 2983 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 44 byte_offset_to_start_of_line: 3053 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2770600.0"
  Error while reading data, error message: Unable to parse; line_number: 45 byte_offset_to_start_of_line: 3123 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 46 byte_offset_to_start_of_line: 3193 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2240000.0"
  Error while reading data, error message: Unable to parse; line_number: 47 byte_offset_to_start_of_line: 3268 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 48 byte_offset_to_start_of_line: 3338 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 49 byte_offset_to_start_of_line: 3409 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 50 byte_offset_to_start_of_line: 3480 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2766400.0"
  Error while reading data, error message: Unable to parse; line_number: 51 byte_offset_to_start_of_line: 3551 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 52 byte_offset_to_start_of_line: 3622 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 53 byte_offset_to_start_of_line: 3693 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2240000.0"
  Error while reading data, error message: Unable to parse; line_number: 54 byte_offset_to_start_of_line: 3769 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 55 byte_offset_to_start_of_line: 3840 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 56 byte_offset_to_start_of_line: 3911 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 57 byte_offset_to_start_of_line: 3982 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 58 byte_offset_to_start_of_line: 4053 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 59 byte_offset_to_start_of_line: 4124 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 60 byte_offset_to_start_of_line: 4195 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 61 byte_offset_to_start_of_line: 4265 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 62 byte_offset_to_start_of_line: 4335 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 63 byte_offset_to_start_of_line: 4405 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 64 byte_offset_to_start_of_line: 4475 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2774000.0"
  Error while reading data, error message: Unable to parse; line_number: 65 byte_offset_to_start_of_line: 4545 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 66 byte_offset_to_start_of_line: 4615 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 67 byte_offset_to_start_of_line: 4685 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 68 byte_offset_to_start_of_line: 4755 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 69 byte_offset_to_start_of_line: 4825 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 70 byte_offset_to_start_of_line: 4895 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 71 byte_offset_to_start_of_line: 4965 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 72 byte_offset_to_start_of_line: 5035 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 73 byte_offset_to_start_of_line: 5105 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 74 byte_offset_to_start_of_line: 5175 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 75 byte_offset_to_start_of_line: 5245 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 76 byte_offset_to_start_of_line: 5315 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 77 byte_offset_to_start_of_line: 5385 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 78 byte_offset_to_start_of_line: 5455 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 79 byte_offset_to_start_of_line: 5525 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 80 byte_offset_to_start_of_line: 5595 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 81 byte_offset_to_start_of_line: 5665 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 82 byte_offset_to_start_of_line: 5735 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 83 byte_offset_to_start_of_line: 5805 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 84 byte_offset_to_start_of_line: 5875 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 85 byte_offset_to_start_of_line: 5945 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 86 byte_offset_to_start_of_line: 6015 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 87 byte_offset_to_start_of_line: 6085 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 88 byte_offset_to_start_of_line: 6155 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 89 byte_offset_to_start_of_line: 6225 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 90 byte_offset_to_start_of_line: 6295 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 91 byte_offset_to_start_of_line: 6365 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2700800.0"
  Error while reading data, error message: Unable to parse; line_number: 92 byte_offset_to_start_of_line: 6435 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 93 byte_offset_to_start_of_line: 6505 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2712000.0"
  Error while reading data, error message: Unable to parse; line_number: 94 byte_offset_to_start_of_line: 6575 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 95 byte_offset_to_start_of_line: 6645 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 96 byte_offset_to_start_of_line: 6715 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 97 byte_offset_to_start_of_line: 6785 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2609200.0"
  Error while reading data, error message: Unable to parse; line_number: 98 byte_offset_to_start_of_line: 6855 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 99 byte_offset_to_start_of_line: 6925 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 100 byte_offset_to_start_of_line: 6995 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 101 byte_offset_to_start_of_line: 7065 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  You are loading data without specifying data format, data will be treated as CSV format by default. If this is not what you mean, please specify data format by --source_format.
[0m18:02:44.578048 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdb00794-8a55-4dac-b439-3d72c6dc85bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd74394d670>]}
[0m18:02:44.580609 [error] [Thread-1  ]: 1 of 2 ERROR loading seed file oscreditrisk.loans .............................. [[31mERROR[0m in 5.42s]
[0m18:02:44.583428 [debug] [Thread-1  ]: Finished running node seed.creditrisk.loans
[0m18:02:44.584227 [debug] [Thread-1  ]: Began running node seed.creditrisk.payments
[0m18:02:44.585300 [info ] [Thread-1  ]: 2 of 2 START seed file oscreditrisk.payments ................................... [RUN]
[0m18:02:44.586371 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly seed.creditrisk.loans, now seed.creditrisk.payments)
[0m18:02:44.587236 [debug] [Thread-1  ]: Began compiling node seed.creditrisk.payments
[0m18:02:44.587867 [debug] [Thread-1  ]: Began executing node seed.creditrisk.payments
[0m18:02:49.333528 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:03:05.611714 [debug] [Thread-1  ]: On seed.creditrisk.payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "seed.creditrisk.payments"} */

    alter table `steam-outlet-209412`.`oscreditrisk`.`payments` set OPTIONS()
  
[0m18:03:06.037936 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:9ea9dd2c-7614-4d86-a24d-2d3a4bdfcbf6&page=queryresults
[0m18:03:06.666537 [debug] [Thread-1  ]: Writing runtime SQL for node "seed.creditrisk.payments"
[0m18:03:06.692781 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdb00794-8a55-4dac-b439-3d72c6dc85bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7454d66d0>]}
[0m18:03:06.693608 [info ] [Thread-1  ]: 2 of 2 OK loaded seed file oscreditrisk.payments ............................... [[32mINSERT 149506[0m in 22.11s]
[0m18:03:06.694539 [debug] [Thread-1  ]: Finished running node seed.creditrisk.payments
[0m18:03:06.696087 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:03:06.696571 [debug] [MainThread]: Connection 'seed.creditrisk.payments' was properly closed.
[0m18:03:06.697104 [info ] [MainThread]: 
[0m18:03:06.697695 [info ] [MainThread]: Finished running 2 seeds in 0 hours 0 minutes and 34.50 seconds (34.50s).
[0m18:03:06.700087 [debug] [MainThread]: Command end result
[0m18:03:06.754629 [info ] [MainThread]: 
[0m18:03:06.755359 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:03:06.755860 [info ] [MainThread]: 
[0m18:03:06.757500 [error] [MainThread]:   Runtime Error in seed loans (seeds/loans.csv)
  Error while reading data, error message: CSV table encountered too many errors, giving up. Rows: 100; errors: 100. Please look into the errors[] collection for more details.
  Error while reading data, error message: CSV processing encountered too many errors, giving up. Rows: 100; errors: 100; max bad: 0; error percent: 0
  Error while reading data, error message: Unable to parse; line_number: 2 byte_offset_to_start_of_line: 93 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 3 byte_offset_to_start_of_line: 163 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 4 byte_offset_to_start_of_line: 233 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 5 byte_offset_to_start_of_line: 303 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 6 byte_offset_to_start_of_line: 373 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 7 byte_offset_to_start_of_line: 443 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 8 byte_offset_to_start_of_line: 513 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 9 byte_offset_to_start_of_line: 583 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 10 byte_offset_to_start_of_line: 653 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2846400.0"
  Error while reading data, error message: Unable to parse; line_number: 11 byte_offset_to_start_of_line: 723 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 12 byte_offset_to_start_of_line: 793 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 13 byte_offset_to_start_of_line: 863 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2855920.0"
  Error while reading data, error message: Unable to parse; line_number: 14 byte_offset_to_start_of_line: 933 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 15 byte_offset_to_start_of_line: 1003 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 16 byte_offset_to_start_of_line: 1073 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 17 byte_offset_to_start_of_line: 1143 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2573120.0"
  Error while reading data, error message: Unable to parse; line_number: 18 byte_offset_to_start_of_line: 1213 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2566400.0"
  Error while reading data, error message: Unable to parse; line_number: 19 byte_offset_to_start_of_line: 1283 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 20 byte_offset_to_start_of_line: 1353 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 21 byte_offset_to_start_of_line: 1423 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2846400.0"
  Error while reading data, error message: Unable to parse; line_number: 22 byte_offset_to_start_of_line: 1493 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 23 byte_offset_to_start_of_line: 1563 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2480000.0"
  Error while reading data, error message: Unable to parse; line_number: 24 byte_offset_to_start_of_line: 1638 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "4000000.0"
  Error while reading data, error message: Unable to parse; line_number: 25 byte_offset_to_start_of_line: 1708 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 26 byte_offset_to_start_of_line: 1778 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 27 byte_offset_to_start_of_line: 1848 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 28 byte_offset_to_start_of_line: 1918 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 29 byte_offset_to_start_of_line: 1988 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 30 byte_offset_to_start_of_line: 2058 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2480000.0"
  Error while reading data, error message: Unable to parse; line_number: 31 byte_offset_to_start_of_line: 2133 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 32 byte_offset_to_start_of_line: 2203 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 33 byte_offset_to_start_of_line: 2273 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2766400.0"
  Error while reading data, error message: Unable to parse; line_number: 34 byte_offset_to_start_of_line: 2343 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 35 byte_offset_to_start_of_line: 2413 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2711800.0"
  Error while reading data, error message: Unable to parse; line_number: 36 byte_offset_to_start_of_line: 2483 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2770600.0"
  Error while reading data, error message: Unable to parse; line_number: 37 byte_offset_to_start_of_line: 2553 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 38 byte_offset_to_start_of_line: 2623 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 39 byte_offset_to_start_of_line: 2693 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 40 byte_offset_to_start_of_line: 2763 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 41 byte_offset_to_start_of_line: 2833 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2240000.0"
  Error while reading data, error message: Unable to parse; line_number: 42 byte_offset_to_start_of_line: 2908 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "1840000.0"
  Error while reading data, error message: Unable to parse; line_number: 43 byte_offset_to_start_of_line: 2983 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 44 byte_offset_to_start_of_line: 3053 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2770600.0"
  Error while reading data, error message: Unable to parse; line_number: 45 byte_offset_to_start_of_line: 3123 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 46 byte_offset_to_start_of_line: 3193 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2240000.0"
  Error while reading data, error message: Unable to parse; line_number: 47 byte_offset_to_start_of_line: 3268 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 48 byte_offset_to_start_of_line: 3338 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 49 byte_offset_to_start_of_line: 3409 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 50 byte_offset_to_start_of_line: 3480 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2766400.0"
  Error while reading data, error message: Unable to parse; line_number: 51 byte_offset_to_start_of_line: 3551 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 52 byte_offset_to_start_of_line: 3622 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 53 byte_offset_to_start_of_line: 3693 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2240000.0"
  Error while reading data, error message: Unable to parse; line_number: 54 byte_offset_to_start_of_line: 3769 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 55 byte_offset_to_start_of_line: 3840 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 56 byte_offset_to_start_of_line: 3911 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 57 byte_offset_to_start_of_line: 3982 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 58 byte_offset_to_start_of_line: 4053 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 59 byte_offset_to_start_of_line: 4124 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2800000.0"
  Error while reading data, error message: Unable to parse; line_number: 60 byte_offset_to_start_of_line: 4195 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 61 byte_offset_to_start_of_line: 4265 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 62 byte_offset_to_start_of_line: 4335 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 63 byte_offset_to_start_of_line: 4405 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 64 byte_offset_to_start_of_line: 4475 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2774000.0"
  Error while reading data, error message: Unable to parse; line_number: 65 byte_offset_to_start_of_line: 4545 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 66 byte_offset_to_start_of_line: 4615 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 67 byte_offset_to_start_of_line: 4685 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 68 byte_offset_to_start_of_line: 4755 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 69 byte_offset_to_start_of_line: 4825 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 70 byte_offset_to_start_of_line: 4895 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 71 byte_offset_to_start_of_line: 4965 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 72 byte_offset_to_start_of_line: 5035 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 73 byte_offset_to_start_of_line: 5105 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 74 byte_offset_to_start_of_line: 5175 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 75 byte_offset_to_start_of_line: 5245 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 76 byte_offset_to_start_of_line: 5315 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 77 byte_offset_to_start_of_line: 5385 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 78 byte_offset_to_start_of_line: 5455 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 79 byte_offset_to_start_of_line: 5525 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 80 byte_offset_to_start_of_line: 5595 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 81 byte_offset_to_start_of_line: 5665 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 82 byte_offset_to_start_of_line: 5735 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 83 byte_offset_to_start_of_line: 5805 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 84 byte_offset_to_start_of_line: 5875 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 85 byte_offset_to_start_of_line: 5945 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 86 byte_offset_to_start_of_line: 6015 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 87 byte_offset_to_start_of_line: 6085 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 88 byte_offset_to_start_of_line: 6155 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 89 byte_offset_to_start_of_line: 6225 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 90 byte_offset_to_start_of_line: 6295 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 91 byte_offset_to_start_of_line: 6365 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2700800.0"
  Error while reading data, error message: Unable to parse; line_number: 92 byte_offset_to_start_of_line: 6435 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 93 byte_offset_to_start_of_line: 6505 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2712000.0"
  Error while reading data, error message: Unable to parse; line_number: 94 byte_offset_to_start_of_line: 6575 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 95 byte_offset_to_start_of_line: 6645 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 96 byte_offset_to_start_of_line: 6715 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 97 byte_offset_to_start_of_line: 6785 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2609200.0"
  Error while reading data, error message: Unable to parse; line_number: 98 byte_offset_to_start_of_line: 6855 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2852000.0"
  Error while reading data, error message: Unable to parse; line_number: 99 byte_offset_to_start_of_line: 6925 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 100 byte_offset_to_start_of_line: 6995 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  Error while reading data, error message: Unable to parse; line_number: 101 byte_offset_to_start_of_line: 7065 column_index: 2 column_name: "unlock_price" column_type: INT64 value: "2880000.0"
  You are loading data without specifying data format, data will be treated as CSV format by default. If this is not what you mean, please specify data format by --source_format.
[0m18:03:06.760566 [info ] [MainThread]: 
[0m18:03:06.761161 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m18:03:06.762033 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_wall_clock_time": 43.006104, "process_user_time": 12.705898, "process_kernel_time": 1.444183, "process_mem_max_rss": "386936832", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:03:06.762870 [debug] [MainThread]: Command `dbt seed` failed at 18:03:06.762714 after 43.01 seconds
[0m18:03:06.763467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd74422f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd745b408e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd74b381e50>]}
[0m18:03:06.764102 [debug] [MainThread]: Flushing usage events
[0m20:08:12.573220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff281260520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff283270d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff283270070>]}


============================== 20:08:12.579030 | 799c7073-d101-4612-b7d0-1324516ac387 ==============================
[0m20:08:12.579030 [info ] [MainThread]: Running with dbt=1.8.8
[0m20:08:12.580029 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'target_path': 'None', 'introspect': 'True', 'empty': 'None', 'profiles_dir': '/Users/david/.dbt', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'log_format': 'default', 'quiet': 'False', 'static_parser': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'use_colors': 'True', 'invocation_command': 'dbt seed', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'debug': 'False', 'version_check': 'True', 'printer_width': '80', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs'}
[0m20:08:17.903043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '799c7073-d101-4612-b7d0-1324516ac387', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff286e88520>]}
[0m20:08:17.985055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '799c7073-d101-4612-b7d0-1324516ac387', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff286dd7eb0>]}
[0m20:08:17.986024 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m20:08:18.025890 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m20:08:18.422527 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 2 files added, 0 files changed.
[0m20:08:18.423702 [debug] [MainThread]: Partial parsing: added file: creditrisk://seeds/raw_payments.csv
[0m20:08:18.424481 [debug] [MainThread]: Partial parsing: added file: creditrisk://seeds/raw_accounts.csv
[0m20:08:18.425008 [debug] [MainThread]: Partial parsing: deleted file: creditrisk://seeds/payments.csv
[0m20:08:18.425471 [debug] [MainThread]: Partial parsing: deleted file: creditrisk://seeds/loans.csv
[0m20:08:18.782708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '799c7073-d101-4612-b7d0-1324516ac387', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff287a51130>]}
[0m20:08:19.038649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '799c7073-d101-4612-b7d0-1324516ac387', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff287a73fa0>]}
[0m20:08:19.039492 [info ] [MainThread]: Found 2 models, 4 data tests, 2 seeds, 479 macros
[0m20:08:19.040070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '799c7073-d101-4612-b7d0-1324516ac387', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff287a6f460>]}
[0m20:08:19.042110 [info ] [MainThread]: 
[0m20:08:19.043154 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:08:19.051375 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m20:08:19.052323 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:08:22.551587 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m20:08:22.553316 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:08:23.168559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '799c7073-d101-4612-b7d0-1324516ac387', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2811edbb0>]}
[0m20:08:23.169663 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:08:23.170264 [info ] [MainThread]: 
[0m20:08:23.175720 [debug] [Thread-1  ]: Began running node seed.creditrisk.raw_accounts
[0m20:08:23.176809 [info ] [Thread-1  ]: 1 of 2 START seed file oscreditrisk.raw_accounts ............................... [RUN]
[0m20:08:23.177651 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now seed.creditrisk.raw_accounts)
[0m20:08:23.178291 [debug] [Thread-1  ]: Began compiling node seed.creditrisk.raw_accounts
[0m20:08:23.178936 [debug] [Thread-1  ]: Began executing node seed.creditrisk.raw_accounts
[0m20:08:23.620960 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:08:29.520718 [debug] [Thread-1  ]: On seed.creditrisk.raw_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "seed.creditrisk.raw_accounts"} */

    alter table `steam-outlet-209412`.`oscreditrisk`.`raw_accounts` set OPTIONS()
  
[0m20:08:30.413515 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:a5c0a6e8-f6b7-44f7-aab4-d591c2d67197&page=queryresults
[0m20:08:31.209568 [debug] [Thread-1  ]: Writing runtime SQL for node "seed.creditrisk.raw_accounts"
[0m20:08:31.236883 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '799c7073-d101-4612-b7d0-1324516ac387', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff282378cd0>]}
[0m20:08:31.238514 [info ] [Thread-1  ]: 1 of 2 OK loaded seed file oscreditrisk.raw_accounts ........................... [[32mINSERT 6201[0m in 8.06s]
[0m20:08:31.239559 [debug] [Thread-1  ]: Finished running node seed.creditrisk.raw_accounts
[0m20:08:31.240696 [debug] [Thread-1  ]: Began running node seed.creditrisk.raw_payments
[0m20:08:31.241567 [info ] [Thread-1  ]: 2 of 2 START seed file oscreditrisk.raw_payments ............................... [RUN]
[0m20:08:31.242283 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly seed.creditrisk.raw_accounts, now seed.creditrisk.raw_payments)
[0m20:08:31.242875 [debug] [Thread-1  ]: Began compiling node seed.creditrisk.raw_payments
[0m20:08:31.243454 [debug] [Thread-1  ]: Began executing node seed.creditrisk.raw_payments
[0m20:08:36.087519 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:08:43.402195 [debug] [Thread-1  ]: On seed.creditrisk.raw_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "seed.creditrisk.raw_payments"} */

    alter table `steam-outlet-209412`.`oscreditrisk`.`raw_payments` set OPTIONS()
  
[0m20:08:43.804443 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:437a38eb-24ad-4f5f-a031-ead78462b18d&page=queryresults
[0m20:08:44.526451 [debug] [Thread-1  ]: Writing runtime SQL for node "seed.creditrisk.raw_payments"
[0m20:08:44.529892 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '799c7073-d101-4612-b7d0-1324516ac387', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2811dde20>]}
[0m20:08:44.530672 [info ] [Thread-1  ]: 2 of 2 OK loaded seed file oscreditrisk.raw_payments ........................... [[32mINSERT 149506[0m in 13.29s]
[0m20:08:44.531598 [debug] [Thread-1  ]: Finished running node seed.creditrisk.raw_payments
[0m20:08:44.533195 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:08:44.533678 [debug] [MainThread]: Connection 'seed.creditrisk.raw_payments' was properly closed.
[0m20:08:44.534228 [info ] [MainThread]: 
[0m20:08:44.534820 [info ] [MainThread]: Finished running 2 seeds in 0 hours 0 minutes and 25.49 seconds (25.49s).
[0m20:08:44.536115 [debug] [MainThread]: Command end result
[0m20:08:44.591672 [info ] [MainThread]: 
[0m20:08:44.592650 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:08:44.593272 [info ] [MainThread]: 
[0m20:08:44.593914 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m20:08:44.594782 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 32.12951, "process_user_time": 11.036833, "process_kernel_time": 1.422405, "process_mem_max_rss": "392900608", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m20:08:44.595758 [debug] [MainThread]: Command `dbt seed` succeeded at 20:08:44.595586 after 32.13 seconds
[0m20:08:44.596401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff281260520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff282a30760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff287a73df0>]}
[0m20:08:44.596993 [debug] [MainThread]: Flushing usage events
[0m20:10:48.502916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8098932520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f809b3afa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f809b3af340>]}


============================== 20:10:48.508449 | f6524df1-b145-4131-91a6-fa3b92aaedbe ==============================
[0m20:10:48.508449 [info ] [MainThread]: Running with dbt=1.8.8
[0m20:10:48.509382 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'use_colors': 'True', 'printer_width': '80', 'fail_fast': 'False', 'warn_error': 'None', 'cache_selected_only': 'False', 'invocation_command': 'dbt run --select cleaned_accounts', 'static_parser': 'True', 'quiet': 'False', 'profiles_dir': '/Users/david/.dbt', 'log_cache_events': 'False', 'partial_parse': 'True', 'target_path': 'None', 'empty': 'False', 'no_print': 'None', 'write_json': 'True', 'introspect': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'version_check': 'True', 'use_experimental_parser': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'debug': 'False'}
[0m20:10:52.966530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f6524df1-b145-4131-91a6-fa3b92aaedbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f809ed84fd0>]}
[0m20:10:53.044254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f6524df1-b145-4131-91a6-fa3b92aaedbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f809ecd9fa0>]}
[0m20:10:53.045245 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m20:10:53.080601 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m20:10:53.440875 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m20:10:53.441688 [debug] [MainThread]: Partial parsing: added file: creditrisk://models/example/1. cleaning/cleaned_accounts.sql
[0m20:10:53.800452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f6524df1-b145-4131-91a6-fa3b92aaedbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80a02c5130>]}
[0m20:10:53.979357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f6524df1-b145-4131-91a6-fa3b92aaedbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80a02c4eb0>]}
[0m20:10:53.980157 [info ] [MainThread]: Found 3 models, 4 data tests, 2 seeds, 479 macros
[0m20:10:53.980721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f6524df1-b145-4131-91a6-fa3b92aaedbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80a0404070>]}
[0m20:10:53.982315 [info ] [MainThread]: 
[0m20:10:53.983130 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:10:53.984327 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m20:10:53.984955 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:10:57.027874 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m20:10:57.029583 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:10:57.724534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f6524df1-b145-4131-91a6-fa3b92aaedbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80988bfbb0>]}
[0m20:10:57.725586 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:10:57.726169 [info ] [MainThread]: 
[0m20:10:57.729919 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m20:10:57.730793 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m20:10:57.731627 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m20:10:57.732289 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m20:10:57.746996 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m20:10:57.748724 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m20:10:57.805296 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m20:10:57.806686 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:10:57.807412 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as WITH accounts as (
    `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date AS TIMESTAMP) as registration_date, 
  CAST(unlock_price AS FLOAT) as unlock_price, 
  CAST(down_payment AS FLOAT) as down_payment, 
  CAST(down_payment_days_included AS FLOAT) as down_payment_days_included, 
  CAST(daily_rate AS FLOAT) as daily_rate, 
FROM accounts;


[0m20:10:58.956193 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:8741498a-aff5-4820-85af-b013687e07ba&page=queryresults
[0m20:10:58.977293 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected identifier `steam-outlet-209412` at [7:5]; reason: invalidQuery, location: query, message: Syntax error: Unexpected identifier `steam-outlet-209412` at [7:5]')
[0m20:11:00.012577 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:1c150bb9-df65-4ac3-8664-7177f7438d46&page=queryresults
[0m20:11:00.013514 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:1c150bb9-df65-4ac3-8664-7177f7438d46&page=queryresults
[0m20:11:00.028561 [debug] [Thread-1  ]: Database Error in model cleaned_accounts (models/example/1. cleaning/cleaned_accounts.sql)
  Syntax error: Unexpected identifier `steam-outlet-209412` at [7:5]
  compiled code at target/run/creditrisk/models/example/1. cleaning/cleaned_accounts.sql
[0m20:11:00.030979 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f6524df1-b145-4131-91a6-fa3b92aaedbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80a0a29940>]}
[0m20:11:00.033057 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.cleaned_accounts ............. [[31mERROR[0m in 2.30s]
[0m20:11:00.034115 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m20:11:00.035872 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:11:00.036372 [debug] [MainThread]: Connection 'model.creditrisk.cleaned_accounts' was properly closed.
[0m20:11:00.036874 [info ] [MainThread]: 
[0m20:11:00.037412 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.05 seconds (6.05s).
[0m20:11:00.038557 [debug] [MainThread]: Command end result
[0m20:11:00.090512 [info ] [MainThread]: 
[0m20:11:00.091305 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:11:00.091822 [info ] [MainThread]: 
[0m20:11:00.092471 [error] [MainThread]:   Database Error in model cleaned_accounts (models/example/1. cleaning/cleaned_accounts.sql)
  Syntax error: Unexpected identifier `steam-outlet-209412` at [7:5]
  compiled code at target/run/creditrisk/models/example/1. cleaning/cleaned_accounts.sql
[0m20:11:00.093125 [info ] [MainThread]: 
[0m20:11:00.093812 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m20:11:00.095252 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 11.686525, "process_user_time": 5.70933, "process_kernel_time": 1.083614, "process_mem_max_rss": "229711872", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m20:11:00.096426 [debug] [MainThread]: Command `dbt run` failed at 20:11:00.096232 after 11.69 seconds
[0m20:11:00.097297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8098932520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8098e87670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80a0404070>]}
[0m20:11:00.098459 [debug] [MainThread]: Flushing usage events
[0m20:14:01.018401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8daa32580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8dc9b0be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8dc9b0190>]}


============================== 20:14:01.026870 | 05b84beb-7cfc-442a-b60d-6d0c31ced306 ==============================
[0m20:14:01.026870 [info ] [MainThread]: Running with dbt=1.8.8
[0m20:14:01.028206 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'fail_fast': 'False', 'warn_error': 'None', 'quiet': 'False', 'invocation_command': 'dbt run --select cleaned_accounts', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'introspect': 'True', 'write_json': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'empty': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'target_path': 'None', 'indirect_selection': 'eager', 'profiles_dir': '/Users/david/.dbt', 'use_experimental_parser': 'False'}
[0m20:14:06.871276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '05b84beb-7cfc-442a-b60d-6d0c31ced306', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8e0488f70>]}
[0m20:14:06.967066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '05b84beb-7cfc-442a-b60d-6d0c31ced306', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8e0b9b280>]}
[0m20:14:06.968029 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m20:14:07.008188 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m20:14:07.386114 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m20:14:07.386900 [debug] [MainThread]: Partial parsing: added file: creditrisk://models/example/0_cleaning/cleaned_accounts.sql
[0m20:14:07.387383 [debug] [MainThread]: Partial parsing: deleted file: creditrisk://models/example/1. cleaning/cleaned_accounts.sql
[0m20:14:07.766509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '05b84beb-7cfc-442a-b60d-6d0c31ced306', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8e0fc8130>]}
[0m20:14:07.966615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '05b84beb-7cfc-442a-b60d-6d0c31ced306', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8e0fd8100>]}
[0m20:14:07.967508 [info ] [MainThread]: Found 3 models, 4 data tests, 2 seeds, 479 macros
[0m20:14:07.968223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '05b84beb-7cfc-442a-b60d-6d0c31ced306', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8daf06bb0>]}
[0m20:14:07.970166 [info ] [MainThread]: 
[0m20:14:07.971138 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:14:07.972422 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m20:14:07.973084 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:14:11.695281 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m20:14:11.696317 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:14:12.326898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '05b84beb-7cfc-442a-b60d-6d0c31ced306', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8e1006040>]}
[0m20:14:12.327957 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:14:12.328531 [info ] [MainThread]: 
[0m20:14:12.332242 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m20:14:12.333090 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m20:14:12.334120 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m20:14:12.334808 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m20:14:12.350923 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m20:14:12.352326 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m20:14:12.410374 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m20:14:12.411594 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:14:12.412330 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as WITH accounts as (
    `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)   as registration_date, 
  CAST(unlock_price                 AS FLOAT)       as unlock_price, 
  CAST(down_payment                 AS FLOAT)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT)       as daily_rate, 
FROM accounts;


[0m20:14:13.049776 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:d63f8d0c-a3a9-4867-8ce1-66404f4d1944&page=queryresults
[0m20:14:13.051082 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected identifier `steam-outlet-209412` at [7:5]; reason: invalidQuery, location: query, message: Syntax error: Unexpected identifier `steam-outlet-209412` at [7:5]')
[0m20:14:13.709778 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:881f5b9f-9509-411f-a331-2b5d4748c8e2&page=queryresults
[0m20:14:13.715962 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:881f5b9f-9509-411f-a331-2b5d4748c8e2&page=queryresults
[0m20:14:13.819967 [debug] [Thread-1  ]: Database Error in model cleaned_accounts (models/example/0_cleaning/cleaned_accounts.sql)
  Syntax error: Unexpected identifier `steam-outlet-209412` at [7:5]
  compiled code at target/run/creditrisk/models/example/0_cleaning/cleaned_accounts.sql
[0m20:14:13.831686 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05b84beb-7cfc-442a-b60d-6d0c31ced306', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8e10075b0>]}
[0m20:14:13.835693 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.cleaned_accounts ............. [[31mERROR[0m in 1.49s]
[0m20:14:13.839892 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m20:14:13.851107 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:14:13.852859 [debug] [MainThread]: Connection 'model.creditrisk.cleaned_accounts' was properly closed.
[0m20:14:13.856332 [info ] [MainThread]: 
[0m20:14:13.860869 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.89 seconds (5.89s).
[0m20:14:13.865527 [debug] [MainThread]: Command end result
[0m20:14:14.017957 [info ] [MainThread]: 
[0m20:14:14.036593 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:14:14.056754 [info ] [MainThread]: 
[0m20:14:14.059011 [error] [MainThread]:   Database Error in model cleaned_accounts (models/example/0_cleaning/cleaned_accounts.sql)
  Syntax error: Unexpected identifier `steam-outlet-209412` at [7:5]
  compiled code at target/run/creditrisk/models/example/0_cleaning/cleaned_accounts.sql
[0m20:14:14.078449 [info ] [MainThread]: 
[0m20:14:14.079818 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m20:14:14.081366 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 13.185333, "process_user_time": 6.85866, "process_kernel_time": 1.456666, "process_mem_max_rss": "229117952", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m20:14:14.083029 [debug] [MainThread]: Command `dbt run` failed at 20:14:14.082735 after 13.19 seconds
[0m20:14:14.083927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8daa32580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8e0b83910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8e10040a0>]}
[0m20:14:14.084742 [debug] [MainThread]: Flushing usage events
[0m20:15:25.214274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6aa24580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6cbfd430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6cbfde80>]}


============================== 20:15:25.219594 | 63984358-e7e3-431e-be71-91ca10404428 ==============================
[0m20:15:25.219594 [info ] [MainThread]: Running with dbt=1.8.8
[0m20:15:25.220589 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'empty': 'False', 'invocation_command': 'dbt run --select cleaned_accounts', 'profiles_dir': '/Users/david/.dbt', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'version_check': 'True', 'log_format': 'default', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'use_colors': 'True', 'quiet': 'False', 'partial_parse': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'no_print': 'None', 'static_parser': 'True', 'cache_selected_only': 'False', 'introspect': 'True', 'write_json': 'True'}
[0m20:15:29.556527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '63984358-e7e3-431e-be71-91ca10404428', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b7046dee0>]}
[0m20:15:29.630638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '63984358-e7e3-431e-be71-91ca10404428', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b703bfd30>]}
[0m20:15:29.631540 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m20:15:29.664455 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m20:15:29.992168 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:15:29.992749 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:15:30.074164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '63984358-e7e3-431e-be71-91ca10404428', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b7115eee0>]}
[0m20:15:30.294128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '63984358-e7e3-431e-be71-91ca10404428', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b7116e6d0>]}
[0m20:15:30.329697 [info ] [MainThread]: Found 3 models, 4 data tests, 2 seeds, 479 macros
[0m20:15:30.330378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '63984358-e7e3-431e-be71-91ca10404428', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b7116bb20>]}
[0m20:15:30.331984 [info ] [MainThread]: 
[0m20:15:30.332830 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:15:30.334177 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m20:15:30.334899 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:15:33.406895 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m20:15:33.408122 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:15:34.084830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '63984358-e7e3-431e-be71-91ca10404428', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b703fac70>]}
[0m20:15:34.085891 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:15:34.086456 [info ] [MainThread]: 
[0m20:15:34.090002 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m20:15:34.090835 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m20:15:34.091646 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m20:15:34.092304 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m20:15:34.116327 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m20:15:34.117721 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m20:15:34.163988 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m20:15:34.165177 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:15:34.166007 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)   as registration_date, 
  CAST(unlock_price                 AS FLOAT)       as unlock_price, 
  CAST(down_payment                 AS FLOAT)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT)       as daily_rate, 
FROM accounts;


[0m20:15:34.894904 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:aeb018c3-fed8-4b55-ade2-e589f547c8e0&page=queryresults
[0m20:15:35.234265 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Type not found: FLOAT at [13:40]; reason: invalidQuery, location: query, message: Type not found: FLOAT at [13:40]')
[0m20:15:36.988754 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b3ffc83a-e8b9-4ef7-b547-1f779fc54a1a&page=queryresults
[0m20:15:37.274464 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b3ffc83a-e8b9-4ef7-b547-1f779fc54a1a&page=queryresults
[0m20:15:37.289119 [debug] [Thread-1  ]: Database Error in model cleaned_accounts (models/example/0_cleaning/cleaned_accounts.sql)
  Type not found: FLOAT at [13:40]
  compiled code at target/run/creditrisk/models/example/0_cleaning/cleaned_accounts.sql
[0m20:15:37.291435 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '63984358-e7e3-431e-be71-91ca10404428', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b71813970>]}
[0m20:15:37.292470 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.cleaned_accounts ............. [[31mERROR[0m in 3.20s]
[0m20:15:37.294086 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m20:15:37.296242 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:15:37.296862 [debug] [MainThread]: Connection 'model.creditrisk.cleaned_accounts' was properly closed.
[0m20:15:37.297388 [info ] [MainThread]: 
[0m20:15:37.297992 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.96 seconds (6.96s).
[0m20:15:37.299566 [debug] [MainThread]: Command end result
[0m20:15:37.359437 [info ] [MainThread]: 
[0m20:15:37.360223 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:15:37.360740 [info ] [MainThread]: 
[0m20:15:37.361379 [error] [MainThread]:   Database Error in model cleaned_accounts (models/example/0_cleaning/cleaned_accounts.sql)
  Type not found: FLOAT at [13:40]
  compiled code at target/run/creditrisk/models/example/0_cleaning/cleaned_accounts.sql
[0m20:15:37.362182 [info ] [MainThread]: 
[0m20:15:37.362830 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m20:15:37.363770 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 12.247308, "process_user_time": 5.542869, "process_kernel_time": 1.025964, "process_mem_max_rss": "226476032", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m20:15:37.364868 [debug] [MainThread]: Command `dbt run` failed at 20:15:37.364684 after 12.25 seconds
[0m20:15:37.365623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6aa24580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6ad21d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b70e0bc70>]}
[0m20:15:37.366479 [debug] [MainThread]: Flushing usage events
[0m20:17:03.698509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d66a33520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d68938a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d68938340>]}


============================== 20:17:03.703824 | 5140bb9f-51c0-4b03-b4fa-6139912c30d3 ==============================
[0m20:17:03.703824 [info ] [MainThread]: Running with dbt=1.8.8
[0m20:17:03.705032 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'invocation_command': 'dbt run --select cleaned_accounts', 'log_cache_events': 'False', 'write_json': 'True', 'introspect': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/david/.dbt', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'quiet': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'partial_parse': 'True', 'log_format': 'default', 'use_colors': 'True', 'static_parser': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'target_path': 'None'}
[0m20:17:08.381129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5140bb9f-51c0-4b03-b4fa-6139912c30d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d6c596b20>]}
[0m20:17:08.479027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5140bb9f-51c0-4b03-b4fa-6139912c30d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d688f90d0>]}
[0m20:17:08.480015 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m20:17:08.509981 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m20:17:08.861685 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:17:08.862376 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:17:08.952156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5140bb9f-51c0-4b03-b4fa-6139912c30d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d6d160130>]}
[0m20:17:09.140624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5140bb9f-51c0-4b03-b4fa-6139912c30d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d6d16ea60>]}
[0m20:17:09.141616 [info ] [MainThread]: Found 4 models, 4 data tests, 2 seeds, 479 macros
[0m20:17:09.142293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5140bb9f-51c0-4b03-b4fa-6139912c30d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d6d12e370>]}
[0m20:17:09.144003 [info ] [MainThread]: 
[0m20:17:09.145039 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:17:09.146411 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m20:17:09.147593 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:17:12.220572 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m20:17:12.222048 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:17:12.811613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5140bb9f-51c0-4b03-b4fa-6139912c30d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d687cfa60>]}
[0m20:17:12.812706 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:17:12.813284 [info ] [MainThread]: 
[0m20:17:12.817392 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m20:17:12.818255 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m20:17:12.819274 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m20:17:12.820169 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m20:17:13.289581 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m20:17:13.291590 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m20:17:13.336560 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m20:17:13.337659 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:17:13.338366 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m20:17:14.172313 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:908d9746-48eb-4587-be12-1cd892cd3f23&page=queryresults
[0m20:17:14.895754 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5140bb9f-51c0-4b03-b4fa-6139912c30d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d67b76af0>]}
[0m20:17:14.896967 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.cleaned_accounts ................. [[32mCREATE VIEW (0 processed)[0m in 2.08s]
[0m20:17:14.899307 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m20:17:14.901559 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:17:14.902137 [debug] [MainThread]: Connection 'model.creditrisk.cleaned_accounts' was properly closed.
[0m20:17:14.902684 [info ] [MainThread]: 
[0m20:17:14.903237 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.76 seconds (5.76s).
[0m20:17:14.904584 [debug] [MainThread]: Command end result
[0m20:17:14.996488 [info ] [MainThread]: 
[0m20:17:14.997996 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:17:14.999186 [info ] [MainThread]: 
[0m20:17:15.000779 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m20:17:15.003993 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.415193, "process_user_time": 5.912645, "process_kernel_time": 1.107585, "process_mem_max_rss": "225361920", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m20:17:15.007789 [debug] [MainThread]: Command `dbt run` succeeded at 20:17:15.007257 after 11.42 seconds
[0m20:17:15.011391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d66a33520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d6cdcf190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d688f90d0>]}
[0m20:17:15.012809 [debug] [MainThread]: Flushing usage events
[0m20:17:38.961647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7112634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe713169d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe713169100>]}


============================== 20:17:38.968132 | d35efe3a-f8f6-4e02-9fe0-34fd8558c924 ==============================
[0m20:17:38.968132 [info ] [MainThread]: Running with dbt=1.8.8
[0m20:17:38.969223 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'no_print': 'None', 'debug': 'False', 'printer_width': '80', 'static_parser': 'True', 'partial_parse': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'write_json': 'True', 'version_check': 'True', 'target_path': 'None', 'fail_fast': 'False', 'log_format': 'default', 'quiet': 'False', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'invocation_command': 'dbt run --select 0_cleaning', 'warn_error': 'None', 'use_colors': 'True', 'introspect': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/david/.dbt'}
[0m20:17:43.731084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd35efe3a-f8f6-4e02-9fe0-34fd8558c924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe711529dc0>]}
[0m20:17:43.803027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd35efe3a-f8f6-4e02-9fe0-34fd8558c924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe716cd9a60>]}
[0m20:17:43.803931 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m20:17:43.835468 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m20:17:44.191893 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:17:44.192526 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:17:44.273556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd35efe3a-f8f6-4e02-9fe0-34fd8558c924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe717960130>]}
[0m20:17:44.458783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd35efe3a-f8f6-4e02-9fe0-34fd8558c924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7179865b0>]}
[0m20:17:44.459567 [info ] [MainThread]: Found 4 models, 4 data tests, 2 seeds, 479 macros
[0m20:17:44.460124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd35efe3a-f8f6-4e02-9fe0-34fd8558c924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe717929070>]}
[0m20:17:44.460991 [warn ] [MainThread]: The selection criterion '0_cleaning' does not match any enabled nodes
[0m20:17:44.462145 [info ] [MainThread]: 
[0m20:17:44.462688 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m20:17:44.465427 [debug] [MainThread]: Command end result
[0m20:17:44.508388 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.6463394, "process_user_time": 5.781468, "process_kernel_time": 1.029828, "process_mem_max_rss": "219955200", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m20:17:44.509494 [debug] [MainThread]: Command `dbt run` succeeded at 20:17:44.509306 after 5.65 seconds
[0m20:17:44.510141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7112634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7179296a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe716cd9a60>]}
[0m20:17:44.510720 [debug] [MainThread]: Flushing usage events
[0m20:22:40.162097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ac882f5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8accb7e280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8accb7ec40>]}


============================== 20:22:40.166846 | 22aa6c08-6638-40b5-98f5-c1750d95df41 ==============================
[0m20:22:40.166846 [info ] [MainThread]: Running with dbt=1.8.8
[0m20:22:40.167802 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run --select date_spine', 'debug': 'False', 'profiles_dir': '/Users/david/.dbt', 'use_colors': 'True', 'version_check': 'True', 'empty': 'False', 'introspect': 'True', 'no_print': 'None', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'cache_selected_only': 'False', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'target_path': 'None', 'log_format': 'default', 'log_cache_events': 'False', 'printer_width': '80', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'static_parser': 'True', 'warn_error': 'None'}
[0m20:22:44.003201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '22aa6c08-6638-40b5-98f5-c1750d95df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8accb29b50>]}
[0m20:22:44.060949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '22aa6c08-6638-40b5-98f5-c1750d95df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad0c155b0>]}
[0m20:22:44.061716 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m20:22:44.086269 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m20:22:44.340747 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:22:44.341224 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:22:44.406270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22aa6c08-6638-40b5-98f5-c1750d95df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad1160130>]}
[0m20:22:44.552136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22aa6c08-6638-40b5-98f5-c1750d95df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad115ed60>]}
[0m20:22:44.552748 [info ] [MainThread]: Found 5 models, 4 data tests, 2 seeds, 479 macros
[0m20:22:44.553175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22aa6c08-6638-40b5-98f5-c1750d95df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad11833a0>]}
[0m20:22:44.554551 [info ] [MainThread]: 
[0m20:22:44.555320 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:22:44.556322 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m20:22:44.556801 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:22:47.414101 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m20:22:47.415055 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:22:48.044974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22aa6c08-6638-40b5-98f5-c1750d95df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad0410040>]}
[0m20:22:48.046023 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:22:48.046594 [info ] [MainThread]: 
[0m20:22:48.050866 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m20:22:48.051779 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.date_spine ............................ [RUN]
[0m20:22:48.052662 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.date_spine)
[0m20:22:48.053378 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m20:22:48.076564 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m20:22:48.077671 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m20:22:48.124062 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m20:22:48.125288 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:22:48.126059 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`date_spine`
  OPTIONS()
  as WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

min_max_dates as (
    SELECT 
        CAST(MIN(registration_date) AS DATE) as min_date,
        CAST(MAX(registration_date) AS DATE) as max_date,
    FROM accounts
)

SELECT
    TIMESTAMP_ADD(
        (SELECT min_date FROM min_max_dates), 
        INTERVAL n DAY
    ) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            --'2021-12-31', 
            --'2015-01-01', -- Date the first account was 
            DAY
        )
    )
) AS n;


[0m20:22:49.239734 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:f4b562dd-5636-46d0-a4f5-b082ccb1bfcb&page=queryresults
[0m20:22:49.906069 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22aa6c08-6638-40b5-98f5-c1750d95df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad178a5e0>]}
[0m20:22:49.907095 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.date_spine ....................... [[32mCREATE VIEW (0 processed)[0m in 1.85s]
[0m20:22:49.908081 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m20:22:49.909648 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:22:49.910129 [debug] [MainThread]: Connection 'model.creditrisk.date_spine' was properly closed.
[0m20:22:49.910633 [info ] [MainThread]: 
[0m20:22:49.911176 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.36 seconds (5.36s).
[0m20:22:49.912323 [debug] [MainThread]: Command end result
[0m20:22:49.965204 [info ] [MainThread]: 
[0m20:22:49.966174 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:22:49.966724 [info ] [MainThread]: 
[0m20:22:49.967296 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m20:22:49.968110 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.891236, "process_user_time": 5.069089, "process_kernel_time": 0.841991, "process_mem_max_rss": "226533376", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m20:22:49.969012 [debug] [MainThread]: Command `dbt run` succeeded at 20:22:49.968858 after 9.89 seconds
[0m20:22:49.969630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ac882f5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ac8d832b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad0c155b0>]}
[0m20:22:49.970226 [debug] [MainThread]: Flushing usage events
[0m21:13:31.450754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0ee261520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f0269a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f0269340>]}


============================== 21:13:31.456596 | 13e42f03-64b7-45d0-9f83-8fc55cbb609a ==============================
[0m21:13:31.456596 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:13:31.457927 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'empty': 'False', 'use_colors': 'True', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/david/.dbt', 'version_check': 'True', 'printer_width': '80', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'debug': 'False', 'invocation_command': 'dbt run --select +accounts_history_beginner', 'use_experimental_parser': 'False', 'target_path': 'None', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'write_json': 'True', 'warn_error': 'None', 'static_parser': 'True'}
[0m21:13:36.497265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '13e42f03-64b7-45d0-9f83-8fc55cbb609a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f0243e20>]}
[0m21:13:36.584122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '13e42f03-64b7-45d0-9f83-8fc55cbb609a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f3bcbfa0>]}
[0m21:13:36.585189 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:13:36.629665 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:13:37.040385 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:13:37.041259 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:13:37.135645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '13e42f03-64b7-45d0-9f83-8fc55cbb609a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f486dfd0>]}
[0m21:13:37.341890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '13e42f03-64b7-45d0-9f83-8fc55cbb609a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f4878400>]}
[0m21:13:37.342747 [info ] [MainThread]: Found 7 models, 2 seeds, 4 data tests, 479 macros
[0m21:13:37.343334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '13e42f03-64b7-45d0-9f83-8fc55cbb609a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f4837250>]}
[0m21:13:37.345326 [info ] [MainThread]: 
[0m21:13:37.346354 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:13:37.354046 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:13:37.356122 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:13:40.915389 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:13:40.917758 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:13:41.523802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '13e42f03-64b7-45d0-9f83-8fc55cbb609a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f00ffa60>]}
[0m21:13:41.524822 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:13:41.525379 [info ] [MainThread]: 
[0m21:13:41.529677 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m21:13:41.530668 [info ] [Thread-1  ]: 1 of 4 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m21:13:41.531944 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m21:13:41.532664 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m21:13:41.549399 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m21:13:41.551297 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m21:13:41.598720 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m21:13:41.600103 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:13:41.600986 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m21:13:42.386486 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:a9fe0d47-5bb2-4205-800f-58720bd31d86&page=queryresults
[0m21:13:43.077162 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13e42f03-64b7-45d0-9f83-8fc55cbb609a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f44db610>]}
[0m21:13:43.078423 [info ] [Thread-1  ]: 1 of 4 OK created sql view model oscreditrisk.cleaned_accounts ................. [[32mCREATE VIEW (0 processed)[0m in 1.54s]
[0m21:13:43.079420 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m21:13:43.080147 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_payments
[0m21:13:43.081221 [info ] [Thread-1  ]: 2 of 4 START sql view model oscreditrisk.cleaned_payments ...................... [RUN]
[0m21:13:43.081989 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_accounts, now model.creditrisk.cleaned_payments)
[0m21:13:43.082572 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_payments
[0m21:13:43.087368 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_payments"
[0m21:13:43.088469 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_payments
[0m21:13:43.098450 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_payments"
[0m21:13:43.099787 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:13:43.100824 [debug] [Thread-1  ]: On model.creditrisk.cleaned_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_payments"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`
)

SELECT 
  account_id,
  CAST(down_payment             AS BOOLEAN)     as down_payment,
  CAST(payment_effective_date   AS TIMESTAMP)   as payment_effective_date,
  CAST(amount                   AS FLOAT)       as amount,
FROM payments;


[0m21:13:43.913072 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:15c5baec-722c-4490-a651-1b9fa82d234e&page=queryresults
[0m21:13:44.224666 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Type not found: FLOAT at [19:36]; reason: invalidQuery, location: query, message: Type not found: FLOAT at [19:36]')
[0m21:13:45.103051 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:05693c9d-4365-4cdf-8125-16fa8506e387&page=queryresults
[0m21:13:45.399788 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:05693c9d-4365-4cdf-8125-16fa8506e387&page=queryresults
[0m21:13:45.415196 [debug] [Thread-1  ]: Database Error in model cleaned_payments (models/example/0_cleaning/cleaned_payments.sql)
  Type not found: FLOAT at [19:36]
  compiled code at target/run/creditrisk/models/example/0_cleaning/cleaned_payments.sql
[0m21:13:45.416716 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13e42f03-64b7-45d0-9f83-8fc55cbb609a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f51692e0>]}
[0m21:13:45.417717 [error] [Thread-1  ]: 2 of 4 ERROR creating sql view model oscreditrisk.cleaned_payments ............. [[31mERROR[0m in 2.33s]
[0m21:13:45.418664 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_payments
[0m21:13:45.419366 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m21:13:45.420282 [info ] [Thread-1  ]: 3 of 4 START sql view model oscreditrisk.date_spine ............................ [RUN]
[0m21:13:45.421094 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_payments, now model.creditrisk.date_spine)
[0m21:13:45.421683 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m21:13:45.432248 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m21:13:45.433534 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m21:13:45.438884 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m21:13:45.440414 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:13:45.441282 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`date_spine`
  OPTIONS()
  as /*
    This transformations is generating a dataset containing one row for each day betwee : 
    - The first day you opened an account
    - Today. With artificial data here we consider today being the day after we received the last payment.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

min_max_dates as (
    SELECT 
        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,
        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,
    FROM payments
)

SELECT
    TIMESTAMP_ADD(
        (SELECT min_date FROM min_max_dates), 
        INTERVAL n DAY
    ) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            DAY
        )
    )
) AS n;


[0m21:13:46.182344 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:69bbdbb1-a4ef-4bec-b68f-a1413017418e&page=queryresults
[0m21:13:46.183240 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Table "payments" must be qualified with a dataset (e.g. dataset.table).; reason: invalid, location: payments, message: Table "payments" must be qualified with a dataset (e.g. dataset.table).')
[0m21:13:46.767470 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b6eceef4-7eb0-4c21-9fa9-73b4964ebb8f&page=queryresults
[0m21:13:46.774660 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b6eceef4-7eb0-4c21-9fa9-73b4964ebb8f&page=queryresults
[0m21:13:46.783277 [debug] [Thread-1  ]: Database Error in model date_spine (models/example/1_building_core_dataset/date_spine.sql)
  Table "payments" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/date_spine.sql
[0m21:13:46.784432 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13e42f03-64b7-45d0-9f83-8fc55cbb609a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f515ba30>]}
[0m21:13:46.786143 [error] [Thread-1  ]: 3 of 4 ERROR creating sql view model oscreditrisk.date_spine ................... [[31mERROR[0m in 1.36s]
[0m21:13:46.789240 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m21:13:46.790693 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m21:13:46.792810 [info ] [Thread-1  ]: 4 of 4 SKIP relation oscreditrisk.accounts_history_beginner .................... [[33mSKIP[0m]
[0m21:13:46.794101 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m21:13:46.806939 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:13:46.807885 [debug] [MainThread]: Connection 'model.creditrisk.date_spine' was properly closed.
[0m21:13:46.808892 [info ] [MainThread]: 
[0m21:13:46.809805 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 9.46 seconds (9.46s).
[0m21:13:46.812788 [debug] [MainThread]: Command end result
[0m21:13:46.878599 [info ] [MainThread]: 
[0m21:13:46.879739 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m21:13:46.880549 [info ] [MainThread]: 
[0m21:13:46.881262 [error] [MainThread]:   Database Error in model cleaned_payments (models/example/0_cleaning/cleaned_payments.sql)
  Type not found: FLOAT at [19:36]
  compiled code at target/run/creditrisk/models/example/0_cleaning/cleaned_payments.sql
[0m21:13:46.881787 [info ] [MainThread]: 
[0m21:13:46.882404 [error] [MainThread]:   Database Error in model date_spine (models/example/1_building_core_dataset/date_spine.sql)
  Table "payments" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/date_spine.sql
[0m21:13:46.883041 [info ] [MainThread]: 
[0m21:13:46.883817 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=2 SKIP=1 TOTAL=4
[0m21:13:46.885873 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 15.567249, "process_user_time": 6.101297, "process_kernel_time": 1.24545, "process_mem_max_rss": "226893824", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:13:46.887059 [debug] [MainThread]: Command `dbt run` failed at 21:13:46.886737 after 15.57 seconds
[0m21:13:46.887732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0ee261520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0ee686670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0f44c4250>]}
[0m21:13:46.888333 [debug] [MainThread]: Flushing usage events
[0m21:14:24.305677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9361a2f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9364270d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93642703d0>]}


============================== 21:14:24.310211 | 1dac4ae7-22c2-4aa6-b337-f4582cc0154e ==============================
[0m21:14:24.310211 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:14:24.311169 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'static_parser': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/david/.dbt', 'log_format': 'default', 'target_path': 'None', 'write_json': 'True', 'quiet': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'invocation_command': 'dbt run --select +accounts_history_beginner', 'printer_width': '80', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'use_colors': 'True', 'log_cache_events': 'False', 'empty': 'False', 'version_check': 'True', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True'}
[0m21:14:28.158397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1dac4ae7-22c2-4aa6-b337-f4582cc0154e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9367dc1eb0>]}
[0m21:14:28.230919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1dac4ae7-22c2-4aa6-b337-f4582cc0154e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93683fa7c0>]}
[0m21:14:28.231874 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:14:28.263835 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:14:28.604125 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:14:28.604692 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:14:28.686557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1dac4ae7-22c2-4aa6-b337-f4582cc0154e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f936896deb0>]}
[0m21:14:28.877680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1dac4ae7-22c2-4aa6-b337-f4582cc0154e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9368995790>]}
[0m21:14:28.878522 [info ] [MainThread]: Found 7 models, 2 seeds, 4 data tests, 479 macros
[0m21:14:28.879084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1dac4ae7-22c2-4aa6-b337-f4582cc0154e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9368933e20>]}
[0m21:14:28.881457 [info ] [MainThread]: 
[0m21:14:28.882763 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:14:28.889654 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:14:28.890337 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:14:31.738194 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:14:31.739178 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:32.449957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1dac4ae7-22c2-4aa6-b337-f4582cc0154e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9367e09610>]}
[0m21:14:32.451130 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:14:32.451780 [info ] [MainThread]: 
[0m21:14:32.455679 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m21:14:32.456507 [info ] [Thread-1  ]: 1 of 4 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m21:14:32.457321 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m21:14:32.457993 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m21:14:32.479059 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m21:14:32.480569 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m21:14:32.527176 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m21:14:32.528323 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:14:32.529079 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m21:14:33.372815 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:939a4b6e-3855-4b5c-bbfc-bd57d521116a&page=queryresults
[0m21:14:34.073585 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1dac4ae7-22c2-4aa6-b337-f4582cc0154e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93689770a0>]}
[0m21:14:34.074713 [info ] [Thread-1  ]: 1 of 4 OK created sql view model oscreditrisk.cleaned_accounts ................. [[32mCREATE VIEW (0 processed)[0m in 1.61s]
[0m21:14:34.075762 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m21:14:34.076515 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_payments
[0m21:14:34.077284 [info ] [Thread-1  ]: 2 of 4 START sql view model oscreditrisk.cleaned_payments ...................... [RUN]
[0m21:14:34.078206 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_accounts, now model.creditrisk.cleaned_payments)
[0m21:14:34.078938 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_payments
[0m21:14:34.084378 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_payments"
[0m21:14:34.085557 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_payments
[0m21:14:34.097653 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_payments"
[0m21:14:34.098994 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:14:34.099777 [debug] [Thread-1  ]: On model.creditrisk.cleaned_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_payments"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`
)

SELECT 
  account_id,
  CAST(down_payment             AS BOOLEAN)         as down_payment,
  CAST(payment_effective_date   AS TIMESTAMP)       as payment_effective_date,
  CAST(amount                   AS FLOAT64)         as amount,
FROM payments;


[0m21:14:35.081319 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:79c2c211-b250-4fd7-8efc-0e24947e5b1d&page=queryresults
[0m21:14:35.724479 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1dac4ae7-22c2-4aa6-b337-f4582cc0154e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f936898db20>]}
[0m21:14:35.725445 [info ] [Thread-1  ]: 2 of 4 OK created sql view model oscreditrisk.cleaned_payments ................. [[32mCREATE VIEW (0 processed)[0m in 1.65s]
[0m21:14:35.726480 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_payments
[0m21:14:35.727200 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m21:14:35.728065 [info ] [Thread-1  ]: 3 of 4 START sql view model oscreditrisk.date_spine ............................ [RUN]
[0m21:14:35.728786 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_payments, now model.creditrisk.date_spine)
[0m21:14:35.729357 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m21:14:35.735882 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m21:14:35.737512 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m21:14:35.742897 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m21:14:35.744317 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:14:35.745227 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`date_spine`
  OPTIONS()
  as /*
    This transformations is generating a dataset containing one row for each day betwee : 
    - The first day you opened an account
    - Today. With artificial data here we consider today being the day after we received the last payment.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

min_max_dates as (
    SELECT 
        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,
        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,
    FROM payments
)

SELECT
    TIMESTAMP_ADD(
        (SELECT min_date FROM min_max_dates), 
        INTERVAL n DAY
    ) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            DAY
        )
    )
) AS n;


[0m21:14:36.347554 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b6b5d862-b1a3-42fe-9ff0-d515e3a6258f&page=queryresults
[0m21:14:36.348464 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Table "payments" must be qualified with a dataset (e.g. dataset.table).; reason: invalid, location: payments, message: Table "payments" must be qualified with a dataset (e.g. dataset.table).')
[0m21:14:37.630818 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ce03c73d-a276-4e74-9cd8-3783e963c647&page=queryresults
[0m21:14:37.631732 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ce03c73d-a276-4e74-9cd8-3783e963c647&page=queryresults
[0m21:14:37.645483 [debug] [Thread-1  ]: Database Error in model date_spine (models/example/1_building_core_dataset/date_spine.sql)
  Table "payments" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/date_spine.sql
[0m21:14:37.646400 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1dac4ae7-22c2-4aa6-b337-f4582cc0154e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f936898da30>]}
[0m21:14:37.647437 [error] [Thread-1  ]: 3 of 4 ERROR creating sql view model oscreditrisk.date_spine ................... [[31mERROR[0m in 1.92s]
[0m21:14:37.648504 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m21:14:37.649938 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m21:14:37.650757 [info ] [Thread-1  ]: 4 of 4 SKIP relation oscreditrisk.accounts_history_beginner .................... [[33mSKIP[0m]
[0m21:14:37.651628 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m21:14:37.653565 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:14:37.654188 [debug] [MainThread]: Connection 'model.creditrisk.date_spine' was properly closed.
[0m21:14:37.654953 [info ] [MainThread]: 
[0m21:14:37.655612 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 8.77 seconds (8.77s).
[0m21:14:37.657245 [debug] [MainThread]: Command end result
[0m21:14:37.714811 [info ] [MainThread]: 
[0m21:14:37.715772 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:14:37.716678 [info ] [MainThread]: 
[0m21:14:37.717567 [error] [MainThread]:   Database Error in model date_spine (models/example/1_building_core_dataset/date_spine.sql)
  Table "payments" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/date_spine.sql
[0m21:14:37.718179 [info ] [MainThread]: 
[0m21:14:37.718779 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=1 TOTAL=4
[0m21:14:37.719669 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 13.505355, "process_user_time": 5.627665, "process_kernel_time": 0.943223, "process_mem_max_rss": "228356096", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:14:37.720872 [debug] [MainThread]: Command `dbt run` failed at 21:14:37.720553 after 13.51 seconds
[0m21:14:37.721722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9361a2f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9361d5b8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93683fa7c0>]}
[0m21:14:37.722490 [debug] [MainThread]: Flushing usage events
[0m21:14:58.873009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabea260550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabec271d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabec271400>]}


============================== 21:14:58.878071 | 6f84cee4-8c8a-4586-bba9-3ceee2d62edc ==============================
[0m21:14:58.878071 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:14:58.879159 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'cache_selected_only': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select +accounts_history_beginner', 'profiles_dir': '/Users/david/.dbt', 'version_check': 'True', 'log_cache_events': 'False', 'target_path': 'None', 'no_print': 'None', 'introspect': 'True', 'debug': 'False', 'use_colors': 'True', 'log_format': 'default', 'static_parser': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'partial_parse': 'True', 'quiet': 'False', 'warn_error': 'None', 'indirect_selection': 'eager'}
[0m21:15:02.904811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f84cee4-8c8a-4586-bba9-3ceee2d62edc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabefccca90>]}
[0m21:15:03.001396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6f84cee4-8c8a-4586-bba9-3ceee2d62edc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf059d250>]}
[0m21:15:03.002370 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:15:03.038856 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:15:03.413332 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:15:03.413941 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:15:03.505456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6f84cee4-8c8a-4586-bba9-3ceee2d62edc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf096dee0>]}
[0m21:15:03.711186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6f84cee4-8c8a-4586-bba9-3ceee2d62edc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf096ea30>]}
[0m21:15:03.712037 [info ] [MainThread]: Found 7 models, 2 seeds, 4 data tests, 479 macros
[0m21:15:03.713012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f84cee4-8c8a-4586-bba9-3ceee2d62edc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf091a5b0>]}
[0m21:15:03.717568 [info ] [MainThread]: 
[0m21:15:03.719058 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:15:03.728572 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:15:03.729492 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:15:06.988416 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:15:06.990159 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:15:07.672636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f84cee4-8c8a-4586-bba9-3ceee2d62edc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf05d1c10>]}
[0m21:15:07.673766 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:15:07.674451 [info ] [MainThread]: 
[0m21:15:07.679576 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m21:15:07.680561 [info ] [Thread-1  ]: 1 of 4 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m21:15:07.681496 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m21:15:07.682190 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m21:15:07.701711 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m21:15:07.703041 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m21:15:07.749726 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m21:15:07.751023 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:15:07.751893 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m21:15:08.455237 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:0738fc85-ee8b-449d-a063-027ea846ec0e&page=queryresults
[0m21:15:09.078965 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f84cee4-8c8a-4586-bba9-3ceee2d62edc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf096ecd0>]}
[0m21:15:09.080039 [info ] [Thread-1  ]: 1 of 4 OK created sql view model oscreditrisk.cleaned_accounts ................. [[32mCREATE VIEW (0 processed)[0m in 1.40s]
[0m21:15:09.081140 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m21:15:09.081905 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_payments
[0m21:15:09.082803 [info ] [Thread-1  ]: 2 of 4 START sql view model oscreditrisk.cleaned_payments ...................... [RUN]
[0m21:15:09.083548 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_accounts, now model.creditrisk.cleaned_payments)
[0m21:15:09.084129 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_payments
[0m21:15:09.089421 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_payments"
[0m21:15:09.090645 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_payments
[0m21:15:09.101735 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_payments"
[0m21:15:09.102827 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:15:09.103543 [debug] [Thread-1  ]: On model.creditrisk.cleaned_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_payments"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`
)

SELECT 
  account_id,
  CAST(down_payment             AS BOOLEAN)         as down_payment,
  CAST(payment_effective_date   AS TIMESTAMP)       as payment_effective_date,
  CAST(amount                   AS FLOAT64)         as amount,
FROM payments;


[0m21:15:09.927593 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:f65eb667-e4a5-4d37-a02a-742baf68bb39&page=queryresults
[0m21:15:10.605885 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f84cee4-8c8a-4586-bba9-3ceee2d62edc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf122c760>]}
[0m21:15:10.606815 [info ] [Thread-1  ]: 2 of 4 OK created sql view model oscreditrisk.cleaned_payments ................. [[32mCREATE VIEW (0 processed)[0m in 1.52s]
[0m21:15:10.607779 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_payments
[0m21:15:10.608958 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m21:15:10.609799 [info ] [Thread-1  ]: 3 of 4 START sql view model oscreditrisk.date_spine ............................ [RUN]
[0m21:15:10.610505 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_payments, now model.creditrisk.date_spine)
[0m21:15:10.611147 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m21:15:10.617452 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m21:15:10.618940 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m21:15:10.623877 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m21:15:10.624983 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:15:10.625726 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`date_spine`
  OPTIONS()
  as /*
    This transformations is generating a dataset containing one row for each day betwee : 
    - The first day you opened an account
    - Today. With artificial data here we consider today being the day after we received the last payment.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

min_max_dates as (
    SELECT 
        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,
        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,
    FROM payments
)

SELECT
    TIMESTAMP_ADD(
        (SELECT min_date FROM min_max_dates), 
        INTERVAL n DAY
    ) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            DAY
        )
    )
) AS n;


[0m21:15:11.564193 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:47b9c2cb-5228-49d2-b9cc-bd0d433126e1&page=queryresults
[0m21:15:12.386299 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f84cee4-8c8a-4586-bba9-3ceee2d62edc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf1261760>]}
[0m21:15:12.387466 [info ] [Thread-1  ]: 3 of 4 OK created sql view model oscreditrisk.date_spine ....................... [[32mCREATE VIEW (0 processed)[0m in 1.78s]
[0m21:15:12.388537 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m21:15:12.389728 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m21:15:12.390638 [info ] [Thread-1  ]: 4 of 4 START sql view model oscreditrisk.accounts_history_beginner ............. [RUN]
[0m21:15:12.391497 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.date_spine, now model.creditrisk.accounts_history_beginner)
[0m21:15:12.392113 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_beginner
[0m21:15:12.401655 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_beginner"
[0m21:15:12.402816 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_beginner
[0m21:15:12.408236 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_beginner"
[0m21:15:12.409406 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:15:12.411086 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_beginner"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
  OPTIONS()
  as /*
    This transformations is generating the first version of the core dataset (beginner version). 
    It is essentially : 
    - Joining the accounts dataset with a date spine for the target granuarity
    - Grouping the payment by day, and joining them to the accounts history
    - Calculating cumulated sums to describe the cumulated amount paid, and a few other useful fields
*/

WITH accounts as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

payments as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

date_spine as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

accounts_with_spine as (
  SELECT 
    *,
    TIMESTAMP_DIFF(reporting_date, registration_date, DAY) + 1 as reporting_day,
  FROM accounts
  LEFT JOIN date_spine
  ON accounts.registration_date <= date_spine.reporting_date
),

payments_grouped_by_day as (
  SELECT 
    account_id,
    
    DATE_ADD(
      DATE_TRUNC(payment_effective_date, DAY), 
      INTERVAL 1 DAY
    ) as reporting_date,

    SUM(amount) as amount,
    SUM(
      IF(not down_payment, amount, 0)
    ) as amount_excl_dp,

  FROM payments
  GROUP BY ALL
),

joint as (
  SELECT 
    * EXCEPT(amount, amount_excl_dp),
    COALESCE(amount,          0) as amount,
    COALESCE(amount_excl_dp,  0) as amount_excl_dp,
  FROM accounts_with_spine 
  LEFT JOIN payments_grouped_by_day 
  USING(account_id, reporting_date)
),

calc_paid_total as (
  SELECT 
    *,
    SUM(amount)         OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total,
    SUM(amount_excl_dp) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_excl_dp,
    
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate) + down_payment_days_included as nominal_term,
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate)                              as nominal_term_excl_dp,
  FROM joint
)

SELECT * FROM calc_paid_total;


[0m21:15:13.409403 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:d1a97aa5-8dfa-4b98-bc83-14cc3a1fe767&page=queryresults
[0m21:15:13.820896 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('No matching signature for operator <= for argument types: TIMESTAMP, DATETIME\n  Signature: T1 <= T1\n    Unable to find common supertype for templated argument <T1>\n      Input types for <T1>: {TIMESTAMP, DATETIME} at [32:6]; reason: invalidQuery, location: query, message: No matching signature for operator <= for argument types: TIMESTAMP, DATETIME\n  Signature: T1 <= T1\n    Unable to find common supertype for templated argument <T1>\n      Input types for <T1>: {TIMESTAMP, DATETIME} at [32:6]')
[0m21:15:14.943651 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:6bebf356-59d0-4855-8382-cf9b9673856f&page=queryresults
[0m21:15:15.359242 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:6bebf356-59d0-4855-8382-cf9b9673856f&page=queryresults
[0m21:15:15.375075 [debug] [Thread-1  ]: Database Error in model accounts_history_beginner (models/example/1_building_core_dataset/accounts_history_beginner.sql)
  No matching signature for operator <= for argument types: TIMESTAMP, DATETIME
    Signature: T1 <= T1
      Unable to find common supertype for templated argument <T1>
        Input types for <T1>: {TIMESTAMP, DATETIME} at [32:6]
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/accounts_history_beginner.sql
[0m21:15:15.375944 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f84cee4-8c8a-4586-bba9-3ceee2d62edc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf12d6d30>]}
[0m21:15:15.377061 [error] [Thread-1  ]: 4 of 4 ERROR creating sql view model oscreditrisk.accounts_history_beginner .... [[31mERROR[0m in 2.98s]
[0m21:15:15.378116 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m21:15:15.380151 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:15:15.380702 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_beginner' was properly closed.
[0m21:15:15.381406 [info ] [MainThread]: 
[0m21:15:15.382022 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 11.66 seconds (11.66s).
[0m21:15:15.384496 [debug] [MainThread]: Command end result
[0m21:15:15.441533 [info ] [MainThread]: 
[0m21:15:15.442316 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:15:15.442844 [info ] [MainThread]: 
[0m21:15:15.443640 [error] [MainThread]:   Database Error in model accounts_history_beginner (models/example/1_building_core_dataset/accounts_history_beginner.sql)
  No matching signature for operator <= for argument types: TIMESTAMP, DATETIME
    Signature: T1 <= T1
      Unable to find common supertype for templated argument <T1>
        Input types for <T1>: {TIMESTAMP, DATETIME} at [32:6]
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/accounts_history_beginner.sql
[0m21:15:15.444374 [info ] [MainThread]: 
[0m21:15:15.445138 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m21:15:15.446005 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 16.677156, "process_user_time": 5.992553, "process_kernel_time": 1.042533, "process_mem_max_rss": "228065280", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:15:15.446933 [debug] [MainThread]: Command `dbt run` failed at 21:15:15.446758 after 16.68 seconds
[0m21:15:15.447570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabea260550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabec1fa8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabea47e4c0>]}
[0m21:15:15.448241 [debug] [MainThread]: Flushing usage events
[0m21:16:01.664271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5362634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53820bd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53820b100>]}


============================== 21:16:01.670615 | 6c3065b7-4325-4932-aef7-1752f7a56a00 ==============================
[0m21:16:01.670615 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:16:01.672221 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'use_colors': 'True', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'quiet': 'False', 'partial_parse': 'True', 'empty': 'False', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'printer_width': '80', 'warn_error': 'None', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'profiles_dir': '/Users/david/.dbt', 'invocation_command': 'dbt run --select 1+accounts_history_beginner', 'introspect': 'True', 'log_format': 'default'}
[0m21:16:05.542271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6c3065b7-4325-4932-aef7-1752f7a56a00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb536429dc0>]}
[0m21:16:05.619901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6c3065b7-4325-4932-aef7-1752f7a56a00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5381da460>]}
[0m21:16:05.620971 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:16:05.653765 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:16:06.046905 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:16:06.047499 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:16:06.134316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c3065b7-4325-4932-aef7-1752f7a56a00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53c72deb0>]}
[0m21:16:06.335771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c3065b7-4325-4932-aef7-1752f7a56a00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53c755a00>]}
[0m21:16:06.336822 [info ] [MainThread]: Found 7 models, 2 seeds, 4 data tests, 479 macros
[0m21:16:06.337413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c3065b7-4325-4932-aef7-1752f7a56a00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53c6da310>]}
[0m21:16:06.339300 [info ] [MainThread]: 
[0m21:16:06.340181 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:16:06.348273 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:16:06.349022 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:16:09.324209 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:16:09.324963 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:16:09.901643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c3065b7-4325-4932-aef7-1752f7a56a00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53c505c10>]}
[0m21:16:09.902513 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:16:09.902998 [info ] [MainThread]: 
[0m21:16:09.905781 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m21:16:09.906477 [info ] [Thread-1  ]: 1 of 4 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m21:16:09.907055 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m21:16:09.907506 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m21:16:09.921661 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m21:16:09.922590 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m21:16:09.958411 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m21:16:09.959417 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:16:09.960041 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m21:16:10.709815 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:24e1f89f-09f8-4ad0-bcae-ad232fded982&page=queryresults
[0m21:16:11.706716 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c3065b7-4325-4932-aef7-1752f7a56a00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53c755dc0>]}
[0m21:16:11.708137 [info ] [Thread-1  ]: 1 of 4 OK created sql view model oscreditrisk.cleaned_accounts ................. [[32mCREATE VIEW (0 processed)[0m in 1.80s]
[0m21:16:11.709531 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m21:16:11.710511 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_payments
[0m21:16:11.712675 [info ] [Thread-1  ]: 2 of 4 START sql view model oscreditrisk.cleaned_payments ...................... [RUN]
[0m21:16:11.715753 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_accounts, now model.creditrisk.cleaned_payments)
[0m21:16:11.716524 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_payments
[0m21:16:11.723226 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_payments"
[0m21:16:11.724499 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_payments
[0m21:16:11.739166 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_payments"
[0m21:16:11.740741 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:16:11.741613 [debug] [Thread-1  ]: On model.creditrisk.cleaned_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_payments"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`
)

SELECT 
  account_id,
  CAST(down_payment             AS BOOLEAN)         as down_payment,
  CAST(payment_effective_date   AS TIMESTAMP)       as payment_effective_date,
  CAST(amount                   AS FLOAT64)         as amount,
FROM payments;


[0m21:16:12.451861 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:e79236c9-289d-4889-b588-34fd5bab88d9&page=queryresults
[0m21:16:13.015951 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c3065b7-4325-4932-aef7-1752f7a56a00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53c7563a0>]}
[0m21:16:13.016914 [info ] [Thread-1  ]: 2 of 4 OK created sql view model oscreditrisk.cleaned_payments ................. [[32mCREATE VIEW (0 processed)[0m in 1.30s]
[0m21:16:13.017880 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_payments
[0m21:16:13.019022 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m21:16:13.019821 [info ] [Thread-1  ]: 3 of 4 START sql view model oscreditrisk.date_spine ............................ [RUN]
[0m21:16:13.020764 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_payments, now model.creditrisk.date_spine)
[0m21:16:13.021354 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m21:16:13.028067 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m21:16:13.029545 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m21:16:13.034640 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m21:16:13.036003 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:16:13.036928 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`date_spine`
  OPTIONS()
  as /*
    This transformations is generating a dataset containing one row for each day betwee : 
    - The first day you opened an account
    - Today. With artificial data here we consider today being the day after we received the last payment.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

min_max_dates as (
    SELECT 
        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,
        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,
    FROM payments
)

SELECT
    CAST(
        TIMESTAMP_ADD(
            (SELECT min_date FROM min_max_dates), 
            INTERVAL n DAY
        ) 
    ) AS TIMESTAMP) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            DAY
        )
    )
) AS n;


[0m21:16:13.721095 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b849c29e-045c-40af-aaca-f2db0e169978&page=queryresults
[0m21:16:13.722006 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Expected keyword AS but got ")" at [29:5]; reason: invalidQuery, location: query, message: Syntax error: Expected keyword AS but got ")" at [29:5]')
[0m21:16:14.729857 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:d3a72700-e7cc-4b64-ad3f-d5b4634f51f6&page=queryresults
[0m21:16:14.734815 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:d3a72700-e7cc-4b64-ad3f-d5b4634f51f6&page=queryresults
[0m21:16:14.769279 [debug] [Thread-1  ]: Database Error in model date_spine (models/example/1_building_core_dataset/date_spine.sql)
  Syntax error: Expected keyword AS but got ")" at [29:5]
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/date_spine.sql
[0m21:16:14.774094 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c3065b7-4325-4932-aef7-1752f7a56a00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53cd79df0>]}
[0m21:16:14.775183 [error] [Thread-1  ]: 3 of 4 ERROR creating sql view model oscreditrisk.date_spine ................... [[31mERROR[0m in 1.75s]
[0m21:16:14.776127 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m21:16:14.777329 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m21:16:14.779282 [info ] [Thread-1  ]: 4 of 4 SKIP relation oscreditrisk.accounts_history_beginner .................... [[33mSKIP[0m]
[0m21:16:14.780840 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m21:16:14.782688 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:16:14.783331 [debug] [MainThread]: Connection 'model.creditrisk.date_spine' was properly closed.
[0m21:16:14.784043 [info ] [MainThread]: 
[0m21:16:14.784711 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 8.44 seconds (8.44s).
[0m21:16:14.786791 [debug] [MainThread]: Command end result
[0m21:16:14.848530 [info ] [MainThread]: 
[0m21:16:14.849290 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:16:14.849822 [info ] [MainThread]: 
[0m21:16:14.850483 [error] [MainThread]:   Database Error in model date_spine (models/example/1_building_core_dataset/date_spine.sql)
  Syntax error: Expected keyword AS but got ")" at [29:5]
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/date_spine.sql
[0m21:16:14.851006 [info ] [MainThread]: 
[0m21:16:14.851561 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=1 TOTAL=4
[0m21:16:14.852490 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 13.287373, "process_user_time": 5.920819, "process_kernel_time": 1.012876, "process_mem_max_rss": "228106240", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:16:14.853522 [debug] [MainThread]: Command `dbt run` failed at 21:16:14.853345 after 13.29 seconds
[0m21:16:14.854169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5362634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53bae6ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53c755ac0>]}
[0m21:16:14.854766 [debug] [MainThread]: Flushing usage events
[0m21:16:35.113778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f814f260580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8151269be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8151269190>]}


============================== 21:16:35.118657 | b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9 ==============================
[0m21:16:35.118657 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:16:35.119761 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'printer_width': '80', 'fail_fast': 'False', 'invocation_command': 'dbt run --select 1+accounts_history_beginner', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error': 'None', 'empty': 'False', 'indirect_selection': 'eager', 'no_print': 'None', 'profiles_dir': '/Users/david/.dbt', 'write_json': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'quiet': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m21:16:38.509496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815551f4f0>]}
[0m21:16:38.586810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81554d7ca0>]}
[0m21:16:38.587768 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:16:38.618816 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:16:38.954018 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:16:38.954598 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:16:39.033852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8155a6deb0>]}
[0m21:16:39.198688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8155a95b50>]}
[0m21:16:39.199458 [info ] [MainThread]: Found 7 models, 2 seeds, 4 data tests, 479 macros
[0m21:16:39.200056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8155a1a190>]}
[0m21:16:39.201893 [info ] [MainThread]: 
[0m21:16:39.202685 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:16:39.209418 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:16:39.210145 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:16:41.814326 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:16:41.815236 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:16:42.384320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f814f5649a0>]}
[0m21:16:42.385375 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:16:42.385956 [info ] [MainThread]: 
[0m21:16:42.388997 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m21:16:42.389834 [info ] [Thread-1  ]: 1 of 4 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m21:16:42.390575 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m21:16:42.391171 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m21:16:42.408028 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m21:16:42.409189 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m21:16:42.455210 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m21:16:42.456374 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:16:42.457111 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m21:16:43.316083 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:7220e4ba-bee0-4a9b-9473-3b1102021997&page=queryresults
[0m21:16:44.024541 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815560a820>]}
[0m21:16:44.025578 [info ] [Thread-1  ]: 1 of 4 OK created sql view model oscreditrisk.cleaned_accounts ................. [[32mCREATE VIEW (0 processed)[0m in 1.63s]
[0m21:16:44.026583 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m21:16:44.027305 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_payments
[0m21:16:44.028168 [info ] [Thread-1  ]: 2 of 4 START sql view model oscreditrisk.cleaned_payments ...................... [RUN]
[0m21:16:44.028895 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_accounts, now model.creditrisk.cleaned_payments)
[0m21:16:44.029516 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_payments
[0m21:16:44.033994 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_payments"
[0m21:16:44.035162 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_payments
[0m21:16:44.045160 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_payments"
[0m21:16:44.046804 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:16:44.048283 [debug] [Thread-1  ]: On model.creditrisk.cleaned_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_payments"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`
)

SELECT 
  account_id,
  CAST(down_payment             AS BOOLEAN)         as down_payment,
  CAST(payment_effective_date   AS TIMESTAMP)       as payment_effective_date,
  CAST(amount                   AS FLOAT64)         as amount,
FROM payments;


[0m21:16:44.856663 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:102b5e24-b3d2-43f8-a8a7-2fc3414b5fc8&page=queryresults
[0m21:16:45.454657 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8155a8d1f0>]}
[0m21:16:45.455614 [info ] [Thread-1  ]: 2 of 4 OK created sql view model oscreditrisk.cleaned_payments ................. [[32mCREATE VIEW (0 processed)[0m in 1.43s]
[0m21:16:45.456570 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_payments
[0m21:16:45.457698 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m21:16:45.458504 [info ] [Thread-1  ]: 3 of 4 START sql view model oscreditrisk.date_spine ............................ [RUN]
[0m21:16:45.459353 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_payments, now model.creditrisk.date_spine)
[0m21:16:45.460110 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m21:16:45.467983 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m21:16:45.469053 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m21:16:45.473645 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m21:16:45.474711 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:16:45.475448 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`date_spine`
  OPTIONS()
  as /*
    This transformations is generating a dataset containing one row for each day betwee : 
    - The first day you opened an account
    - Today. With artificial data here we consider today being the day after we received the last payment.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

min_max_dates as (
    SELECT 
        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,
        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,
    FROM payments
)

SELECT
    CAST(
        TIMESTAMP_ADD(
            (SELECT min_date FROM min_max_dates), 
            INTERVAL n DAY
        ) AS TIMESTAMP
    ) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            DAY
        )
    )
) AS n;


[0m21:16:46.442733 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:e9769b09-ce3e-47fd-83ef-865637b0c47f&page=queryresults
[0m21:16:47.106200 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8156354430>]}
[0m21:16:47.107139 [info ] [Thread-1  ]: 3 of 4 OK created sql view model oscreditrisk.date_spine ....................... [[32mCREATE VIEW (0 processed)[0m in 1.65s]
[0m21:16:47.108151 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m21:16:47.109248 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m21:16:47.110055 [info ] [Thread-1  ]: 4 of 4 START sql view model oscreditrisk.accounts_history_beginner ............. [RUN]
[0m21:16:47.110745 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.date_spine, now model.creditrisk.accounts_history_beginner)
[0m21:16:47.111313 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_beginner
[0m21:16:47.118910 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_beginner"
[0m21:16:47.120724 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_beginner
[0m21:16:47.125416 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_beginner"
[0m21:16:47.126489 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:16:47.127273 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_beginner"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
  OPTIONS()
  as /*
    This transformations is generating the first version of the core dataset (beginner version). 
    It is essentially : 
    - Joining the accounts dataset with a date spine for the target granuarity
    - Grouping the payment by day, and joining them to the accounts history
    - Calculating cumulated sums to describe the cumulated amount paid, and a few other useful fields
*/

WITH accounts as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

payments as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

date_spine as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

accounts_with_spine as (
  SELECT 
    *,
    TIMESTAMP_DIFF(reporting_date, registration_date, DAY) + 1 as reporting_day,
  FROM accounts
  LEFT JOIN date_spine
  ON accounts.registration_date <= date_spine.reporting_date
),

payments_grouped_by_day as (
  SELECT 
    account_id,
    
    DATE_ADD(
      DATE_TRUNC(payment_effective_date, DAY), 
      INTERVAL 1 DAY
    ) as reporting_date,

    SUM(amount) as amount,
    SUM(
      IF(not down_payment, amount, 0)
    ) as amount_excl_dp,

  FROM payments
  GROUP BY ALL
),

joint as (
  SELECT 
    * EXCEPT(amount, amount_excl_dp),
    COALESCE(amount,          0) as amount,
    COALESCE(amount_excl_dp,  0) as amount_excl_dp,
  FROM accounts_with_spine 
  LEFT JOIN payments_grouped_by_day 
  USING(account_id, reporting_date)
),

calc_paid_total as (
  SELECT 
    *,
    SUM(amount)         OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total,
    SUM(amount_excl_dp) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_excl_dp,
    
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate) + down_payment_days_included as nominal_term,
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate)                              as nominal_term_excl_dp,
  FROM joint
)

SELECT * FROM calc_paid_total;


[0m21:16:48.129332 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:c9b1a1fa-0436-4394-a30e-fa020a5a1183&page=queryresults
[0m21:16:48.793201 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b105aa3f-b3b8-4d18-a4f4-f8681e7c68f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81560b2670>]}
[0m21:16:48.794169 [info ] [Thread-1  ]: 4 of 4 OK created sql view model oscreditrisk.accounts_history_beginner ........ [[32mCREATE VIEW (0 processed)[0m in 1.68s]
[0m21:16:48.795206 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m21:16:48.796792 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:16:48.797397 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_beginner' was properly closed.
[0m21:16:48.798000 [info ] [MainThread]: 
[0m21:16:48.798562 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 9.60 seconds (9.60s).
[0m21:16:48.800364 [debug] [MainThread]: Command end result
[0m21:16:48.852820 [info ] [MainThread]: 
[0m21:16:48.853627 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:16:48.854243 [info ] [MainThread]: 
[0m21:16:48.854858 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m21:16:48.855709 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 13.84147, "process_user_time": 5.591899, "process_kernel_time": 0.900502, "process_mem_max_rss": "227733504", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:16:48.856622 [debug] [MainThread]: Command `dbt run` succeeded at 21:16:48.856461 after 13.84 seconds
[0m21:16:48.857248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f814f260580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8155a21f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81554d7ca0>]}
[0m21:16:48.857834 [debug] [MainThread]: Flushing usage events
[0m21:19:07.263054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa44e260580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa450371be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa450371190>]}


============================== 21:19:07.267779 | 622df278-f7cb-44d2-93c7-cb6d711c9bb1 ==============================
[0m21:19:07.267779 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:19:07.268912 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'empty': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run --select accounts_history_advanced', 'write_json': 'True', 'fail_fast': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'profiles_dir': '/Users/david/.dbt', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'target_path': 'None', 'debug': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True'}
[0m21:19:11.553262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '622df278-f7cb-44d2-93c7-cb6d711c9bb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45451f4f0>]}
[0m21:19:11.630143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '622df278-f7cb-44d2-93c7-cb6d711c9bb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4544d7ca0>]}
[0m21:19:11.631072 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:19:11.664143 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:19:12.037294 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:19:12.037907 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:19:12.107157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '622df278-f7cb-44d2-93c7-cb6d711c9bb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45484cee0>]}
[0m21:19:12.329355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '622df278-f7cb-44d2-93c7-cb6d711c9bb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa454879340>]}
[0m21:19:12.330145 [info ] [MainThread]: Found 5 models, 2 seeds, 480 macros
[0m21:19:12.330713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '622df278-f7cb-44d2-93c7-cb6d711c9bb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa454867640>]}
[0m21:19:12.332436 [info ] [MainThread]: 
[0m21:19:12.333345 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:19:12.334639 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:19:12.335263 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:15.333741 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:19:15.335626 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:15.931585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '622df278-f7cb-44d2-93c7-cb6d711c9bb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa44e1eebe0>]}
[0m21:19:15.933267 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:19:15.933882 [info ] [MainThread]: 
[0m21:19:15.937987 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m21:19:15.938987 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.accounts_history_advanced ............. [RUN]
[0m21:19:15.940205 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m21:19:15.941036 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m21:19:16.037479 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m21:19:16.038836 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m21:19:16.084456 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m21:19:16.085660 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:19:16.086548 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
  OPTIONS()
  as /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

postponed_payments as (
    SELECT 
        *,
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.
        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses
    FROM calc_paid_total
),

prepared_for_udf as ( -- Preparing the data for the UDF (consuming arrays)
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM postponed_payments
    GROUP BY ALL
),

apply_udf AS (
  SELECT 
    *,
    oscreditrisk.payment_linearization(
      prepared_for_udf.payment_amounts, 
      prepared_for_udf.daily_rates, 
      prepared_for_udf.casted_reporting_dates
    ) as payment_amount_lin_excl_dp
  FROM prepared_for_udf
)

SELECT * FROM apply_udf;


[0m21:19:16.730922 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:4d39c020-2c28-4b9f-b1d8-4c320070b34b&page=queryresults
[0m21:19:16.732031 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Table "calc_paid_total" must be qualified with a dataset (e.g. dataset.table).; reason: invalid, location: calc_paid_total, message: Table "calc_paid_total" must be qualified with a dataset (e.g. dataset.table).')
[0m21:19:17.331607 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:1c3a33c1-dc12-4aa1-9f2c-40701df3bd58&page=queryresults
[0m21:19:17.332923 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:1c3a33c1-dc12-4aa1-9f2c-40701df3bd58&page=queryresults
[0m21:19:17.349244 [debug] [Thread-1  ]: Database Error in model accounts_history_advanced (models/example/1_building_core_dataset/accounts_history_advanced.sql)
  Table "calc_paid_total" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/accounts_history_advanced.sql
[0m21:19:17.352087 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '622df278-f7cb-44d2-93c7-cb6d711c9bb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45514cf40>]}
[0m21:19:17.353240 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.accounts_history_advanced .... [[31mERROR[0m in 1.41s]
[0m21:19:17.354341 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m21:19:17.356438 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:19:17.357124 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m21:19:17.357717 [info ] [MainThread]: 
[0m21:19:17.358299 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.02 seconds (5.02s).
[0m21:19:17.359949 [debug] [MainThread]: Command end result
[0m21:19:17.420696 [info ] [MainThread]: 
[0m21:19:17.421554 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:19:17.422108 [info ] [MainThread]: 
[0m21:19:17.422787 [error] [MainThread]:   Database Error in model accounts_history_advanced (models/example/1_building_core_dataset/accounts_history_advanced.sql)
  Table "calc_paid_total" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/accounts_history_advanced.sql
[0m21:19:17.423340 [info ] [MainThread]: 
[0m21:19:17.423930 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m21:19:17.424790 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 10.2735195, "process_user_time": 5.8993, "process_kernel_time": 1.113015, "process_mem_max_rss": "225308672", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:19:17.425705 [debug] [MainThread]: Command `dbt run` failed at 21:19:17.425550 after 10.27 seconds
[0m21:19:17.426350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa44e260580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa44e4649a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa44fc406a0>]}
[0m21:19:17.427228 [debug] [MainThread]: Flushing usage events
[0m21:19:31.736521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca18a634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1aa76250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1aa76fa0>]}


============================== 21:19:31.741377 | 0cb84f11-fc92-4143-a511-5f10456886ad ==============================
[0m21:19:31.741377 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:19:31.742544 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'log_cache_events': 'False', 'static_parser': 'True', 'debug': 'False', 'invocation_command': 'dbt run --select accounts_history_advanced', 'version_check': 'True', 'empty': 'False', 'partial_parse': 'True', 'write_json': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'log_format': 'default', 'target_path': 'None', 'no_print': 'None', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/david/.dbt', 'introspect': 'True', 'printer_width': '80', 'use_experimental_parser': 'False'}
[0m21:19:36.300345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0cb84f11-fc92-4143-a511-5f10456886ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1eaf7430>]}
[0m21:19:36.375083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0cb84f11-fc92-4143-a511-5f10456886ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1eaf7730>]}
[0m21:19:36.376044 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:19:36.410284 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:19:36.764166 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:19:36.764897 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:19:36.830038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0cb84f11-fc92-4143-a511-5f10456886ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1ef4cee0>]}
[0m21:19:37.053583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0cb84f11-fc92-4143-a511-5f10456886ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1ef7d070>]}
[0m21:19:37.054393 [info ] [MainThread]: Found 5 models, 2 seeds, 480 macros
[0m21:19:37.054940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0cb84f11-fc92-4143-a511-5f10456886ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca18d63ee0>]}
[0m21:19:37.056599 [info ] [MainThread]: 
[0m21:19:37.057480 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:19:37.058817 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:19:37.059428 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:39.969608 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:19:39.970642 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:40.556230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0cb84f11-fc92-4143-a511-5f10456886ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1ef94460>]}
[0m21:19:40.557337 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:19:40.557944 [info ] [MainThread]: 
[0m21:19:40.561974 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m21:19:40.562840 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.accounts_history_advanced ............. [RUN]
[0m21:19:40.563681 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m21:19:40.564330 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m21:19:40.590039 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m21:19:40.591271 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m21:19:40.647304 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m21:19:40.649967 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:19:40.651168 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
  OPTIONS()
  as /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

postponed_payments as (
    SELECT 
        *,
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.
        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses
    FROM accounts_history
),

prepared_for_udf as ( -- Preparing the data for the UDF (consuming arrays)
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM postponed_payments
    GROUP BY ALL
),

apply_udf AS (
  SELECT 
    *,
    oscreditrisk.payment_linearization(
      prepared_for_udf.payment_amounts, 
      prepared_for_udf.daily_rates, 
      prepared_for_udf.casted_reporting_dates
    ) as payment_amount_lin_excl_dp
  FROM prepared_for_udf
)

SELECT * FROM apply_udf;


[0m21:19:41.699437 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:19413375-5d48-4ffa-80c6-7ba48fbb7010&page=queryresults
[0m21:19:42.016221 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Function not found: oscreditrisk.payment_linearization at [44:5]; reason: invalidQuery, location: query, message: Function not found: oscreditrisk.payment_linearization at [44:5]')
[0m21:19:43.632619 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:174a131c-84f8-42f6-999f-d5e7f093354c&page=queryresults
[0m21:19:43.939362 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:174a131c-84f8-42f6-999f-d5e7f093354c&page=queryresults
[0m21:19:43.960751 [debug] [Thread-1  ]: Database Error in model accounts_history_advanced (models/example/1_building_core_dataset/accounts_history_advanced.sql)
  Function not found: oscreditrisk.payment_linearization at [44:5]
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/accounts_history_advanced.sql
[0m21:19:43.969251 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cb84f11-fc92-4143-a511-5f10456886ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1f954a30>]}
[0m21:19:43.970322 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.accounts_history_advanced .... [[31mERROR[0m in 3.40s]
[0m21:19:43.971320 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m21:19:43.973055 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:19:43.973584 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m21:19:43.974109 [info ] [MainThread]: 
[0m21:19:43.975126 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.92 seconds (6.92s).
[0m21:19:43.976514 [debug] [MainThread]: Command end result
[0m21:19:44.087010 [info ] [MainThread]: 
[0m21:19:44.088167 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:19:44.088851 [info ] [MainThread]: 
[0m21:19:44.089614 [error] [MainThread]:   Database Error in model accounts_history_advanced (models/example/1_building_core_dataset/accounts_history_advanced.sql)
  Function not found: oscreditrisk.payment_linearization at [44:5]
  compiled code at target/run/creditrisk/models/example/1_building_core_dataset/accounts_history_advanced.sql
[0m21:19:44.090274 [info ] [MainThread]: 
[0m21:19:44.090928 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m21:19:44.091811 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 12.4651985, "process_user_time": 6.043438, "process_kernel_time": 1.106305, "process_mem_max_rss": "226508800", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:19:44.093110 [debug] [MainThread]: Command `dbt run` failed at 21:19:44.092833 after 12.47 seconds
[0m21:19:44.094874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca18a634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1eaf7430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca1ef3dc10>]}
[0m21:19:44.095814 [debug] [MainThread]: Flushing usage events
[0m21:21:40.369633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4022215b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4042b1d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4042b13d0>]}


============================== 21:21:40.375539 | d3912988-e758-40ea-8b18-17096717c061 ==============================
[0m21:21:40.375539 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:21:40.376556 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'use_colors': 'True', 'quiet': 'False', 'profiles_dir': '/Users/david/.dbt', 'no_print': 'None', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'indirect_selection': 'eager', 'fail_fast': 'False', 'static_parser': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'printer_width': '80', 'invocation_command': 'dbt run --select accounts_history_advanced', 'introspect': 'True', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False'}
[0m21:21:44.913877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd3912988-e758-40ea-8b18-17096717c061', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff404268dc0>]}
[0m21:21:45.073675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd3912988-e758-40ea-8b18-17096717c061', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff404147af0>]}
[0m21:21:45.074663 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:21:45.108028 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:21:45.701170 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:21:45.703064 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:21:45.837031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd3912988-e758-40ea-8b18-17096717c061', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff408877130>]}
[0m21:21:46.071217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd3912988-e758-40ea-8b18-17096717c061', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40889c520>]}
[0m21:21:46.072218 [info ] [MainThread]: Found 5 models, 2 seeds, 1 operation, 480 macros
[0m21:21:46.072856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd3912988-e758-40ea-8b18-17096717c061', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff408877f10>]}
[0m21:21:46.074592 [info ] [MainThread]: 
[0m21:21:46.075547 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:21:46.077003 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:21:46.077813 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:21:49.371875 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:21:49.374267 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:21:50.214719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd3912988-e758-40ea-8b18-17096717c061', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff408438730>]}
[0m21:21:50.215718 [info ] [MainThread]: 
[0m21:21:50.216348 [info ] [MainThread]: Running 1 on-run-start hook
[0m21:21:50.237561 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m21:21:50.247286 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m21:21:50.248446 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:21:50.249546 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m21:21:50.939637 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5a439bac-10a7-4426-bf99-ef178213d411&page=queryresults
[0m21:21:52.375592 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.13s]
[0m21:21:52.376524 [info ] [MainThread]: 
[0m21:21:52.377503 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:21:52.378116 [info ] [MainThread]: 
[0m21:21:52.382116 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m21:21:52.383056 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.accounts_history_advanced ............. [RUN]
[0m21:21:52.383805 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m21:21:52.384417 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m21:21:52.390014 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m21:21:52.391766 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m21:21:52.443846 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m21:21:52.445130 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:21:52.446043 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
  OPTIONS()
  as /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

postponed_payments as (
    SELECT 
        *,
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.
        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses
    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM postponed_payments
    GROUP BY ALL
),

apply_udf AS (
  SELECT 
    *,
    oscreditrisk.payment_linearization(
      prepared_for_udf.payment_amounts, 
      prepared_for_udf.daily_rates, 
      prepared_for_udf.casted_reporting_dates
    ) as payment_amount_lin_excl_dp
  FROM prepared_for_udf
)

SELECT * FROM apply_udf;


[0m21:21:53.455119 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:8ca6236b-04f8-49c0-9c5a-97a3e29efdd6&page=queryresults
[0m21:21:54.204445 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3912988-e758-40ea-8b18-17096717c061', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40846f0a0>]}
[0m21:21:54.205518 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.accounts_history_advanced ........ [[32mCREATE VIEW (0 processed)[0m in 1.82s]
[0m21:21:54.206529 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m21:21:54.208502 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:21:54.209065 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m21:21:54.209646 [info ] [MainThread]: 
[0m21:21:54.210268 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 8.13 seconds (8.13s).
[0m21:21:54.211653 [debug] [MainThread]: Command end result
[0m21:21:54.271163 [info ] [MainThread]: 
[0m21:21:54.272341 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:21:54.272918 [info ] [MainThread]: 
[0m21:21:54.273695 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:21:54.274659 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 14.00593, "process_user_time": 6.30393, "process_kernel_time": 1.159155, "process_mem_max_rss": "227614720", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:21:54.275730 [debug] [MainThread]: Command `dbt run` succeeded at 21:21:54.275484 after 14.01 seconds
[0m21:21:54.276410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4022215b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff403a4a8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff404147af0>]}
[0m21:21:54.277016 [debug] [MainThread]: Flushing usage events
[0m21:26:19.579867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbaaa32580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbac939be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbac939190>]}


============================== 21:26:19.584968 | 8dda4fed-3c33-459e-858e-785da5481fc8 ==============================
[0m21:26:19.584968 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:26:19.586000 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'quiet': 'False', 'introspect': 'True', 'target_path': 'None', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'debug': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error': 'None', 'profiles_dir': '/Users/david/.dbt', 'static_parser': 'True', 'invocation_command': 'dbt run --select accounts_history_advanced', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'no_print': 'None', 'fail_fast': 'False', 'log_format': 'default'}
[0m21:26:24.268931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8dda4fed-3c33-459e-858e-785da5481fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbb0c1fa30>]}
[0m21:26:24.342312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8dda4fed-3c33-459e-858e-785da5481fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbb0bd7ca0>]}
[0m21:26:24.343232 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:26:24.374176 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:26:24.731783 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:26:24.732350 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:26:24.814238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8dda4fed-3c33-459e-858e-785da5481fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbb1041ee0>]}
[0m21:26:25.108149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8dda4fed-3c33-459e-858e-785da5481fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbb1042c70>]}
[0m21:26:25.110263 [info ] [MainThread]: Found 5 models, 2 seeds, 1 operation, 480 macros
[0m21:26:25.115405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8dda4fed-3c33-459e-858e-785da5481fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbb10735b0>]}
[0m21:26:25.119700 [info ] [MainThread]: 
[0m21:26:25.121981 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:26:25.124972 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:26:25.127356 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:26:28.645609 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:26:28.647218 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:26:29.254322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8dda4fed-3c33-459e-858e-785da5481fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbb0516c70>]}
[0m21:26:29.255290 [info ] [MainThread]: 
[0m21:26:29.255900 [info ] [MainThread]: Running 1 on-run-start hook
[0m21:26:29.275587 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m21:26:29.283068 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m21:26:29.283900 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:26:29.284649 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m21:26:29.974793 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:957509e5-e37d-42ae-a558-2439e7837741&page=queryresults
[0m21:26:31.672535 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.39s]
[0m21:26:31.674784 [info ] [MainThread]: 
[0m21:26:31.675997 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:26:31.678909 [info ] [MainThread]: 
[0m21:26:31.684054 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m21:26:31.685219 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.accounts_history_advanced ............. [RUN]
[0m21:26:31.687558 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m21:26:31.688829 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m21:26:31.701963 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m21:26:31.704847 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m21:26:31.772949 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m21:26:31.774749 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:26:31.775739 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
  OPTIONS()
  as /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

postponed_payments as (
    SELECT 
        *,
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.
        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses
    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM postponed_payments
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
    FROM postponed_payments 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
)

SELECT * FROM join_back_on_dataset;


[0m21:26:32.900367 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:7954d77d-e850-4e3c-8a30-3643ed85256d&page=queryresults
[0m21:26:33.602902 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8dda4fed-3c33-459e-858e-785da5481fc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbb1a08610>]}
[0m21:26:33.604178 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.accounts_history_advanced ........ [[32mCREATE VIEW (0 processed)[0m in 1.91s]
[0m21:26:33.605510 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m21:26:33.607349 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:26:33.607848 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m21:26:33.608349 [info ] [MainThread]: 
[0m21:26:33.608901 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 8.49 seconds (8.49s).
[0m21:26:33.610549 [debug] [MainThread]: Command end result
[0m21:26:33.687499 [info ] [MainThread]: 
[0m21:26:33.688502 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:26:33.689328 [info ] [MainThread]: 
[0m21:26:33.690478 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:26:33.692051 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 14.233911, "process_user_time": 6.27683, "process_kernel_time": 1.243824, "process_mem_max_rss": "227418112", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:26:33.693135 [debug] [MainThread]: Command `dbt run` succeeded at 21:26:33.692959 after 14.24 seconds
[0m21:26:33.694071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbaaa32580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbb0c49250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbb0bd7ca0>]}
[0m21:26:33.695463 [debug] [MainThread]: Flushing usage events
[0m21:28:13.440838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa201a2f5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2039f1d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2039f13d0>]}


============================== 21:28:13.446550 | a9cd153e-3ee9-4e28-bddb-9023f5053bf1 ==============================
[0m21:28:13.446550 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:28:13.447615 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select accounts_history_advanced', 'target_path': 'None', 'log_cache_events': 'False', 'write_json': 'True', 'static_parser': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'empty': 'False', 'printer_width': '80', 'log_format': 'default', 'cache_selected_only': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'debug': 'False', 'introspect': 'True', 'profiles_dir': '/Users/david/.dbt', 'quiet': 'False', 'use_colors': 'True'}
[0m21:28:18.686176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a9cd153e-3ee9-4e28-bddb-9023f5053bf1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2039a8b50>]}
[0m21:28:18.767601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a9cd153e-3ee9-4e28-bddb-9023f5053bf1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa207d155b0>]}
[0m21:28:18.768541 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:28:18.804086 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:28:19.354648 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:28:19.357049 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:28:19.559960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a9cd153e-3ee9-4e28-bddb-9023f5053bf1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa208041ee0>]}
[0m21:28:19.989122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a9cd153e-3ee9-4e28-bddb-9023f5053bf1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa208042fa0>]}
[0m21:28:19.989940 [info ] [MainThread]: Found 5 models, 2 seeds, 1 operation, 480 macros
[0m21:28:19.990506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9cd153e-3ee9-4e28-bddb-9023f5053bf1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa207e45550>]}
[0m21:28:19.992415 [info ] [MainThread]: 
[0m21:28:19.994368 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:28:19.997179 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:28:19.998520 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:28:23.743796 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:28:23.744891 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:28:24.523744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9cd153e-3ee9-4e28-bddb-9023f5053bf1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2075f4040>]}
[0m21:28:24.524816 [info ] [MainThread]: 
[0m21:28:24.525506 [info ] [MainThread]: Running 1 on-run-start hook
[0m21:28:24.560368 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m21:28:24.578385 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m21:28:24.581748 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:28:24.583353 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m21:28:25.235125 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:40373320-6d37-4c59-93d9-93459a57024d&page=queryresults
[0m21:28:26.917506 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.34s]
[0m21:28:26.918563 [info ] [MainThread]: 
[0m21:28:26.919359 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:28:26.919860 [info ] [MainThread]: 
[0m21:28:26.924288 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m21:28:26.925376 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.accounts_history_advanced ............. [RUN]
[0m21:28:26.926200 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m21:28:26.926836 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m21:28:26.932776 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m21:28:26.934055 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m21:28:26.983644 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m21:28:26.984887 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:28:26.985746 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
  OPTIONS()
  as /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

        GREATEST(
            0,
            MAX(reporting_day - down_payment_days_included) OVER(PARTITION BY account_id)
         ) as account_age_excl_dp_in_days,

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
)

SELECT * FROM join_back_on_dataset;


[0m21:28:28.060488 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:2f386228-8dfb-4433-9236-11ced388f913&page=queryresults
[0m21:28:28.845250 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9cd153e-3ee9-4e28-bddb-9023f5053bf1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa208908220>]}
[0m21:28:28.847003 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.accounts_history_advanced ........ [[32mCREATE VIEW (0 processed)[0m in 1.92s]
[0m21:28:28.849444 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m21:28:28.853047 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:28:28.853889 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m21:28:28.854752 [info ] [MainThread]: 
[0m21:28:28.856060 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 8.86 seconds (8.86s).
[0m21:28:28.857755 [debug] [MainThread]: Command end result
[0m21:28:28.982350 [info ] [MainThread]: 
[0m21:28:28.983647 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:28:28.984692 [info ] [MainThread]: 
[0m21:28:28.985619 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:28:28.986612 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 15.643644, "process_user_time": 6.376104, "process_kernel_time": 1.24981, "process_mem_max_rss": "227815424", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:28:28.987679 [debug] [MainThread]: Command `dbt run` succeeded at 21:28:28.987490 after 15.64 seconds
[0m21:28:28.988566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa201a2f5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2031a4910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa207d155b0>]}
[0m21:28:28.989850 [debug] [MainThread]: Flushing usage events
[0m21:45:59.157566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd5d260580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd5f26abe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd5f26a190>]}


============================== 21:45:59.162685 | a36f1de2-f19b-488f-9b03-0f03386e5e4b ==============================
[0m21:45:59.162685 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:45:59.163697 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'log_format': 'default', 'empty': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'invocation_command': 'dbt run --select 1_building_core_dataset', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'target_path': 'None', 'printer_width': '80', 'indirect_selection': 'eager', 'introspect': 'True', 'warn_error': 'None', 'profiles_dir': '/Users/david/.dbt', 'write_json': 'True', 'debug': 'False'}
[0m21:46:03.282287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a36f1de2-f19b-488f-9b03-0f03386e5e4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd62c81ee0>]}
[0m21:46:03.356430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a36f1de2-f19b-488f-9b03-0f03386e5e4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd5e472460>]}
[0m21:46:03.357379 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:46:03.389485 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:46:03.813998 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:46:03.814688 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:46:03.905431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a36f1de2-f19b-488f-9b03-0f03386e5e4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63874130>]}
[0m21:46:04.227789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a36f1de2-f19b-488f-9b03-0f03386e5e4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63897130>]}
[0m21:46:04.228657 [info ] [MainThread]: Found 5 models, 2 seeds, 1 operation, 480 macros
[0m21:46:04.229233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a36f1de2-f19b-488f-9b03-0f03386e5e4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd634b40d0>]}
[0m21:46:04.230217 [warn ] [MainThread]: The selection criterion '1_building_core_dataset' does not match any enabled nodes
[0m21:46:04.232024 [info ] [MainThread]: 
[0m21:46:04.232965 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m21:46:04.237132 [debug] [MainThread]: Command end result
[0m21:46:04.301779 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.241912, "process_user_time": 5.597503, "process_kernel_time": 0.994377, "process_mem_max_rss": "219832320", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:46:04.303483 [debug] [MainThread]: Command `dbt run` succeeded at 21:46:04.303186 after 5.24 seconds
[0m21:46:04.304206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd5d260580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd634aae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd5e472460>]}
[0m21:46:04.304882 [debug] [MainThread]: Flushing usage events
[0m21:46:37.590699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec2a354f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec4b70d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec4b70100>]}


============================== 21:46:37.595530 | c5ecd43e-4a68-4ff9-8ea5-396cb019523a ==============================
[0m21:46:37.595530 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:46:37.596595 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'empty': 'False', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/Users/david/.dbt', 'fail_fast': 'False', 'quiet': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'indirect_selection': 'eager', 'use_colors': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'write_json': 'True', 'no_print': 'None', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select 1+accounts_history_advanced', 'target_path': 'None'}
[0m21:46:41.690793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c5ecd43e-4a68-4ff9-8ea5-396cb019523a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec8ad6220>]}
[0m21:46:41.782448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c5ecd43e-4a68-4ff9-8ea5-396cb019523a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec84b5b50>]}
[0m21:46:41.783774 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:46:41.819810 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:46:42.224176 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:46:42.224804 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:46:42.312168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c5ecd43e-4a68-4ff9-8ea5-396cb019523a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec9874130>]}
[0m21:46:42.570989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c5ecd43e-4a68-4ff9-8ea5-396cb019523a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec98975b0>]}
[0m21:46:42.571825 [info ] [MainThread]: Found 5 models, 2 seeds, 1 operation, 480 macros
[0m21:46:42.572486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c5ecd43e-4a68-4ff9-8ea5-396cb019523a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec98352e0>]}
[0m21:46:42.575038 [info ] [MainThread]: 
[0m21:46:42.576298 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:46:42.583752 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:46:42.584567 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:46:46.047261 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:46:46.048935 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:46:46.664277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c5ecd43e-4a68-4ff9-8ea5-396cb019523a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec2f714f0>]}
[0m21:46:46.665165 [info ] [MainThread]: 
[0m21:46:46.665799 [info ] [MainThread]: Running 1 on-run-start hook
[0m21:46:46.685514 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m21:46:46.693665 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m21:46:46.694560 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:46:46.695317 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m21:46:47.403316 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:c9cd1639-2caa-4ad2-b715-bfcab9587b44&page=queryresults
[0m21:46:48.858367 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.16s]
[0m21:46:48.859043 [info ] [MainThread]: 
[0m21:46:48.859814 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:46:48.860353 [info ] [MainThread]: 
[0m21:46:48.863985 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m21:46:48.865017 [info ] [Thread-1  ]: 1 of 2 START sql table model oscreditrisk.accounts_history_beginner ............ [RUN]
[0m21:46:48.865876 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_beginner)
[0m21:46:48.866497 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_beginner
[0m21:46:48.875521 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_beginner"
[0m21:46:48.876958 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_beginner
[0m21:46:48.901194 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:46:49.869167 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_beginner"
[0m21:46:49.871668 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_beginner"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
      
    partition by timestamp_trunc(reporting_date, day)
    cluster by account_id

    OPTIONS()
    as (
      /*
    This transformations is generating the first version of the core dataset (beginner version). 
    It is essentially : 
    - Joining the accounts dataset with a date spine for the target granuarity
    - Grouping the payment by day, and joining them to the accounts history
    - Calculating cumulated sums to describe the cumulated amount paid, and a few other useful fields
*/



WITH accounts as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

payments as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

date_spine as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

accounts_with_spine as (
  SELECT 
    *,
    TIMESTAMP_DIFF(reporting_date, registration_date, DAY) + 1 as reporting_day,
  FROM accounts
  LEFT JOIN date_spine
  ON accounts.registration_date <= date_spine.reporting_date
),

payments_grouped_by_day as (
  SELECT 
    account_id,
    
    DATE_ADD(
      DATE_TRUNC(payment_effective_date, DAY), 
      INTERVAL 1 DAY
    ) as reporting_date,

    SUM(amount) as amount,
    SUM(
      IF(not down_payment, amount, 0)
    ) as amount_excl_dp,

  FROM payments
  GROUP BY ALL
),

joint as (
  SELECT 
    * EXCEPT(amount, amount_excl_dp),
    COALESCE(amount,          0) as amount,
    COALESCE(amount_excl_dp,  0) as amount_excl_dp,
  FROM accounts_with_spine 
  LEFT JOIN payments_grouped_by_day 
  USING(account_id, reporting_date)
),

calc_paid_total as (
  SELECT 
    *,
    SUM(amount)         OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total,
    SUM(amount_excl_dp) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_excl_dp,
    
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate) + down_payment_days_included as nominal_term,
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate)                              as nominal_term_excl_dp,
  FROM joint
)

SELECT * FROM calc_paid_total
    );
  
[0m21:46:50.529320 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:cd4c576c-35e4-4b6f-a62d-923dd7fd4460&page=queryresults
[0m21:47:25.700153 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5ecd43e-4a68-4ff9-8ea5-396cb019523a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec84c1670>]}
[0m21:47:25.702136 [info ] [Thread-1  ]: 1 of 2 OK created sql table model oscreditrisk.accounts_history_beginner ....... [[32mCREATE TABLE (3.4m rows, 6.2 MiB processed)[0m in 36.83s]
[0m21:47:25.703369 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m21:47:25.704564 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m21:47:25.705565 [info ] [Thread-1  ]: 2 of 2 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m21:47:25.706425 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_beginner, now model.creditrisk.accounts_history_advanced)
[0m21:47:25.707022 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m21:47:25.713819 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m21:47:25.715554 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m21:47:25.721882 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:47:26.808690 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m21:47:26.810128 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    partition by timestamp_trunc(reporting_date, day)
    cluster by account_id

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/



WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

        GREATEST(
            0,
            MAX(reporting_day - down_payment_days_included) OVER(PARTITION BY account_id)
         ) as account_age_excl_dp_in_days,

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

final_kpis as (
  SELECT 
    *,
    CASE 
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_back_on_dataset
)

SELECT * FROM final_kpis
    );
  
[0m21:47:27.417813 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:db13cf95-c856-4770-946c-07bc0ab08bf7&page=queryresults
[0m21:48:04.102255 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5ecd43e-4a68-4ff9-8ea5-396cb019523a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9eca309220>]}
[0m21:48:04.103998 [info ] [Thread-1  ]: 2 of 2 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 358.0 MiB processed)[0m in 38.40s]
[0m21:48:04.104984 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m21:48:04.106493 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:48:04.106974 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m21:48:04.107566 [info ] [MainThread]: 
[0m21:48:04.108110 [info ] [MainThread]: Finished running 2 table models, 1 project hook in 0 hours 1 minutes and 21.53 seconds (81.53s).
[0m21:48:04.109394 [debug] [MainThread]: Command end result
[0m21:48:04.171903 [info ] [MainThread]: 
[0m21:48:04.172775 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:48:04.173339 [info ] [MainThread]: 
[0m21:48:04.173932 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m21:48:04.174782 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 86.674774, "process_user_time": 6.037291, "process_kernel_time": 1.004635, "process_mem_max_rss": "227942400", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:48:04.175730 [debug] [MainThread]: Command `dbt run` succeeded at 21:48:04.175571 after 86.68 seconds
[0m21:48:04.176364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec2a354f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec9898e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ec2f64ee0>]}
[0m21:48:04.177187 [debug] [MainThread]: Flushing usage events
[0m21:56:04.542028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea2a32550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea4af1d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea4af1400>]}


============================== 21:56:04.547707 | 0777e40a-5848-4ba8-b5fb-d7e2fcceda3b ==============================
[0m21:56:04.547707 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:56:04.548713 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'write_json': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'target_path': 'None', 'invocation_command': 'dbt run --select 1+accounts_history_advanced', 'introspect': 'True', 'no_print': 'None', 'debug': 'False', 'version_check': 'True', 'printer_width': '80', 'static_parser': 'True', 'warn_error': 'None', 'use_colors': 'True', 'fail_fast': 'False', 'log_cache_events': 'False', 'empty': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'partial_parse': 'True', 'profiles_dir': '/Users/david/.dbt', 'cache_selected_only': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs'}
[0m21:56:09.366948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0777e40a-5848-4ba8-b5fb-d7e2fcceda3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea8bbc370>]}
[0m21:56:09.442518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0777e40a-5848-4ba8-b5fb-d7e2fcceda3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea4975e80>]}
[0m21:56:09.443438 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:56:09.477038 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:56:09.843855 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:56:09.844480 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:56:09.922989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0777e40a-5848-4ba8-b5fb-d7e2fcceda3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea8f2cdc0>]}
[0m21:56:10.161596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0777e40a-5848-4ba8-b5fb-d7e2fcceda3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea8c4c820>]}
[0m21:56:10.162492 [info ] [MainThread]: Found 6 models, 2 seeds, 1 operation, 480 macros
[0m21:56:10.163061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0777e40a-5848-4ba8-b5fb-d7e2fcceda3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea8bcf460>]}
[0m21:56:10.164850 [info ] [MainThread]: 
[0m21:56:10.165704 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:56:10.172650 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:56:10.173396 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:56:13.353375 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:56:13.355292 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:56:13.964943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0777e40a-5848-4ba8-b5fb-d7e2fcceda3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea4ac1220>]}
[0m21:56:13.965969 [info ] [MainThread]: 
[0m21:56:13.966622 [info ] [MainThread]: Running 1 on-run-start hook
[0m21:56:13.989017 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m21:56:13.998106 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m21:56:13.998950 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:56:13.999697 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m21:56:14.684531 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:e90873f5-2da8-461b-92a8-c473c211d9e7&page=queryresults
[0m21:56:16.217776 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.22s]
[0m21:56:16.218459 [info ] [MainThread]: 
[0m21:56:16.219194 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:56:16.219698 [info ] [MainThread]: 
[0m21:56:16.224665 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m21:56:16.225831 [info ] [Thread-1  ]: 1 of 2 START sql table model oscreditrisk.accounts_history_beginner ............ [RUN]
[0m21:56:16.226846 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_beginner)
[0m21:56:16.227480 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_beginner
[0m21:56:16.234317 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_beginner"
[0m21:56:16.235685 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_beginner
[0m21:56:16.349065 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:56:17.176807 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_beginner"
[0m21:56:17.179189 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_beginner"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
      
    partition by timestamp_trunc(reporting_date, day)
    cluster by account_id

    OPTIONS()
    as (
      /*
    This transformations is generating the first version of the core dataset (beginner version). 
    It is essentially : 
    - Joining the accounts dataset with a date spine for the target granuarity
    - Grouping the payment by day, and joining them to the accounts history
    - Calculating cumulated sums to describe the cumulated amount paid, and a few other useful fields
*/



WITH accounts as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

payments as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

date_spine as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

accounts_with_spine as (
  SELECT 
    *,
    TIMESTAMP_DIFF(reporting_date, registration_date, DAY) + 1 as reporting_day,
  FROM accounts
  LEFT JOIN date_spine
  ON accounts.registration_date <= date_spine.reporting_date
),

payments_grouped_by_day as (
  SELECT 
    account_id,
    
    DATE_ADD(
      DATE_TRUNC(payment_effective_date, DAY), 
      INTERVAL 1 DAY
    ) as reporting_date,

    SUM(amount) as amount,
    SUM(
      IF(not down_payment, amount, 0)
    ) as amount_excl_dp,

  FROM payments
  GROUP BY ALL
),

joint as (
  SELECT 
    * EXCEPT(amount, amount_excl_dp),
    COALESCE(amount,          0) as amount,
    COALESCE(amount_excl_dp,  0) as amount_excl_dp,
  FROM accounts_with_spine 
  LEFT JOIN payments_grouped_by_day 
  USING(account_id, reporting_date)
),

calc_paid_total as (
  SELECT 
    *,
    SUM(amount)         OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total,
    SUM(amount_excl_dp) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_excl_dp,
    
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate) + down_payment_days_included as nominal_term,
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate)                              as nominal_term_excl_dp,

    MAX(reporting_day) OVER(PARTITION BY account_id) as account_age_in_days,
    GREATEST(
            0,
            MAX(reporting_day - down_payment_days_included) OVER(PARTITION BY account_id)
    ) as account_age_excl_dp_in_days,

  FROM joint
)

SELECT * FROM calc_paid_total
    );
  
[0m21:56:18.066120 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:8fcf6c95-17cb-463a-843f-e958535caad0&page=queryresults
[0m21:56:45.747266 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0777e40a-5848-4ba8-b5fb-d7e2fcceda3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea214e610>]}
[0m21:56:45.748425 [info ] [Thread-1  ]: 1 of 2 OK created sql table model oscreditrisk.accounts_history_beginner ....... [[32mCREATE TABLE (3.4m rows, 6.2 MiB processed)[0m in 29.52s]
[0m21:56:45.749521 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m21:56:45.750746 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m21:56:45.751582 [info ] [Thread-1  ]: 2 of 2 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m21:56:45.752303 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_beginner, now model.creditrisk.accounts_history_advanced)
[0m21:56:45.752883 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m21:56:45.759519 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m21:56:45.761383 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m21:56:45.765215 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:56:46.356907 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m21:56:46.359943 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    partition by timestamp_trunc(reporting_date, day)
    cluster by account_id

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/



WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    *,
    CASE 
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_back_on_dataset
)

SELECT * FROM final_kpis
    );
  
[0m21:56:46.835736 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:1fa43142-49ea-4b64-babf-8785a0fab5aa&page=queryresults
[0m21:57:27.083605 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0777e40a-5848-4ba8-b5fb-d7e2fcceda3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea9579790>]}
[0m21:57:27.085339 [info ] [Thread-1  ]: 2 of 2 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 409.2 MiB processed)[0m in 41.33s]
[0m21:57:27.086344 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m21:57:27.087930 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:57:27.088407 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m21:57:27.088988 [info ] [MainThread]: 
[0m21:57:27.089532 [info ] [MainThread]: Finished running 2 table models, 1 project hook in 0 hours 1 minutes and 16.92 seconds (76.92s).
[0m21:57:27.090918 [debug] [MainThread]: Command end result
[0m21:57:27.153535 [info ] [MainThread]: 
[0m21:57:27.154344 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:57:27.154891 [info ] [MainThread]: 
[0m21:57:27.155597 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m21:57:27.156639 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 82.7419, "process_user_time": 6.214898, "process_kernel_time": 1.23674, "process_mem_max_rss": "228462592", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:57:27.158277 [debug] [MainThread]: Command `dbt run` succeeded at 21:57:27.158059 after 82.74 seconds
[0m21:57:27.158988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea2a32550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea4295790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea4975e80>]}
[0m21:57:27.159603 [debug] [MainThread]: Flushing usage events
[0m21:58:28.984031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9954a275b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9956914700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9956914520>]}


============================== 21:58:28.989926 | 822b9d7d-9f37-44ad-bb22-4839daa69898 ==============================
[0m21:58:28.989926 [info ] [MainThread]: Running with dbt=1.8.8
[0m21:58:28.990943 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'write_json': 'True', 'invocation_command': 'dbt run --select cohorts_beginner', 'introspect': 'True', 'use_colors': 'True', 'no_print': 'None', 'target_path': 'None', 'log_cache_events': 'False', 'printer_width': '80', 'debug': 'False', 'warn_error': 'None', 'static_parser': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'log_format': 'default', 'empty': 'False', 'profiles_dir': '/Users/david/.dbt', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'fail_fast': 'False', 'quiet': 'False', 'send_anonymous_usage_stats': 'True'}
[0m21:58:33.688247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '822b9d7d-9f37-44ad-bb22-4839daa69898', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f995a4cf910>]}
[0m21:58:33.769223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '822b9d7d-9f37-44ad-bb22-4839daa69898', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9956738100>]}
[0m21:58:33.770609 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:58:33.805338 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m21:58:34.239643 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:58:34.240355 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:58:34.355424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '822b9d7d-9f37-44ad-bb22-4839daa69898', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f995af40ee0>]}
[0m21:58:34.841104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '822b9d7d-9f37-44ad-bb22-4839daa69898', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f995af636d0>]}
[0m21:58:34.842092 [info ] [MainThread]: Found 6 models, 2 seeds, 1 operation, 480 macros
[0m21:58:34.843399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '822b9d7d-9f37-44ad-bb22-4839daa69898', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f995af8c550>]}
[0m21:58:34.845622 [info ] [MainThread]: 
[0m21:58:34.846780 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:58:34.848408 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m21:58:34.850784 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:58:37.974974 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m21:58:37.976131 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:58:38.578510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '822b9d7d-9f37-44ad-bb22-4839daa69898', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f995ac389a0>]}
[0m21:58:38.579489 [info ] [MainThread]: 
[0m21:58:38.580144 [info ] [MainThread]: Running 1 on-run-start hook
[0m21:58:38.602022 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m21:58:38.610357 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m21:58:38.612296 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:58:38.613323 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m21:58:39.287975 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:e301fcd7-fe4b-428b-b6ec-fab4a14e22cb&page=queryresults
[0m21:58:40.667526 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.06s]
[0m21:58:40.668416 [info ] [MainThread]: 
[0m21:58:40.669359 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:58:40.670118 [info ] [MainThread]: 
[0m21:58:40.675026 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_beginner
[0m21:58:40.676306 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cohorts_beginner ...................... [RUN]
[0m21:58:40.677263 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cohorts_beginner)
[0m21:58:40.678144 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_beginner
[0m21:58:40.685955 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_beginner"
[0m21:58:40.687498 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_beginner
[0m21:58:40.752806 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_beginner"
[0m21:58:40.754206 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:58:40.755017 [debug] [Thread-1  ]: On model.creditrisk.cohorts_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_beginner"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohorts_beginner`
  OPTIONS()
  as /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the beginner core dataset, and produces information on raw payments only.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
)

WITH cohort_calc as (
    SELECT 
        *,
        DATE_TRUNC(registration_date, MONTH) as cohort, -- possible to change here to quarter or year
    FROM accounts_history
),

filtered as (
    SELECT 
        * 
    FROM cohort_calc
    WHERE  MOD(reporting_day, 30) = 1 -- optional : downsampling results to 1 point every 30 days. Often sufficient.
    QUALIFY reporting_day <= MIN(account_age_in_days) OVER(PARTITION BY cohort) -- removes the end of cohorts where calculation is not representative of the whole cohort
)

SELECT 
    cohort,
    reporting_day,
    SUM(paid_total) / SUM(unlock_price) as amount_paid_percent,
FROM filtered
GROUP BY ALL;


[0m21:58:41.359973 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b5910793-7400-4839-894a-061de7ecdd43&page=queryresults
[0m21:58:41.360966 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Expected keyword DEPTH but got identifier "cohort_calc" at [15:6]; reason: invalidQuery, location: query, message: Syntax error: Expected keyword DEPTH but got identifier "cohort_calc" at [15:6]')
[0m21:58:42.488786 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ac3dd213-96ec-44fe-ade8-0b333d2a8aa6&page=queryresults
[0m21:58:42.489702 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ac3dd213-96ec-44fe-ade8-0b333d2a8aa6&page=queryresults
[0m21:58:42.505726 [debug] [Thread-1  ]: Database Error in model cohorts_beginner (models/example/2_cohort_visualizations/cohorts_beginner.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cohort_calc" at [15:6]
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_beginner.sql
[0m21:58:42.508167 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '822b9d7d-9f37-44ad-bb22-4839daa69898', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f995b5c0fd0>]}
[0m21:58:42.509186 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.cohorts_beginner ............. [[31mERROR[0m in 1.83s]
[0m21:58:42.510445 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_beginner
[0m21:58:42.512647 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:58:42.513211 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_beginner' was properly closed.
[0m21:58:42.513738 [info ] [MainThread]: 
[0m21:58:42.515483 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 7.67 seconds (7.67s).
[0m21:58:42.518657 [debug] [MainThread]: Command end result
[0m21:58:42.591554 [info ] [MainThread]: 
[0m21:58:42.592516 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:58:42.593193 [info ] [MainThread]: 
[0m21:58:42.594349 [error] [MainThread]:   Database Error in model cohorts_beginner (models/example/2_cohort_visualizations/cohorts_beginner.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cohort_calc" at [15:6]
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_beginner.sql
[0m21:58:42.595417 [info ] [MainThread]: 
[0m21:58:42.596939 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m21:58:42.598328 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 13.72227, "process_user_time": 6.338119, "process_kernel_time": 1.231299, "process_mem_max_rss": "227721216", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:58:42.599480 [debug] [MainThread]: Command `dbt run` failed at 21:58:42.599272 after 13.72 seconds
[0m21:58:42.600211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9954a275b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9954d528e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99560c97f0>]}
[0m21:58:42.600866 [debug] [MainThread]: Flushing usage events
[0m22:00:42.181836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81422f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd816272d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8162723d0>]}


============================== 22:00:42.186994 | f5a9283c-007e-4003-9f29-0d7e4fbfb5e7 ==============================
[0m22:00:42.186994 [info ] [MainThread]: Running with dbt=1.8.8
[0m22:00:42.188122 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'printer_width': '80', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error': 'None', 'debug': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'quiet': 'False', 'write_json': 'True', 'partial_parse': 'True', 'invocation_command': 'dbt run --select 2+cohorts_beginner', 'profiles_dir': '/Users/david/.dbt', 'use_colors': 'True', 'cache_selected_only': 'False', 'empty': 'False', 'fail_fast': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager'}
[0m22:00:47.593436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8161f99a0>]}
[0m22:00:47.672980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81a416910>]}
[0m22:00:47.673950 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:00:47.711761 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m22:00:48.129106 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:00:48.129710 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:00:48.239092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81a840ee0>]}
[0m22:00:48.542720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81a862550>]}
[0m22:00:48.544448 [info ] [MainThread]: Found 6 models, 2 seeds, 1 operation, 480 macros
[0m22:00:48.545401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81a88d7c0>]}
[0m22:00:48.548563 [info ] [MainThread]: 
[0m22:00:48.550121 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:00:48.560429 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m22:00:48.562288 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:00:52.311915 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m22:00:52.313638 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:00:52.910001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81a4c6c40>]}
[0m22:00:52.911327 [info ] [MainThread]: 
[0m22:00:52.912105 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:00:52.932512 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m22:00:52.939459 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m22:00:52.940510 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:00:52.941911 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m22:00:53.561821 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:897fefa5-ffe6-4d3d-8415-4b5afa158cb7&page=queryresults
[0m22:00:55.031079 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.09s]
[0m22:00:55.032531 [info ] [MainThread]: 
[0m22:00:55.034210 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:00:55.035110 [info ] [MainThread]: 
[0m22:00:55.044876 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m22:00:55.046815 [info ] [Thread-1  ]: 1 of 5 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m22:00:55.048235 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m22:00:55.049254 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m22:00:55.057847 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m22:00:55.062339 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m22:00:55.145865 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m22:00:55.147136 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:00:55.148146 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m22:00:55.952166 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5413b627-6dd2-4dc2-b416-4bba26180719&page=queryresults
[0m22:00:56.620244 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd819d14610>]}
[0m22:00:56.621384 [info ] [Thread-1  ]: 1 of 5 OK created sql view model oscreditrisk.cleaned_accounts ................. [[32mCREATE VIEW (0 processed)[0m in 1.57s]
[0m22:00:56.622526 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m22:00:56.623341 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_payments
[0m22:00:56.624232 [info ] [Thread-1  ]: 2 of 5 START sql view model oscreditrisk.cleaned_payments ...................... [RUN]
[0m22:00:56.624962 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_accounts, now model.creditrisk.cleaned_payments)
[0m22:00:56.625547 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_payments
[0m22:00:56.635945 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_payments"
[0m22:00:56.637852 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_payments
[0m22:00:56.642619 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_payments"
[0m22:00:56.643879 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:00:56.644662 [debug] [Thread-1  ]: On model.creditrisk.cleaned_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_payments"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`
)

SELECT 
  account_id,
  CAST(down_payment             AS BOOLEAN)         as down_payment,
  CAST(payment_effective_date   AS TIMESTAMP)       as payment_effective_date,
  CAST(amount                   AS FLOAT64)         as amount,
FROM payments;


[0m22:00:57.561308 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:efac34a0-117c-4276-940a-035305251da5&page=queryresults
[0m22:00:58.190425 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81b0461c0>]}
[0m22:00:58.192158 [info ] [Thread-1  ]: 2 of 5 OK created sql view model oscreditrisk.cleaned_payments ................. [[32mCREATE VIEW (0 processed)[0m in 1.57s]
[0m22:00:58.193737 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_payments
[0m22:00:58.195643 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m22:00:58.196998 [info ] [Thread-1  ]: 3 of 5 START sql view model oscreditrisk.date_spine ............................ [RUN]
[0m22:00:58.199608 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_payments, now model.creditrisk.date_spine)
[0m22:00:58.202728 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m22:00:58.217724 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m22:00:58.220173 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m22:00:58.232799 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m22:00:58.234426 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:00:58.235873 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`date_spine`
  OPTIONS()
  as /*
    This transformations is generating a dataset containing one row for each day betwee : 
    - The first day you opened an account
    - Today. With artificial data here we consider today being the day after we received the last payment.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

min_max_dates as (
    SELECT 
        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,
        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,
    FROM payments
)

SELECT
    CAST(
        TIMESTAMP_ADD(
            (SELECT min_date FROM min_max_dates), 
            INTERVAL n DAY
        ) AS TIMESTAMP
    ) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            DAY
        )
    )
) AS n;


[0m22:00:59.211889 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b370ee4d-5333-4ea3-a2c6-4cb63d522163&page=queryresults
[0m22:00:59.826188 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81aeb83a0>]}
[0m22:00:59.827265 [info ] [Thread-1  ]: 3 of 5 OK created sql view model oscreditrisk.date_spine ....................... [[32mCREATE VIEW (0 processed)[0m in 1.63s]
[0m22:00:59.829146 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m22:00:59.831638 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m22:00:59.833976 [info ] [Thread-1  ]: 4 of 5 START sql table model oscreditrisk.accounts_history_beginner ............ [RUN]
[0m22:00:59.835508 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.date_spine, now model.creditrisk.accounts_history_beginner)
[0m22:00:59.836584 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_beginner
[0m22:00:59.851179 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_beginner"
[0m22:00:59.852503 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_beginner
[0m22:00:59.899646 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:01:00.604829 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_beginner"
[0m22:01:00.606220 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_beginner"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
      
    partition by timestamp_trunc(reporting_date, day)
    cluster by account_id

    OPTIONS()
    as (
      /*
    This transformations is generating the first version of the core dataset (beginner version). 
    It is essentially : 
    - Joining the accounts dataset with a date spine for the target granuarity
    - Grouping the payment by day, and joining them to the accounts history
    - Calculating cumulated sums to describe the cumulated amount paid, and a few other useful fields
*/



WITH accounts as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

payments as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

date_spine as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

accounts_with_spine as (
  SELECT 
    *,
    TIMESTAMP_DIFF(reporting_date, registration_date, DAY) + 1 as reporting_day,
  FROM accounts
  LEFT JOIN date_spine
  ON accounts.registration_date <= date_spine.reporting_date
),

payments_grouped_by_day as (
  SELECT 
    account_id,
    
    DATE_ADD(
      DATE_TRUNC(payment_effective_date, DAY), 
      INTERVAL 1 DAY
    ) as reporting_date,

    SUM(amount) as amount,
    SUM(
      IF(not down_payment, amount, 0)
    ) as amount_excl_dp,

  FROM payments
  GROUP BY ALL
),

joint as (
  SELECT 
    * EXCEPT(amount, amount_excl_dp),
    COALESCE(amount,          0) as amount,
    COALESCE(amount_excl_dp,  0) as amount_excl_dp,
  FROM accounts_with_spine 
  LEFT JOIN payments_grouped_by_day 
  USING(account_id, reporting_date)
),

calc_paid_total as (
  SELECT 
    *,
    SUM(amount)         OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total,
    SUM(amount_excl_dp) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_excl_dp,
    
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate) + down_payment_days_included as nominal_term,
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate)                              as nominal_term_excl_dp,

    MAX(reporting_day) OVER(PARTITION BY account_id) as account_age_in_days,
    GREATEST(
            0,
            MAX(reporting_day - down_payment_days_included) OVER(PARTITION BY account_id)
    ) as account_age_excl_dp_in_days,

    DATE_TRUNC(registration_date, MONTH) as cohort_month,
    DATE_TRUNC(registration_date, QUARTER) as cohort_quarter,
    DATE_TRUNC(registration_date, YEAR) as cohort_year,

  FROM joint
)

SELECT * FROM calc_paid_total
    );
  
[0m22:01:01.305138 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:927294eb-71f1-4df2-bb6d-18bb55752efd&page=queryresults
[0m22:01:28.053349 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd819d14610>]}
[0m22:01:28.054796 [info ] [Thread-1  ]: 4 of 5 OK created sql table model oscreditrisk.accounts_history_beginner ....... [[32mCREATE TABLE (3.4m rows, 6.2 MiB processed)[0m in 28.22s]
[0m22:01:28.056916 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m22:01:28.058993 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_beginner
[0m22:01:28.062143 [info ] [Thread-1  ]: 5 of 5 START sql view model oscreditrisk.cohorts_beginner ...................... [RUN]
[0m22:01:28.064695 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_beginner, now model.creditrisk.cohorts_beginner)
[0m22:01:28.066044 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_beginner
[0m22:01:28.119909 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_beginner"
[0m22:01:28.133957 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_beginner
[0m22:01:28.147567 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_beginner"
[0m22:01:28.150506 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:01:28.154504 [debug] [Thread-1  ]: On model.creditrisk.cohorts_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_beginner"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohorts_beginner`
  OPTIONS()
  as /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the beginner core dataset, and produces information on raw payments only.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

filtered as (
    SELECT 
        * 
    FROM cohort_calc
    -- optional : downsampling results to 1 point every 30 days. Often sufficient.
    WHERE  MOD(reporting_day, 30) = 1 
    -- removing the end of cohorts where calculation is not representative of the whole cohort
    QUALIFY reporting_day <= MIN(account_age_in_days) OVER(PARTITION BY cohort_month) 
)

-- Aggregating results on a cohort level
SELECT 
    cohort,
    reporting_day,
    SUM(paid_total) / SUM(unlock_price) as amount_paid_percent,
FROM filtered
GROUP BY ALL;


[0m22:01:29.034283 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:24220f32-9639-4207-8c91-82cb9bd49f29&page=queryresults
[0m22:01:29.082582 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Table "cohort_calc" must be qualified with a dataset (e.g. dataset.table).; reason: invalid, location: cohort_calc, message: Table "cohort_calc" must be qualified with a dataset (e.g. dataset.table).')
[0m22:01:30.040062 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:df58da3f-df47-4d5f-8cfc-b441da72ecdb&page=queryresults
[0m22:01:30.041284 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:df58da3f-df47-4d5f-8cfc-b441da72ecdb&page=queryresults
[0m22:01:30.057947 [debug] [Thread-1  ]: Database Error in model cohorts_beginner (models/example/2_cohort_visualizations/cohorts_beginner.sql)
  Table "cohort_calc" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_beginner.sql
[0m22:01:30.058838 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f5a9283c-007e-4003-9f29-0d7e4fbfb5e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81b0ed790>]}
[0m22:01:30.059897 [error] [Thread-1  ]: 5 of 5 ERROR creating sql view model oscreditrisk.cohorts_beginner ............. [[31mERROR[0m in 1.99s]
[0m22:01:30.061257 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_beginner
[0m22:01:30.063353 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:01:30.063947 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_beginner' was properly closed.
[0m22:01:30.064703 [info ] [MainThread]: 
[0m22:01:30.066331 [info ] [MainThread]: Finished running 4 view models, 1 table model, 1 project hook in 0 hours 0 minutes and 41.52 seconds (41.51s).
[0m22:01:30.070453 [debug] [MainThread]: Command end result
[0m22:01:30.148289 [info ] [MainThread]: 
[0m22:01:30.149099 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:01:30.149792 [info ] [MainThread]: 
[0m22:01:30.150501 [error] [MainThread]:   Database Error in model cohorts_beginner (models/example/2_cohort_visualizations/cohorts_beginner.sql)
  Table "cohort_calc" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_beginner.sql
[0m22:01:30.151058 [info ] [MainThread]: 
[0m22:01:30.151728 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m22:01:30.152613 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 48.07829, "process_user_time": 6.868597, "process_kernel_time": 1.36377, "process_mem_max_rss": "229679104", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:01:30.153733 [debug] [MainThread]: Command `dbt run` failed at 22:01:30.153506 after 48.08 seconds
[0m22:01:30.154980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81422f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8145698e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd81a8e76a0>]}
[0m22:01:30.156159 [debug] [MainThread]: Flushing usage events
[0m22:01:52.177355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc746a32580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc748b7d430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc748b7de80>]}


============================== 22:01:52.183543 | a9efd601-3fb8-409d-9d44-e0c05c99021d ==============================
[0m22:01:52.183543 [info ] [MainThread]: Running with dbt=1.8.8
[0m22:01:52.184850 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'invocation_command': 'dbt run --select cohorts_beginner', 'target_path': 'None', 'write_json': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'no_print': 'None', 'empty': 'False', 'partial_parse': 'True', 'printer_width': '80', 'use_colors': 'True', 'debug': 'False', 'introspect': 'True', 'warn_error': 'None', 'quiet': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/Users/david/.dbt', 'fail_fast': 'False', 'log_format': 'default', 'indirect_selection': 'eager'}
[0m22:01:58.677595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a9efd601-3fb8-409d-9d44-e0c05c99021d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc74cc1fa30>]}
[0m22:01:58.760296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a9efd601-3fb8-409d-9d44-e0c05c99021d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc74cbd7ca0>]}
[0m22:01:58.761623 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:01:58.800019 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m22:01:59.195416 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:01:59.196064 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:01:59.283394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a9efd601-3fb8-409d-9d44-e0c05c99021d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc74cf79130>]}
[0m22:01:59.656164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a9efd601-3fb8-409d-9d44-e0c05c99021d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc74cd0ea30>]}
[0m22:01:59.656979 [info ] [MainThread]: Found 7 models, 2 seeds, 1 operation, 480 macros
[0m22:01:59.657552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9efd601-3fb8-409d-9d44-e0c05c99021d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc746d2f550>]}
[0m22:01:59.659180 [info ] [MainThread]: 
[0m22:01:59.660175 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:01:59.661590 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m22:01:59.662183 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:02:02.816780 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m22:02:02.818619 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:02:03.515702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9efd601-3fb8-409d-9d44-e0c05c99021d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc74ccb4070>]}
[0m22:02:03.516638 [info ] [MainThread]: 
[0m22:02:03.517287 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:02:03.538692 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m22:02:03.548399 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m22:02:03.549317 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:02:03.550094 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m22:02:04.189016 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:9a666937-5ba7-4f5f-948f-05e3b6c71a6d&page=queryresults
[0m22:02:05.901241 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.35s]
[0m22:02:05.902525 [info ] [MainThread]: 
[0m22:02:05.903590 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:02:05.904254 [info ] [MainThread]: 
[0m22:02:05.909423 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_beginner
[0m22:02:05.911164 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cohorts_beginner ...................... [RUN]
[0m22:02:05.913427 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cohorts_beginner)
[0m22:02:05.914627 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_beginner
[0m22:02:05.921965 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_beginner"
[0m22:02:05.923186 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_beginner
[0m22:02:05.988554 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_beginner"
[0m22:02:05.989788 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:02:05.990577 [debug] [Thread-1  ]: On model.creditrisk.cohorts_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_beginner"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohorts_beginner`
  OPTIONS()
  as /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the beginner core dataset, and produces information on raw payments only.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

filtered as (
    SELECT 
        * 
    FROM accounts_history
    -- optional : downsampling results to 1 point every 30 days. Often sufficient.
    WHERE  MOD(reporting_day, 30) = 1 
    -- removing the end of cohorts where calculation is not representative of the whole cohort
    QUALIFY reporting_day <= MIN(account_age_in_days) OVER(PARTITION BY cohort_month) 
)

-- Aggregating results on a cohort level
SELECT 
    cohort,
    reporting_day,
    SUM(paid_total) / SUM(unlock_price) as amount_paid_percent,
FROM filtered
GROUP BY ALL;


[0m22:02:06.752573 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:9877870e-9e3b-47ee-8418-07f2b83ab0d7&page=queryresults
[0m22:02:07.090855 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: cohort at [27:5]; reason: invalidQuery, location: query, message: Unrecognized name: cohort at [27:5]')
[0m22:02:07.652691 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:08249f77-ccb0-4b04-b97d-0c6bcacdac2e&page=queryresults
[0m22:02:07.953144 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:08249f77-ccb0-4b04-b97d-0c6bcacdac2e&page=queryresults
[0m22:02:07.971138 [debug] [Thread-1  ]: Database Error in model cohorts_beginner (models/example/2_cohort_visualizations/cohorts_beginner.sql)
  Unrecognized name: cohort at [27:5]
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_beginner.sql
[0m22:02:07.973761 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9efd601-3fb8-409d-9d44-e0c05c99021d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc74d8386d0>]}
[0m22:02:07.974889 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.cohorts_beginner ............. [[31mERROR[0m in 2.06s]
[0m22:02:07.976030 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_beginner
[0m22:02:07.979003 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:02:07.980088 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_beginner' was properly closed.
[0m22:02:07.980684 [info ] [MainThread]: 
[0m22:02:07.981457 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 8.32 seconds (8.32s).
[0m22:02:07.982985 [debug] [MainThread]: Command end result
[0m22:02:08.073601 [info ] [MainThread]: 
[0m22:02:08.074885 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:02:08.076022 [info ] [MainThread]: 
[0m22:02:08.078345 [error] [MainThread]:   Database Error in model cohorts_beginner (models/example/2_cohort_visualizations/cohorts_beginner.sql)
  Unrecognized name: cohort at [27:5]
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_beginner.sql
[0m22:02:08.080589 [info ] [MainThread]: 
[0m22:02:08.082641 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m22:02:08.084680 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 16.009256, "process_user_time": 6.999031, "process_kernel_time": 1.365149, "process_mem_max_rss": "228093952", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:02:08.085965 [debug] [MainThread]: Command `dbt run` failed at 22:02:08.085772 after 16.01 seconds
[0m22:02:08.086788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc746a32580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc746d00bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc74cd51220>]}
[0m22:02:08.087472 [debug] [MainThread]: Flushing usage events
[0m22:04:53.202600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb5e25d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb60268d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb602683d0>]}


============================== 22:04:53.207236 | 87da9dbf-5932-4f32-b8ff-d34b9660be75 ==============================
[0m22:04:53.207236 [info ] [MainThread]: Running with dbt=1.8.8
[0m22:04:53.208165 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'target_path': 'None', 'printer_width': '80', 'invocation_command': 'dbt run --select cohorts_beginner', 'fail_fast': 'False', 'quiet': 'False', 'introspect': 'True', 'version_check': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'use_colors': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'indirect_selection': 'eager', 'empty': 'False', 'profiles_dir': '/Users/david/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'static_parser': 'True', 'log_format': 'default', 'write_json': 'True'}
[0m22:04:57.260588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '87da9dbf-5932-4f32-b8ff-d34b9660be75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb6451f670>]}
[0m22:04:57.339994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '87da9dbf-5932-4f32-b8ff-d34b9660be75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb5fb392e0>]}
[0m22:04:57.340952 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:04:57.379146 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m22:04:57.761342 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:04:57.761961 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:04:57.844399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '87da9dbf-5932-4f32-b8ff-d34b9660be75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb64a79130>]}
[0m22:04:58.107951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '87da9dbf-5932-4f32-b8ff-d34b9660be75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb64a459d0>]}
[0m22:04:58.108742 [info ] [MainThread]: Found 7 models, 2 seeds, 1 operation, 480 macros
[0m22:04:58.109291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '87da9dbf-5932-4f32-b8ff-d34b9660be75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb64a8ab80>]}
[0m22:04:58.110897 [info ] [MainThread]: 
[0m22:04:58.111734 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:04:58.112952 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m22:04:58.113663 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:05:01.341317 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m22:05:01.342302 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:05:01.997680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '87da9dbf-5932-4f32-b8ff-d34b9660be75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb64538a90>]}
[0m22:05:01.998562 [info ] [MainThread]: 
[0m22:05:01.999160 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:05:02.016899 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m22:05:02.024658 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m22:05:02.025513 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:05:02.026258 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m22:05:02.616979 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:97d8d908-e175-4af3-8f8e-db453d821e16&page=queryresults
[0m22:05:04.277464 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.25s]
[0m22:05:04.278132 [info ] [MainThread]: 
[0m22:05:04.278858 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:05:04.279359 [info ] [MainThread]: 
[0m22:05:04.283153 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_beginner
[0m22:05:04.284361 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cohorts_beginner ...................... [RUN]
[0m22:05:04.285251 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cohorts_beginner)
[0m22:05:04.285857 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_beginner
[0m22:05:04.290670 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_beginner"
[0m22:05:04.291906 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_beginner
[0m22:05:04.341104 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_beginner"
[0m22:05:04.343411 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:05:04.344405 [debug] [Thread-1  ]: On model.creditrisk.cohorts_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_beginner"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohorts_beginner`
  OPTIONS()
  as /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the beginner core dataset. 
    Produces information on raw payments only.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

filtered as (
    SELECT 
        * 
    FROM accounts_history
    -- optional : downsampling results to 1 point every 30 days. Often sufficient.
    WHERE  MOD(reporting_day, 30) = 1 
    -- removing the end of cohorts where calculation is not representative of the whole cohort
    QUALIFY reporting_day <= MIN(account_age_in_days) OVER(PARTITION BY cohort_month) 
)

-- Aggregating results on a cohort level
SELECT 
    cohort_month,
    reporting_day,
    SUM(paid_total) / SUM(unlock_price) as amount_paid_percent,
FROM filtered
GROUP BY ALL;


[0m22:05:05.081530 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:d0832c1c-2883-4dd1-b47c-ec6cd59948b7&page=queryresults
[0m22:05:05.808062 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '87da9dbf-5932-4f32-b8ff-d34b9660be75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb65102820>]}
[0m22:05:05.809083 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.cohorts_beginner ................. [[32mCREATE VIEW (0 processed)[0m in 1.52s]
[0m22:05:05.810051 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_beginner
[0m22:05:05.811746 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:05:05.812229 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_beginner' was properly closed.
[0m22:05:05.812778 [info ] [MainThread]: 
[0m22:05:05.813344 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 7.70 seconds (7.70s).
[0m22:05:05.814368 [debug] [MainThread]: Command end result
[0m22:05:05.873310 [info ] [MainThread]: 
[0m22:05:05.874239 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:05:05.874912 [info ] [MainThread]: 
[0m22:05:05.875603 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:05:05.876520 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.763528, "process_user_time": 5.863736, "process_kernel_time": 1.025358, "process_mem_max_rss": "227291136", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:05:05.877460 [debug] [MainThread]: Command `dbt run` succeeded at 22:05:05.877293 after 12.76 seconds
[0m22:05:05.878085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb5e25d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb5e570940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb5fb3f910>]}
[0m22:05:05.878695 [debug] [MainThread]: Flushing usage events
[0m22:05:17.759268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6ea260580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6ec276430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6ec276e80>]}


============================== 22:05:17.764714 | 22f3b36e-05b7-4f59-9483-769813b8b84e ==============================
[0m22:05:17.764714 [info ] [MainThread]: Running with dbt=1.8.8
[0m22:05:17.765742 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'no_print': 'None', 'partial_parse': 'True', 'introspect': 'True', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'debug': 'False', 'profiles_dir': '/Users/david/.dbt', 'target_path': 'None', 'quiet': 'False', 'invocation_command': 'dbt run --select cohorts_advanced', 'use_experimental_parser': 'False', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'version_check': 'True', 'empty': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'warn_error': 'None'}
[0m22:05:21.995010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '22f3b36e-05b7-4f59-9483-769813b8b84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6efd83ee0>]}
[0m22:05:22.083306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '22f3b36e-05b7-4f59-9483-769813b8b84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6efcd6d30>]}
[0m22:05:22.084401 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:05:22.124055 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m22:05:22.480684 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:05:22.481245 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:05:22.557178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22f3b36e-05b7-4f59-9483-769813b8b84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6f0979130>]}
[0m22:05:22.805233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22f3b36e-05b7-4f59-9483-769813b8b84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6f066c490>]}
[0m22:05:22.806030 [info ] [MainThread]: Found 7 models, 2 seeds, 1 operation, 480 macros
[0m22:05:22.806585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22f3b36e-05b7-4f59-9483-769813b8b84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6ec05c640>]}
[0m22:05:22.808230 [info ] [MainThread]: 
[0m22:05:22.809043 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:05:22.810295 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m22:05:22.810907 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:05:25.967532 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m22:05:25.969270 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:05:26.578490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22f3b36e-05b7-4f59-9483-769813b8b84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6f059edf0>]}
[0m22:05:26.579342 [info ] [MainThread]: 
[0m22:05:26.579942 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:05:26.597978 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m22:05:26.608411 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m22:05:26.609289 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:05:26.610048 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m22:05:27.264617 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:4d7e4cd7-d270-4605-b934-e9acb8edd12a&page=queryresults
[0m22:05:28.672041 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.06s]
[0m22:05:28.673200 [info ] [MainThread]: 
[0m22:05:28.674686 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:05:28.675676 [info ] [MainThread]: 
[0m22:05:28.681455 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_advanced
[0m22:05:28.682471 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cohorts_advanced ...................... [RUN]
[0m22:05:28.683934 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cohorts_advanced)
[0m22:05:28.684758 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_advanced
[0m22:05:28.692874 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_advanced"
[0m22:05:28.694863 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_advanced
[0m22:05:28.749810 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_advanced"
[0m22:05:28.751421 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:05:28.753006 [debug] [Thread-1  ]: On model.creditrisk.cohorts_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_advanced"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohorts_advanced`
  OPTIONS()
  as /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the advanced core dataset.
    Produces information on linearized payments and with a term elapsed in % excluding downpayment.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

perc_elapsed as (
  SELECT 
    *,
    SAFE_DIVIDE(reporting_day_excl_dp, nominal_term_excl_dp) as perc_term_elapsed,
  FROM accounts_history
),

approximating as (
  SELECT
    *,
    -- Flooring the perc paid to the next 5% (we could choose another grain)
    FLOOR(perc_term_elapsed * 20) * 5 as perc_term_elapsed_approx,
  FROM perc_elapsed
)

SELECT * FROM approximating
WHERE perc_term_elapsed_approx <= 200
QUALIFY ROW_NUMBER() OVER(PARTITION BY account_id, CAST(perc_term_elapsed_approx AS STRING) ORDER BY reporting_day_excl_dp) = 1;


[0m22:05:29.529597 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:01d31ae3-cadf-4f92-83dc-a7bf786ecaa2&page=queryresults
[0m22:05:30.168088 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22f3b36e-05b7-4f59-9483-769813b8b84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6f1341880>]}
[0m22:05:30.169179 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.cohorts_advanced ................. [[32mCREATE VIEW (0 processed)[0m in 1.48s]
[0m22:05:30.170433 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_advanced
[0m22:05:30.172267 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:05:30.172889 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_advanced' was properly closed.
[0m22:05:30.173430 [info ] [MainThread]: 
[0m22:05:30.174021 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 7.36 seconds (7.36s).
[0m22:05:30.175144 [debug] [MainThread]: Command end result
[0m22:05:30.233283 [info ] [MainThread]: 
[0m22:05:30.234534 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:05:30.235310 [info ] [MainThread]: 
[0m22:05:30.236121 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:05:30.237136 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.60358, "process_user_time": 5.919085, "process_kernel_time": 1.035066, "process_mem_max_rss": "227225600", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:05:30.238216 [debug] [MainThread]: Command `dbt run` succeeded at 22:05:30.237984 after 12.60 seconds
[0m22:05:30.238902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6ea260580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6f03d7d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6efcd6d30>]}
[0m22:05:30.239501 [debug] [MainThread]: Flushing usage events
[0m22:16:02.097525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83fd22f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83ff231dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83ff231400>]}


============================== 22:16:02.101829 | cb6c6659-9cda-4354-881b-6ff12fcf06c9 ==============================
[0m22:16:02.101829 [info ] [MainThread]: Running with dbt=1.8.8
[0m22:16:02.102761 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'quiet': 'False', 'version_check': 'True', 'warn_error': 'None', 'write_json': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'indirect_selection': 'eager', 'introspect': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'invocation_command': 'dbt run --select cohorts_advanced', 'static_parser': 'True', 'profiles_dir': '/Users/david/.dbt', 'use_experimental_parser': 'False', 'printer_width': '80', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True'}
[0m22:16:05.759076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cb6c6659-9cda-4354-881b-6ff12fcf06c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8402ca8520>]}
[0m22:16:05.838508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cb6c6659-9cda-4354-881b-6ff12fcf06c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83ff201160>]}
[0m22:16:05.839463 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:16:05.868916 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m22:16:06.320465 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:16:06.321104 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:16:06.415926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cb6c6659-9cda-4354-881b-6ff12fcf06c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f840373a130>]}
[0m22:16:06.693470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cb6c6659-9cda-4354-881b-6ff12fcf06c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f840373baf0>]}
[0m22:16:06.694334 [info ] [MainThread]: Found 7 models, 2 seeds, 1 operation, 480 macros
[0m22:16:06.694924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb6c6659-9cda-4354-881b-6ff12fcf06c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f840374ab20>]}
[0m22:16:06.696639 [info ] [MainThread]: 
[0m22:16:06.697657 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:16:06.700311 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m22:16:06.701618 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:16:09.812768 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m22:16:09.814082 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:16:10.417910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb6c6659-9cda-4354-881b-6ff12fcf06c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8403650070>]}
[0m22:16:10.418901 [info ] [MainThread]: 
[0m22:16:10.419599 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:16:10.438662 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m22:16:10.446271 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m22:16:10.447114 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:16:10.447857 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m22:16:11.073158 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:6544a183-4551-4330-87d6-1ba6a0400ecd&page=queryresults
[0m22:16:12.438154 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 1.99s]
[0m22:16:12.438821 [info ] [MainThread]: 
[0m22:16:12.439550 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:16:12.440064 [info ] [MainThread]: 
[0m22:16:12.443197 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_advanced
[0m22:16:12.444023 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cohorts_advanced ...................... [RUN]
[0m22:16:12.445422 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cohorts_advanced)
[0m22:16:12.446059 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_advanced
[0m22:16:12.450916 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_advanced"
[0m22:16:12.452754 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_advanced
[0m22:16:12.496940 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_advanced"
[0m22:16:12.498365 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:16:12.499166 [debug] [Thread-1  ]: On model.creditrisk.cohorts_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_advanced"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohorts_advanced`
  OPTIONS()
  as /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the advanced core dataset.
    Produces information on linearized payments and with a term elapsed in % excluding downpayment.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

perc_elapsed as (
    SELECT 
        *,
        SAFE_DIVIDE(reporting_day_excl_dp, nominal_term_excl_dp) as perc_term_elapsed,
    FROM accounts_history
),

approximating as (
    SELECT
        *,
        -- Flooring the perc paid to the next 5% (we could choose another grain)
        FLOOR(perc_term_elapsed * 20) * 5 as perc_term_elapsed_approx,
    FROM perc_elapsed
),

downsampling as (
    SELECT 
        * 
    FROM approximating
    -- Optional : limit the time horizon to 200% of contractual term. Often sufficient.
    WHERE perc_term_elapsed_approx <= 200
    -- Ensure the dataset ends up with only one row per grain on % of contractual term
    QUALIFY ROW_NUMBER() OVER(PARTITION BY account_id, CAST(perc_term_elapsed_approx AS STRING) ORDER BY reporting_day_excl_dp) = 1
),

counting_accounts as (
  SELECT 
    *,
    COUNT(account_id) OVER (PARTITION BY cohort, CAST(perc_term_elapsed_approx AS INT64)) as cnt_accounts,
  FROM downsampling
),

filtering as (
    SELECT 
        *,
    FROM counting_accounts
    -- optional - removes the end of cohorts where calculation is not representative of the whole cohort. 
    -- We take 98% and not 100% as otherwise only a few outliers might prevent us from showing the cohort.
    QUALIFY cnt_accounts >= 0.98 * MAX(cnt_accounts) OVER(PARTITION BY cohort_month) 
),

aggregating as (
    SELECT 
        cohort_month,
        perc_term_elapsed_approx,
        SUM(paid_total_lin) / SUM(unlock_price - downpayment) as amount_paid_percent,
    FROM filtering
    GROUP BY ALL 
)

SELECT * FROM aggregating;


[0m22:16:13.195113 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:26b6f6ce-c52d-486f-8cdf-1cbbd2abe21b&page=queryresults
[0m22:16:13.490918 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: cohort at [44:42]; reason: invalidQuery, location: query, message: Unrecognized name: cohort at [44:42]')
[0m22:16:14.348475 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:485a5b8e-053b-4874-8981-8451681742a2&page=queryresults
[0m22:16:14.622050 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:485a5b8e-053b-4874-8981-8451681742a2&page=queryresults
[0m22:16:14.639993 [debug] [Thread-1  ]: Database Error in model cohorts_advanced (models/example/2_cohort_visualizations/cohorts_advanced.sql)
  Unrecognized name: cohort at [44:42]
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_advanced.sql
[0m22:16:14.642967 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cb6c6659-9cda-4354-881b-6ff12fcf06c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8403dbfb50>]}
[0m22:16:14.644370 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.cohorts_advanced ............. [[31mERROR[0m in 2.20s]
[0m22:16:14.645433 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_advanced
[0m22:16:14.647240 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:16:14.647754 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_advanced' was properly closed.
[0m22:16:14.648282 [info ] [MainThread]: 
[0m22:16:14.648941 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 7.95 seconds (7.95s).
[0m22:16:14.651128 [debug] [MainThread]: Command end result
[0m22:16:14.709403 [info ] [MainThread]: 
[0m22:16:14.710641 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:16:14.711207 [info ] [MainThread]: 
[0m22:16:14.711887 [error] [MainThread]:   Database Error in model cohorts_advanced (models/example/2_cohort_visualizations/cohorts_advanced.sql)
  Unrecognized name: cohort at [44:42]
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_advanced.sql
[0m22:16:14.712427 [info ] [MainThread]: 
[0m22:16:14.713002 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m22:16:14.713854 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 12.7149515, "process_user_time": 5.272713, "process_kernel_time": 0.969184, "process_mem_max_rss": "228200448", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:16:14.714776 [debug] [MainThread]: Command `dbt run` failed at 22:16:14.714608 after 12.72 seconds
[0m22:16:14.715400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83fd22f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83ff201160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83fea008e0>]}
[0m22:16:14.715992 [debug] [MainThread]: Flushing usage events
[0m22:16:20.566511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e9a22f5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e9c2f1d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e9c2f13d0>]}


============================== 22:16:20.572970 | 2cc2c2e6-4b7c-4ffc-b340-532598a9d341 ==============================
[0m22:16:20.572970 [info ] [MainThread]: Running with dbt=1.8.8
[0m22:16:20.574217 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'use_experimental_parser': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'version_check': 'True', 'write_json': 'True', 'no_print': 'None', 'invocation_command': 'dbt run --select cohorts_advanced', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'fail_fast': 'False', 'profiles_dir': '/Users/david/.dbt', 'use_colors': 'True', 'debug': 'False', 'log_format': 'default', 'printer_width': '80', 'indirect_selection': 'eager', 'warn_error': 'None', 'quiet': 'False', 'log_cache_events': 'False', 'empty': 'False', 'static_parser': 'True'}
[0m22:16:27.172991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2cc2c2e6-4b7c-4ffc-b340-532598a9d341', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e9c2a7b50>]}
[0m22:16:27.285355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2cc2c2e6-4b7c-4ffc-b340-532598a9d341', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea02d55b0>]}
[0m22:16:27.286400 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:16:27.331265 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m22:16:27.849505 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:16:27.850204 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:16:27.949304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2cc2c2e6-4b7c-4ffc-b340-532598a9d341', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea083a130>]}
[0m22:16:28.233603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2cc2c2e6-4b7c-4ffc-b340-532598a9d341', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea0802a30>]}
[0m22:16:28.234416 [info ] [MainThread]: Found 7 models, 2 seeds, 1 operation, 480 macros
[0m22:16:28.235112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2cc2c2e6-4b7c-4ffc-b340-532598a9d341', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea084ab20>]}
[0m22:16:28.236986 [info ] [MainThread]: 
[0m22:16:28.238098 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:16:28.239566 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m22:16:28.240976 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:16:31.682343 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m22:16:31.684603 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:16:32.324465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2cc2c2e6-4b7c-4ffc-b340-532598a9d341', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e9a56b940>]}
[0m22:16:32.325455 [info ] [MainThread]: 
[0m22:16:32.326432 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:16:32.351021 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m22:16:32.363678 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m22:16:32.365332 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:16:32.366299 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m22:16:33.021609 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:12696de5-07e6-4867-b608-374dfe507bec&page=queryresults
[0m22:16:34.172695 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 1.81s]
[0m22:16:34.173379 [info ] [MainThread]: 
[0m22:16:34.174178 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:16:34.175185 [info ] [MainThread]: 
[0m22:16:34.179380 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_advanced
[0m22:16:34.180393 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cohorts_advanced ...................... [RUN]
[0m22:16:34.181176 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cohorts_advanced)
[0m22:16:34.181792 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_advanced
[0m22:16:34.190276 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_advanced"
[0m22:16:34.192075 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_advanced
[0m22:16:34.253458 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_advanced"
[0m22:16:34.255620 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:16:34.256827 [debug] [Thread-1  ]: On model.creditrisk.cohorts_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_advanced"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohorts_advanced`
  OPTIONS()
  as /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the advanced core dataset.
    Produces information on linearized payments and with a term elapsed in % excluding downpayment.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

perc_elapsed as (
    SELECT 
        *,
        SAFE_DIVIDE(reporting_day_excl_dp, nominal_term_excl_dp) as perc_term_elapsed,
    FROM accounts_history
),

approximating as (
    SELECT
        *,
        -- Flooring the perc paid to the next 5% (we could choose another grain)
        FLOOR(perc_term_elapsed * 20) * 5 as perc_term_elapsed_approx,
    FROM perc_elapsed
),

downsampling as (
    SELECT 
        * 
    FROM approximating
    -- Optional : limit the time horizon to 200% of contractual term. Often sufficient.
    WHERE perc_term_elapsed_approx <= 200
    -- Ensure the dataset ends up with only one row per grain on % of contractual term
    QUALIFY ROW_NUMBER() OVER(PARTITION BY account_id, CAST(perc_term_elapsed_approx AS STRING) ORDER BY reporting_day_excl_dp) = 1
),

counting_accounts as (
  SELECT 
    *,
    COUNT(account_id) OVER (PARTITION BY cohort_month, CAST(perc_term_elapsed_approx AS INT64)) as cnt_accounts,
  FROM downsampling
),

filtering as (
    SELECT 
        *,
    FROM counting_accounts
    -- optional - removes the end of cohorts where calculation is not representative of the whole cohort. 
    -- We take 98% and not 100% as otherwise only a few outliers might prevent us from showing the cohort.
    QUALIFY cnt_accounts >= 0.98 * MAX(cnt_accounts) OVER(PARTITION BY cohort_month) 
),

aggregating as (
    SELECT 
        cohort_month,
        perc_term_elapsed_approx,
        SUM(paid_total_lin) / SUM(unlock_price - downpayment) as amount_paid_percent,
    FROM filtering
    GROUP BY ALL 
)

SELECT * FROM aggregating;


[0m22:16:34.992813 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ce2d841a-5180-4137-a26d-5480c1dfe05b&page=queryresults
[0m22:16:35.280785 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: cohort_month at [44:42]; reason: invalidQuery, location: query, message: Unrecognized name: cohort_month at [44:42]')
[0m22:16:35.786079 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:e57bba74-0fb5-40a0-a107-016d23dc2a4a&page=queryresults
[0m22:16:36.068907 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:e57bba74-0fb5-40a0-a107-016d23dc2a4a&page=queryresults
[0m22:16:36.081849 [debug] [Thread-1  ]: Database Error in model cohorts_advanced (models/example/2_cohort_visualizations/cohorts_advanced.sql)
  Unrecognized name: cohort_month at [44:42]
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_advanced.sql
[0m22:16:36.084602 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2cc2c2e6-4b7c-4ffc-b340-532598a9d341', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ea0fa8d60>]}
[0m22:16:36.086176 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.cohorts_advanced ............. [[31mERROR[0m in 1.90s]
[0m22:16:36.087865 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_advanced
[0m22:16:36.089609 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:16:36.090374 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_advanced' was properly closed.
[0m22:16:36.090855 [info ] [MainThread]: 
[0m22:16:36.091398 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 7.85 seconds (7.85s).
[0m22:16:36.092708 [debug] [MainThread]: Command end result
[0m22:16:36.144335 [info ] [MainThread]: 
[0m22:16:36.144979 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:16:36.145373 [info ] [MainThread]: 
[0m22:16:36.145900 [error] [MainThread]:   Database Error in model cohorts_advanced (models/example/2_cohort_visualizations/cohorts_advanced.sql)
  Unrecognized name: cohort_month at [44:42]
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_advanced.sql
[0m22:16:36.146347 [info ] [MainThread]: 
[0m22:16:36.146773 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m22:16:36.147401 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 15.718016, "process_user_time": 7.21954, "process_kernel_time": 1.519632, "process_mem_max_rss": "228024320", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:16:36.148081 [debug] [MainThread]: Command `dbt run` failed at 22:16:36.147962 after 15.72 seconds
[0m22:16:36.148550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e9a22f5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e9a532550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e9ba94940>]}
[0m22:16:36.148985 [debug] [MainThread]: Flushing usage events
[0m22:17:10.138451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89142215b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89161f9d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89161f93d0>]}


============================== 22:17:10.143626 | c5d8d364-9dac-4596-bed0-bb7ee32dfc1f ==============================
[0m22:17:10.143626 [info ] [MainThread]: Running with dbt=1.8.8
[0m22:17:10.144804 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'quiet': 'False', 'write_json': 'True', 'invocation_command': 'dbt run --select 1+cohorts_advanced', 'use_experimental_parser': 'False', 'introspect': 'True', 'target_path': 'None', 'fail_fast': 'False', 'log_cache_events': 'False', 'use_colors': 'True', 'static_parser': 'True', 'printer_width': '80', 'log_format': 'default', 'debug': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'empty': 'False', 'no_print': 'None', 'partial_parse': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/david/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m22:17:14.036111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c5d8d364-9dac-4596-bed0-bb7ee32dfc1f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8919d6ae80>]}
[0m22:17:14.093238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c5d8d364-9dac-4596-bed0-bb7ee32dfc1f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89161deeb0>]}
[0m22:17:14.094029 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:17:14.118805 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m22:17:14.396918 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:17:14.397401 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:17:14.458797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c5d8d364-9dac-4596-bed0-bb7ee32dfc1f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f891a87a130>]}
[0m22:17:14.624709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c5d8d364-9dac-4596-bed0-bb7ee32dfc1f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f891a8418e0>]}
[0m22:17:14.625329 [info ] [MainThread]: Found 7 models, 2 seeds, 1 operation, 480 macros
[0m22:17:14.625996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c5d8d364-9dac-4596-bed0-bb7ee32dfc1f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f891a88ab20>]}
[0m22:17:14.627428 [info ] [MainThread]: 
[0m22:17:14.628104 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:17:14.633235 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m22:17:14.633886 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:17:17.117928 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m22:17:17.118924 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:17:17.753920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c5d8d364-9dac-4596-bed0-bb7ee32dfc1f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f891a5cea00>]}
[0m22:17:17.754903 [info ] [MainThread]: 
[0m22:17:17.755598 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:17:17.775115 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m22:17:17.782527 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m22:17:17.783538 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:17:17.784354 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m22:17:18.516362 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:439d3e98-0f2d-47a6-98ed-345ba5be709f&page=queryresults
[0m22:17:19.923423 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.14s]
[0m22:17:19.924597 [info ] [MainThread]: 
[0m22:17:19.925928 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:17:19.926863 [info ] [MainThread]: 
[0m22:17:19.931767 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m22:17:19.932867 [info ] [Thread-1  ]: 1 of 2 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m22:17:19.933988 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m22:17:19.934908 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m22:17:19.943552 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m22:17:19.946097 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m22:17:19.988584 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:17:20.689565 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m22:17:20.691327 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    partition by timestamp_trunc(reporting_date, day)
    cluster by account_id

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/



WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    *,
    CASE 
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_back_on_dataset
)

SELECT * FROM final_kpis
    );
  
[0m22:17:21.174488 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ca0287c8-17f0-4b76-ae63-2d78a49c041f&page=queryresults
[0m22:18:01.581404 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5d8d364-9dac-4596-bed0-bb7ee32dfc1f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8919cba730>]}
[0m22:18:01.583217 [info ] [Thread-1  ]: 1 of 2 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 485.9 MiB processed)[0m in 41.65s]
[0m22:18:01.584229 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m22:18:01.585421 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_advanced
[0m22:18:01.586192 [info ] [Thread-1  ]: 2 of 2 START sql view model oscreditrisk.cohorts_advanced ...................... [RUN]
[0m22:18:01.586893 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_advanced, now model.creditrisk.cohorts_advanced)
[0m22:18:01.587482 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_advanced
[0m22:18:01.592770 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_advanced"
[0m22:18:01.593872 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_advanced
[0m22:18:01.625835 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_advanced"
[0m22:18:01.627217 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:18:01.628719 [debug] [Thread-1  ]: On model.creditrisk.cohorts_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_advanced"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohorts_advanced`
  OPTIONS()
  as /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the advanced core dataset.
    Produces information on linearized payments and with a term elapsed in % excluding downpayment.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

perc_elapsed as (
    SELECT 
        *,
        SAFE_DIVIDE(reporting_day_excl_dp, nominal_term_excl_dp) as perc_term_elapsed,
    FROM accounts_history
),

approximating as (
    SELECT
        *,
        -- Flooring the perc paid to the next 5% (we could choose another grain)
        FLOOR(perc_term_elapsed * 20) * 5 as perc_term_elapsed_approx,
    FROM perc_elapsed
),

downsampling as (
    SELECT 
        * 
    FROM approximating
    -- Optional : limit the time horizon to 200% of contractual term. Often sufficient.
    WHERE perc_term_elapsed_approx <= 200
    -- Ensure the dataset ends up with only one row per grain on % of contractual term
    QUALIFY ROW_NUMBER() OVER(PARTITION BY account_id, CAST(perc_term_elapsed_approx AS STRING) ORDER BY reporting_day_excl_dp) = 1
),

counting_accounts as (
  SELECT 
    *,
    COUNT(account_id) OVER (PARTITION BY cohort_month, CAST(perc_term_elapsed_approx AS INT64)) as cnt_accounts,
  FROM downsampling
),

filtering as (
    SELECT 
        *,
    FROM counting_accounts
    -- optional - removes the end of cohorts where calculation is not representative of the whole cohort. 
    -- We take 98% and not 100% as otherwise only a few outliers might prevent us from showing the cohort.
    QUALIFY cnt_accounts >= 0.98 * MAX(cnt_accounts) OVER(PARTITION BY cohort_month) 
),

aggregating as (
    SELECT 
        cohort_month,
        perc_term_elapsed_approx,
        SUM(paid_total_lin) / SUM(unlock_price - downpayment) as amount_paid_percent,
    FROM filtering
    GROUP BY ALL 
)

SELECT * FROM aggregating;


[0m22:18:02.443497 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:1cd42996-e473-46aa-9bac-43a52aa703fe&page=queryresults
[0m22:18:02.735915 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: downpayment; Did you mean down_payment? at [61:50]; reason: invalidQuery, location: query, message: Unrecognized name: downpayment; Did you mean down_payment? at [61:50]')
[0m22:18:04.071935 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:bc836f1d-4e07-4f66-905b-e59b65910530&page=queryresults
[0m22:18:04.373862 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:bc836f1d-4e07-4f66-905b-e59b65910530&page=queryresults
[0m22:18:04.389375 [debug] [Thread-1  ]: Database Error in model cohorts_advanced (models/example/2_cohort_visualizations/cohorts_advanced.sql)
  Unrecognized name: downpayment; Did you mean down_payment? at [61:50]
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_advanced.sql
[0m22:18:04.390729 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5d8d364-9dac-4596-bed0-bb7ee32dfc1f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f891b29e790>]}
[0m22:18:04.392433 [error] [Thread-1  ]: 2 of 2 ERROR creating sql view model oscreditrisk.cohorts_advanced ............. [[31mERROR[0m in 2.80s]
[0m22:18:04.394252 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_advanced
[0m22:18:04.397001 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:18:04.397728 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_advanced' was properly closed.
[0m22:18:04.399034 [info ] [MainThread]: 
[0m22:18:04.399920 [info ] [MainThread]: Finished running 1 table model, 1 view model, 1 project hook in 0 hours 0 minutes and 49.77 seconds (49.77s).
[0m22:18:04.401561 [debug] [MainThread]: Command end result
[0m22:18:04.469637 [info ] [MainThread]: 
[0m22:18:04.470740 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:18:04.471541 [info ] [MainThread]: 
[0m22:18:04.472588 [error] [MainThread]:   Database Error in model cohorts_advanced (models/example/2_cohort_visualizations/cohorts_advanced.sql)
  Unrecognized name: downpayment; Did you mean down_payment? at [61:50]
  compiled code at target/run/creditrisk/models/example/2_cohort_visualizations/cohorts_advanced.sql
[0m22:18:04.473254 [info ] [MainThread]: 
[0m22:18:04.473865 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m22:18:04.474737 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 54.450024, "process_user_time": 5.413385, "process_kernel_time": 0.922376, "process_mem_max_rss": "229748736", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:18:04.476025 [debug] [MainThread]: Command `dbt run` failed at 22:18:04.475629 after 54.45 seconds
[0m22:18:04.476849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89142215b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f891466f8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8915acd280>]}
[0m22:18:04.477820 [debug] [MainThread]: Flushing usage events
[0m22:18:25.651821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb87a33520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb89b71d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb89b710a0>]}


============================== 22:18:25.657335 | ff6245b6-661b-4c65-b734-deeac7955056 ==============================
[0m22:18:25.657335 [info ] [MainThread]: Running with dbt=1.8.8
[0m22:18:25.658289 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run --select 1+cohorts_advanced', 'empty': 'False', 'static_parser': 'True', 'warn_error': 'None', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'introspect': 'True', 'log_format': 'default', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'target_path': 'None', 'version_check': 'True', 'printer_width': '80', 'indirect_selection': 'eager', 'profiles_dir': '/Users/david/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'debug': 'False', 'quiet': 'False'}
[0m22:18:30.252169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ff6245b6-661b-4c65-b734-deeac7955056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb88573820>]}
[0m22:18:30.343261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ff6245b6-661b-4c65-b734-deeac7955056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8dbfc1c0>]}
[0m22:18:30.344481 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:18:30.381277 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m22:18:31.202773 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:18:31.203589 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:18:31.341480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ff6245b6-661b-4c65-b734-deeac7955056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8df6a130>]}
[0m22:18:31.687263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ff6245b6-661b-4c65-b734-deeac7955056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8df8e0a0>]}
[0m22:18:31.688853 [info ] [MainThread]: Found 7 models, 2 seeds, 1 operation, 480 macros
[0m22:18:31.690390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff6245b6-661b-4c65-b734-deeac7955056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8df66fd0>]}
[0m22:18:31.694930 [info ] [MainThread]: 
[0m22:18:31.698169 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:18:31.711354 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m22:18:31.712594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:18:35.098919 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m22:18:35.099919 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:18:35.673147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff6245b6-661b-4c65-b734-deeac7955056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8dd0b5b0>]}
[0m22:18:35.674089 [info ] [MainThread]: 
[0m22:18:35.674683 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:18:35.695982 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m22:18:35.705810 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m22:18:35.707010 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:18:35.707908 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m22:18:36.340140 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:de282174-2bb9-4d93-8108-497b8d4d235b&page=queryresults
[0m22:18:38.083561 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.38s]
[0m22:18:38.084271 [info ] [MainThread]: 
[0m22:18:38.085016 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:18:38.085599 [info ] [MainThread]: 
[0m22:18:38.092392 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m22:18:38.093721 [info ] [Thread-1  ]: 1 of 2 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m22:18:38.094756 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m22:18:38.096107 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m22:18:38.107550 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m22:18:38.109299 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m22:18:38.160013 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:18:38.797669 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m22:18:38.799004 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    partition by timestamp_trunc(reporting_date, day)
    cluster by account_id

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/



WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    *,
    CASE 
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_back_on_dataset
)

SELECT * FROM final_kpis
    );
  
[0m22:18:39.338361 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:a34be21e-9332-4d34-8ac2-e7aacf661df6&page=queryresults
[0m22:19:25.999793 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff6245b6-661b-4c65-b734-deeac7955056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8d5da670>]}
[0m22:19:26.001184 [info ] [Thread-1  ]: 1 of 2 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 485.9 MiB processed)[0m in 47.90s]
[0m22:19:26.002235 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m22:19:26.003640 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_advanced
[0m22:19:26.004500 [info ] [Thread-1  ]: 2 of 2 START sql view model oscreditrisk.cohorts_advanced ...................... [RUN]
[0m22:19:26.005292 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_advanced, now model.creditrisk.cohorts_advanced)
[0m22:19:26.005900 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_advanced
[0m22:19:26.010918 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_advanced"
[0m22:19:26.012022 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_advanced
[0m22:19:26.041340 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_advanced"
[0m22:19:26.043287 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:19:26.044196 [debug] [Thread-1  ]: On model.creditrisk.cohorts_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_advanced"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohorts_advanced`
  OPTIONS()
  as /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the advanced core dataset.
    Produces information on linearized payments and with a term elapsed in % excluding downpayment.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

perc_elapsed as (
    SELECT 
        *,
        SAFE_DIVIDE(reporting_day_excl_dp, nominal_term_excl_dp) as perc_term_elapsed,
    FROM accounts_history
),

approximating as (
    SELECT
        *,
        -- Flooring the perc paid to the next 5% (we could choose another grain)
        FLOOR(perc_term_elapsed * 20) * 5 as perc_term_elapsed_approx,
    FROM perc_elapsed
),

downsampling as (
    SELECT 
        * 
    FROM approximating
    -- Optional : limit the time horizon to 200% of contractual term. Often sufficient.
    WHERE perc_term_elapsed_approx <= 200
    -- Ensure the dataset ends up with only one row per grain on % of contractual term
    QUALIFY ROW_NUMBER() OVER(PARTITION BY account_id, CAST(perc_term_elapsed_approx AS STRING) ORDER BY reporting_day_excl_dp) = 1
),

counting_accounts as (
  SELECT 
    *,
    COUNT(account_id) OVER (PARTITION BY cohort_month, CAST(perc_term_elapsed_approx AS INT64)) as cnt_accounts,
  FROM downsampling
),

filtering as (
    SELECT 
        *,
    FROM counting_accounts
    -- optional - removes the end of cohorts where calculation is not representative of the whole cohort. 
    -- We take 98% and not 100% as otherwise only a few outliers might prevent us from showing the cohort.
    QUALIFY cnt_accounts >= 0.98 * MAX(cnt_accounts) OVER(PARTITION BY cohort_month) 
),

aggregating as (
    SELECT 
        cohort_month,
        perc_term_elapsed_approx,
        SUM(paid_total_lin) / SUM(unlock_price - down_payment) as amount_paid_percent,
    FROM filtering
    GROUP BY ALL 
)

SELECT * FROM aggregating;


[0m22:19:26.844466 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:a058c943-aacc-49c0-949e-adae4cafbf97&page=queryresults
[0m22:19:27.534499 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff6245b6-661b-4c65-b734-deeac7955056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8e85e5b0>]}
[0m22:19:27.535554 [info ] [Thread-1  ]: 2 of 2 OK created sql view model oscreditrisk.cohorts_advanced ................. [[32mCREATE VIEW (0 processed)[0m in 1.53s]
[0m22:19:27.536873 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_advanced
[0m22:19:27.538738 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:19:27.539458 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_advanced' was properly closed.
[0m22:19:27.540643 [info ] [MainThread]: 
[0m22:19:27.542321 [info ] [MainThread]: Finished running 1 table model, 1 view model, 1 project hook in 0 hours 0 minutes and 55.84 seconds (55.84s).
[0m22:19:27.544602 [debug] [MainThread]: Command end result
[0m22:19:27.613385 [info ] [MainThread]: 
[0m22:19:27.614326 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:19:27.614920 [info ] [MainThread]: 
[0m22:19:27.615546 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m22:19:27.616454 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 62.06488, "process_user_time": 6.502736, "process_kernel_time": 1.218672, "process_mem_max_rss": "228012032", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:19:27.617958 [debug] [MainThread]: Command `dbt run` succeeded at 22:19:27.617745 after 62.07 seconds
[0m22:19:27.618777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb87a33520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8dfc3a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8dbfc1c0>]}
[0m22:19:27.619498 [debug] [MainThread]: Flushing usage events
[0m22:34:28.593723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07325d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa075a6e280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa075a6ec40>]}


============================== 22:34:28.599154 | 48071f7d-c715-47bc-95dd-97094dd3bece ==============================
[0m22:34:28.599154 [info ] [MainThread]: Running with dbt=1.8.8
[0m22:34:28.600231 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'indirect_selection': 'eager', 'profiles_dir': '/Users/david/.dbt', 'write_json': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'static_parser': 'True', 'use_colors': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'quiet': 'False', 'warn_error': 'None', 'log_cache_events': 'False', 'invocation_command': 'dbt run --select +cohorts_beginner', 'introspect': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'no_print': 'None', 'target_path': 'None', 'empty': 'False', 'fail_fast': 'False', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'printer_width': '80'}
[0m22:34:32.950414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa079da6730>]}
[0m22:34:33.025625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa079d1f400>]}
[0m22:34:33.026668 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:34:33.060639 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m22:34:33.425611 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:34:33.426521 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:34:33.508912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07a068f70>]}
[0m22:34:33.689183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07a079fa0>]}
[0m22:34:33.689959 [info ] [MainThread]: Found 8 models, 2 seeds, 1 operation, 480 macros
[0m22:34:33.690514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07a05d310>]}
[0m22:34:33.692506 [info ] [MainThread]: 
[0m22:34:33.693659 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:34:33.700775 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m22:34:33.701587 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:36.978424 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m22:34:36.980190 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:34:37.591813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa073761b20>]}
[0m22:34:37.593009 [info ] [MainThread]: 
[0m22:34:37.594116 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:34:37.624538 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m22:34:37.633956 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m22:34:37.635353 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:34:37.636269 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m22:34:38.302702 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:495b7923-ad4f-4783-94a4-821f7fc446dd&page=queryresults
[0m22:34:39.532460 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 1.90s]
[0m22:34:39.533185 [info ] [MainThread]: 
[0m22:34:39.533959 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:34:39.534475 [info ] [MainThread]: 
[0m22:34:39.538750 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m22:34:39.540031 [info ] [Thread-1  ]: 1 of 5 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m22:34:39.540922 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m22:34:39.541613 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m22:34:39.547072 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m22:34:39.548603 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m22:34:39.599213 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m22:34:39.600476 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:39.601206 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m22:34:40.383800 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:0afd55af-a6a9-451b-a58d-1c5de4ec7e6d&page=queryresults
[0m22:34:41.003502 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07a80cd00>]}
[0m22:34:41.004530 [info ] [Thread-1  ]: 1 of 5 OK created sql view model oscreditrisk.cleaned_accounts ................. [[32mCREATE VIEW (0 processed)[0m in 1.46s]
[0m22:34:41.005500 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m22:34:41.006198 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_payments
[0m22:34:41.006912 [info ] [Thread-1  ]: 2 of 5 START sql view model oscreditrisk.cleaned_payments ...................... [RUN]
[0m22:34:41.007721 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_accounts, now model.creditrisk.cleaned_payments)
[0m22:34:41.008320 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_payments
[0m22:34:41.012663 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_payments"
[0m22:34:41.013885 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_payments
[0m22:34:41.022583 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_payments"
[0m22:34:41.023821 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:41.024573 [debug] [Thread-1  ]: On model.creditrisk.cleaned_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_payments"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`
)

SELECT 
  account_id,
  CAST(down_payment             AS BOOLEAN)         as down_payment,
  CAST(payment_effective_date   AS TIMESTAMP)       as payment_effective_date,
  CAST(amount                   AS FLOAT64)         as amount,
FROM payments;


[0m22:34:41.784483 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:df74bd21-80ac-4923-a1ea-a75cdcbc2e84&page=queryresults
[0m22:34:42.501687 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07a883310>]}
[0m22:34:42.502638 [info ] [Thread-1  ]: 2 of 5 OK created sql view model oscreditrisk.cleaned_payments ................. [[32mCREATE VIEW (0 processed)[0m in 1.49s]
[0m22:34:42.503694 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_payments
[0m22:34:42.504760 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m22:34:42.505625 [info ] [Thread-1  ]: 3 of 5 START sql table model oscreditrisk.date_spine ........................... [RUN]
[0m22:34:42.506336 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_payments, now model.creditrisk.date_spine)
[0m22:34:42.506917 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m22:34:42.513557 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m22:34:42.514810 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m22:34:42.533508 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:43.548387 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m22:34:43.549653 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`date_spine`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating a dataset containing one row for each day betwee : 
    - The first day you opened an account
    - Today. With artificial data here we consider today being the day after we received the last payment.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

min_max_dates as (
    SELECT 
        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,
        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,
    FROM payments
)

SELECT
    CAST(
        TIMESTAMP_ADD(
            (SELECT min_date FROM min_max_dates), 
            INTERVAL n DAY
        ) AS TIMESTAMP
    ) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            DAY
        )
    )
) AS n
    );
  
[0m22:34:44.277022 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:a5f24616-7ba0-491e-aeb5-d88a9d060921&page=queryresults
[0m22:34:47.417922 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07a88a250>]}
[0m22:34:47.418874 [info ] [Thread-1  ]: 3 of 5 OK created sql table model oscreditrisk.date_spine ...................... [[32mCREATE TABLE (1.1k rows, 3.4 MiB processed)[0m in 4.91s]
[0m22:34:47.419819 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m22:34:47.420971 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m22:34:47.421719 [info ] [Thread-1  ]: 4 of 5 START sql table model oscreditrisk.accounts_history_beginner ............ [RUN]
[0m22:34:47.422408 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.date_spine, now model.creditrisk.accounts_history_beginner)
[0m22:34:47.422986 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_beginner
[0m22:34:47.428609 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_beginner"
[0m22:34:47.429679 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_beginner
[0m22:34:47.434512 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:48.150822 [debug] [Thread-1  ]: Hard refreshing `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner` because it is not replaceable
[0m22:34:48.501039 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_beginner"
[0m22:34:48.502341 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_beginner"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the first version of the core dataset (beginner version). 
    It is essentially : 
    - Joining the accounts dataset with a date spine for the target granuarity
    - Grouping the payment by day, and joining them to the accounts history
    - Calculating cumulated sums to describe the cumulated amount paid, and a few other useful fields
*/

WITH accounts as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

payments as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

date_spine as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

accounts_with_spine as (
  SELECT 
    *,
    TIMESTAMP_DIFF(reporting_date, registration_date, DAY) + 1 as reporting_day,
  FROM accounts
  LEFT JOIN date_spine
  ON accounts.registration_date <= date_spine.reporting_date
),

payments_grouped_by_day as (
  SELECT 
    account_id,
    
    DATE_ADD(
      DATE_TRUNC(payment_effective_date, DAY), 
      INTERVAL 1 DAY
    ) as reporting_date,

    SUM(amount) as amount,
    SUM(
      IF(not down_payment, amount, 0)
    ) as amount_excl_dp,

  FROM payments
  GROUP BY ALL
),

joint as (
  SELECT 
    * EXCEPT(amount, amount_excl_dp),
    COALESCE(amount,          0) as amount,
    COALESCE(amount_excl_dp,  0) as amount_excl_dp,
  FROM accounts_with_spine 
  LEFT JOIN payments_grouped_by_day 
  USING(account_id, reporting_date)
),

calc_paid_total as (
  SELECT 
    *,
    SUM(amount)         OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total,
    SUM(amount_excl_dp) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_excl_dp,
    
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate) + down_payment_days_included as nominal_term,
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate)                              as nominal_term_excl_dp,

    MAX(reporting_day) OVER(PARTITION BY account_id) as account_age_in_days,
    GREATEST(
            0,
            MAX(reporting_day - down_payment_days_included) OVER(PARTITION BY account_id)
    ) as account_age_excl_dp_in_days,

    DATE_TRUNC(registration_date, MONTH) as cohort_month,
    DATE_TRUNC(registration_date, QUARTER) as cohort_quarter,
    DATE_TRUNC(registration_date, YEAR) as cohort_year,

  FROM joint
)

SELECT * FROM calc_paid_total
    );
  
[0m22:34:49.571203 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:c87b4d44-2d3d-4227-958d-ec41e25697de&page=queryresults
[0m22:34:56.428300 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07a88a280>]}
[0m22:34:56.429277 [info ] [Thread-1  ]: 4 of 5 OK created sql table model oscreditrisk.accounts_history_beginner ....... [[32mCREATE TABLE (3.4m rows, 6.2 MiB processed)[0m in 9.01s]
[0m22:34:56.430241 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m22:34:56.431315 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_beginner
[0m22:34:56.432209 [info ] [Thread-1  ]: 5 of 5 START sql table model oscreditrisk.cohorts_beginner ..................... [RUN]
[0m22:34:56.432931 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_beginner, now model.creditrisk.cohorts_beginner)
[0m22:34:56.433642 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_beginner
[0m22:34:56.444373 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_beginner"
[0m22:34:56.445766 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_beginner
[0m22:34:56.451267 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:57.431011 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_beginner"
[0m22:34:57.432249 [debug] [Thread-1  ]: On model.creditrisk.cohorts_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_beginner"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`cohorts_beginner`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the beginner core dataset. 
    Produces information on raw payments only.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

filtered as (
    SELECT 
        * 
    FROM accounts_history
    -- optional : downsampling results to 1 point every 30 days. Often sufficient.
    WHERE  MOD(reporting_day, 30) = 1 
    -- optional : removing the end of cohorts where calculation is not representative of the whole cohort
    QUALIFY reporting_day <= MIN(account_age_in_days) OVER(PARTITION BY cohort_month) 
)

-- Aggregating results on a cohort level
SELECT 
    cohort_month,
    reporting_day,
    SUM(paid_total) / SUM(unlock_price) as amount_paid_percent,
FROM filtered
GROUP BY ALL
    );
  
[0m22:34:57.962959 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:2362213e-4f0c-457b-a0b8-63eca0fac116&page=queryresults
[0m22:35:01.173497 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48071f7d-c715-47bc-95dd-97094dd3bece', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07a08e280>]}
[0m22:35:01.174505 [info ] [Thread-1  ]: 5 of 5 OK created sql table model oscreditrisk.cohorts_beginner ................ [[32mCREATE TABLE (666.0 rows, 127.9 MiB processed)[0m in 4.74s]
[0m22:35:01.175502 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_beginner
[0m22:35:01.177254 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:35:01.177800 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_beginner' was properly closed.
[0m22:35:01.178467 [info ] [MainThread]: 
[0m22:35:01.179145 [info ] [MainThread]: Finished running 2 view models, 3 table models, 1 project hook in 0 hours 0 minutes and 27.48 seconds (27.48s).
[0m22:35:01.181840 [debug] [MainThread]: Command end result
[0m22:35:01.239163 [info ] [MainThread]: 
[0m22:35:01.239891 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:35:01.240420 [info ] [MainThread]: 
[0m22:35:01.240996 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m22:35:01.241826 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 32.790348, "process_user_time": 6.201594, "process_kernel_time": 1.15624, "process_mem_max_rss": "227991552", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:35:01.242720 [debug] [MainThread]: Command `dbt run` succeeded at 22:35:01.242567 after 32.79 seconds
[0m22:35:01.243376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07325d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07532f940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa079d1f400>]}
[0m22:35:01.244141 [debug] [MainThread]: Flushing usage events
[0m22:35:30.207669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb213232550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb216370d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb216370400>]}


============================== 22:35:30.212398 | b2b79b86-a56c-4880-a07b-7abe12e8c3d8 ==============================
[0m22:35:30.212398 [info ] [MainThread]: Running with dbt=1.8.8
[0m22:35:30.213385 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'partial_parse': 'True', 'log_cache_events': 'False', 'static_parser': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'write_json': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/david/.dbt', 'invocation_command': 'dbt run --select +cohorts_advanced', 'target_path': 'None', 'warn_error': 'None', 'use_colors': 'True', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'no_print': 'None', 'quiet': 'False', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'introspect': 'True', 'indirect_selection': 'eager', 'log_format': 'default'}
[0m22:35:34.005638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb219db4a90>]}
[0m22:35:34.082027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21a472250>]}
[0m22:35:34.083001 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:35:34.117060 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m22:35:34.442799 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:35:34.443464 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:35:34.531384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21a868f70>]}
[0m22:35:34.705898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21a8752b0>]}
[0m22:35:34.706677 [info ] [MainThread]: Found 8 models, 2 seeds, 1 operation, 480 macros
[0m22:35:34.707240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21a85e820>]}
[0m22:35:34.709261 [info ] [MainThread]: 
[0m22:35:34.710079 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:35:34.718625 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m22:35:34.719934 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:35:37.699417 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m22:35:37.700375 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:35:38.312934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2162fa8e0>]}
[0m22:35:38.313824 [info ] [MainThread]: 
[0m22:35:38.314398 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:35:38.338199 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m22:35:38.345748 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m22:35:38.346829 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:35:38.347626 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m22:35:39.014826 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:31b7ba0d-43a8-46ab-a3d4-3308d91d4a3d&page=queryresults
[0m22:35:40.566329 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.22s]
[0m22:35:40.566990 [info ] [MainThread]: 
[0m22:35:40.567708 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:35:40.568208 [info ] [MainThread]: 
[0m22:35:40.571029 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m22:35:40.571840 [info ] [Thread-1  ]: 1 of 6 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m22:35:40.572865 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m22:35:40.573765 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m22:35:40.578613 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m22:35:40.580262 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m22:35:40.627426 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m22:35:40.628630 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:35:40.629353 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m22:35:41.370038 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:17c8003b-e70a-4375-8ad5-c39bcac64200&page=queryresults
[0m22:35:41.979830 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21b30ec10>]}
[0m22:35:41.980842 [info ] [Thread-1  ]: 1 of 6 OK created sql view model oscreditrisk.cleaned_accounts ................. [[32mCREATE VIEW (0 processed)[0m in 1.41s]
[0m22:35:41.981829 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m22:35:41.982540 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_payments
[0m22:35:41.983383 [info ] [Thread-1  ]: 2 of 6 START sql view model oscreditrisk.cleaned_payments ...................... [RUN]
[0m22:35:41.984094 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_accounts, now model.creditrisk.cleaned_payments)
[0m22:35:41.984666 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_payments
[0m22:35:41.989130 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_payments"
[0m22:35:41.990274 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_payments
[0m22:35:41.998502 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_payments"
[0m22:35:41.999625 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:35:42.000336 [debug] [Thread-1  ]: On model.creditrisk.cleaned_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_payments"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`
)

SELECT 
  account_id,
  CAST(down_payment             AS BOOLEAN)         as down_payment,
  CAST(payment_effective_date   AS TIMESTAMP)       as payment_effective_date,
  CAST(amount                   AS FLOAT64)         as amount,
FROM payments;


[0m22:35:42.714224 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:72727e7f-9ded-4f68-9a88-4f9841238d7c&page=queryresults
[0m22:35:43.305191 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21b3a14c0>]}
[0m22:35:43.313665 [info ] [Thread-1  ]: 2 of 6 OK created sql view model oscreditrisk.cleaned_payments ................. [[32mCREATE VIEW (0 processed)[0m in 1.32s]
[0m22:35:43.314718 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_payments
[0m22:35:43.315799 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m22:35:43.316667 [info ] [Thread-1  ]: 3 of 6 START sql table model oscreditrisk.date_spine ........................... [RUN]
[0m22:35:43.317398 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_payments, now model.creditrisk.date_spine)
[0m22:35:43.317978 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m22:35:43.325464 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m22:35:43.326967 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m22:35:43.344431 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:35:43.985092 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m22:35:43.986262 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`date_spine`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating a dataset containing one row for each day betwee : 
    - The first day you opened an account
    - Today. With artificial data here we consider today being the day after we received the last payment.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

min_max_dates as (
    SELECT 
        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,
        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,
    FROM payments
)

SELECT
    CAST(
        TIMESTAMP_ADD(
            (SELECT min_date FROM min_max_dates), 
            INTERVAL n DAY
        ) AS TIMESTAMP
    ) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            DAY
        )
    )
) AS n
    );
  
[0m22:35:44.650363 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:4a370569-f221-4ccc-b582-48486edff185&page=queryresults
[0m22:35:47.936038 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21b36a880>]}
[0m22:35:47.937035 [info ] [Thread-1  ]: 3 of 6 OK created sql table model oscreditrisk.date_spine ...................... [[32mCREATE TABLE (1.1k rows, 3.4 MiB processed)[0m in 4.62s]
[0m22:35:47.937996 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m22:35:47.939090 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m22:35:47.939958 [info ] [Thread-1  ]: 4 of 6 START sql table model oscreditrisk.accounts_history_beginner ............ [RUN]
[0m22:35:47.940661 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.date_spine, now model.creditrisk.accounts_history_beginner)
[0m22:35:47.941235 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_beginner
[0m22:35:47.946767 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_beginner"
[0m22:35:47.947892 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_beginner
[0m22:35:47.952654 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:35:48.653522 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_beginner"
[0m22:35:48.654769 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_beginner"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the first version of the core dataset (beginner version). 
    It is essentially : 
    - Joining the accounts dataset with a date spine for the target granuarity
    - Grouping the payment by day, and joining them to the accounts history
    - Calculating cumulated sums to describe the cumulated amount paid, and a few other useful fields
*/

WITH accounts as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

payments as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

date_spine as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

accounts_with_spine as (
  SELECT 
    *,
    TIMESTAMP_DIFF(reporting_date, registration_date, DAY) + 1 as reporting_day,
  FROM accounts
  LEFT JOIN date_spine
  ON accounts.registration_date <= date_spine.reporting_date
),

payments_grouped_by_day as (
  SELECT 
    account_id,
    
    DATE_ADD(
      DATE_TRUNC(payment_effective_date, DAY), 
      INTERVAL 1 DAY
    ) as reporting_date,

    SUM(amount) as amount,
    SUM(
      IF(not down_payment, amount, 0)
    ) as amount_excl_dp,

  FROM payments
  GROUP BY ALL
),

joint as (
  SELECT 
    * EXCEPT(amount, amount_excl_dp),
    COALESCE(amount,          0) as amount,
    COALESCE(amount_excl_dp,  0) as amount_excl_dp,
  FROM accounts_with_spine 
  LEFT JOIN payments_grouped_by_day 
  USING(account_id, reporting_date)
),

calc_paid_total as (
  SELECT 
    *,
    SUM(amount)         OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total,
    SUM(amount_excl_dp) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_excl_dp,
    
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate) + down_payment_days_included as nominal_term,
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate)                              as nominal_term_excl_dp,

    MAX(reporting_day) OVER(PARTITION BY account_id) as account_age_in_days,
    GREATEST(
            0,
            MAX(reporting_day - down_payment_days_included) OVER(PARTITION BY account_id)
    ) as account_age_excl_dp_in_days,

    DATE_TRUNC(registration_date, MONTH) as cohort_month,
    DATE_TRUNC(registration_date, QUARTER) as cohort_quarter,
    DATE_TRUNC(registration_date, YEAR) as cohort_year,

  FROM joint
)

SELECT * FROM calc_paid_total
    );
  
[0m22:35:49.344255 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:78316519-eb89-4b19-91b2-cbbf00601c14&page=queryresults
[0m22:35:56.943892 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21b3daee0>]}
[0m22:35:56.944889 [info ] [Thread-1  ]: 4 of 6 OK created sql table model oscreditrisk.accounts_history_beginner ....... [[32mCREATE TABLE (3.4m rows, 6.2 MiB processed)[0m in 9.00s]
[0m22:35:56.945867 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m22:35:56.946941 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m22:35:56.947831 [info ] [Thread-1  ]: 5 of 6 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m22:35:56.948525 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_beginner, now model.creditrisk.accounts_history_advanced)
[0m22:35:56.949093 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m22:35:56.959261 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m22:35:56.960311 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m22:35:56.963984 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:35:57.620253 [debug] [Thread-1  ]: Hard refreshing `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced` because it is not replaceable
[0m22:35:57.939667 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m22:35:57.940949 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    *,
    CASE 
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_back_on_dataset
)

SELECT * FROM final_kpis
    );
  
[0m22:35:58.818344 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:bfe2b481-fad8-4e68-9d1f-210ddbef46c1&page=queryresults
[0m22:36:16.719274 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21b40f0a0>]}
[0m22:36:16.720657 [info ] [Thread-1  ]: 5 of 6 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 485.9 MiB processed)[0m in 19.77s]
[0m22:36:16.721635 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m22:36:16.722830 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_advanced
[0m22:36:16.723878 [info ] [Thread-1  ]: 6 of 6 START sql table model oscreditrisk.cohorts_advanced ..................... [RUN]
[0m22:36:16.724744 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_advanced, now model.creditrisk.cohorts_advanced)
[0m22:36:16.725347 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_advanced
[0m22:36:16.730414 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_advanced"
[0m22:36:16.731488 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_advanced
[0m22:36:16.736193 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:36:17.661032 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_advanced"
[0m22:36:17.662522 [debug] [Thread-1  ]: On model.creditrisk.cohorts_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`cohorts_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the advanced core dataset.
    Produces information on linearized payments and with a term elapsed in % excluding downpayment.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

perc_elapsed as (
    SELECT 
        *,
        SAFE_DIVIDE(reporting_day_excl_dp, nominal_term_excl_dp) as perc_term_elapsed,
    FROM accounts_history
),

approximating as (
    SELECT
        *,
        -- Flooring the perc paid to the next 5% (we could choose another grain)
        FLOOR(perc_term_elapsed * 20) * 5 as perc_term_elapsed_approx,
    FROM perc_elapsed
),

downsampling as (
    SELECT 
        * 
    FROM approximating
    -- Optional : limit the time horizon to 200% of contractual term. Often sufficient.
    WHERE perc_term_elapsed_approx <= 200
    -- Ensure the dataset ends up with only one row per grain on % of contractual term
    QUALIFY ROW_NUMBER() OVER(PARTITION BY account_id, CAST(perc_term_elapsed_approx AS STRING) ORDER BY reporting_day_excl_dp) = 1
),

counting_accounts as (
  SELECT 
    *,
    COUNT(account_id) OVER (PARTITION BY cohort_month, CAST(perc_term_elapsed_approx AS INT64)) as cnt_accounts,
  FROM downsampling
),

filtering as (
    SELECT 
        *,
    FROM counting_accounts
    -- optional - removes the end of cohorts where calculation is not representative of the whole cohort. 
    -- We take 98% and not 100% as otherwise only a few outliers might prevent us from showing the cohort.
    QUALIFY cnt_accounts >= 0.98 * MAX(cnt_accounts) OVER(PARTITION BY cohort_month) 
),

aggregating as (
    SELECT 
        cohort_month,
        perc_term_elapsed_approx,
        SUM(paid_total_lin) / SUM(unlock_price - down_payment) as amount_paid_percent,
    FROM filtering
    GROUP BY ALL 
)

SELECT * FROM aggregating
    );
  
[0m22:36:18.202680 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5473c121-311a-4b29-ba17-02bed2007a71&page=queryresults
[0m22:36:22.857286 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2b79b86-a56c-4880-a07b-7abe12e8c3d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21b43d550>]}
[0m22:36:22.858931 [info ] [Thread-1  ]: 6 of 6 OK created sql table model oscreditrisk.cohorts_advanced ................ [[32mCREATE TABLE (693.0 rows, 178.4 MiB processed)[0m in 6.13s]
[0m22:36:22.860440 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_advanced
[0m22:36:22.862770 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:36:22.863897 [debug] [MainThread]: Connection 'model.creditrisk.cohorts_advanced' was properly closed.
[0m22:36:22.864600 [info ] [MainThread]: 
[0m22:36:22.865177 [info ] [MainThread]: Finished running 2 view models, 4 table models, 1 project hook in 0 hours 0 minutes and 48.15 seconds (48.15s).
[0m22:36:22.868815 [debug] [MainThread]: Command end result
[0m22:36:22.960375 [info ] [MainThread]: 
[0m22:36:22.961670 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:36:22.962863 [info ] [MainThread]: 
[0m22:36:22.964269 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m22:36:22.966569 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 52.856236, "process_user_time": 5.868592, "process_kernel_time": 0.949698, "process_mem_max_rss": "227819520", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:36:22.968713 [debug] [MainThread]: Command `dbt run` succeeded at 22:36:22.968472 after 52.86 seconds
[0m22:36:22.969715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb213232550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21a7db760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb21a527a90>]}
[0m22:36:22.970856 [debug] [MainThread]: Flushing usage events
[0m23:14:10.368328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f682215e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f6a231d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f6a2313d0>]}


============================== 23:14:10.374792 | 4562be51-3644-41ac-af62-40d489454887 ==============================
[0m23:14:10.374792 [info ] [MainThread]: Running with dbt=1.8.8
[0m23:14:10.377761 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'printer_width': '80', 'use_colors': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select cohort_projection_model', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'write_json': 'True', 'introspect': 'True', 'partial_parse': 'True', 'profiles_dir': '/Users/david/.dbt', 'debug': 'False', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False'}
[0m23:14:15.185606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4562be51-3644-41ac-af62-40d489454887', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f6e41fd60>]}
[0m23:14:15.264633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4562be51-3644-41ac-af62-40d489454887', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f699ca2e0>]}
[0m23:14:15.265587 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m23:14:15.297183 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m23:14:15.636059 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:14:15.636611 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:14:15.719013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4562be51-3644-41ac-af62-40d489454887', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f6e967dc0>]}
[0m23:14:15.915509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4562be51-3644-41ac-af62-40d489454887', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f6e976e20>]}
[0m23:14:15.916393 [info ] [MainThread]: Found 8 models, 2 seeds, 1 operation, 480 macros
[0m23:14:15.917036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4562be51-3644-41ac-af62-40d489454887', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f6e92ac40>]}
[0m23:14:15.918918 [info ] [MainThread]: 
[0m23:14:15.919989 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m23:14:15.921205 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m23:14:15.921841 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:14:19.053391 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m23:14:19.054347 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:14:19.646815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4562be51-3644-41ac-af62-40d489454887', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f6dca8730>]}
[0m23:14:19.647668 [info ] [MainThread]: 
[0m23:14:19.648249 [info ] [MainThread]: Running 1 on-run-start hook
[0m23:14:19.671325 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m23:14:19.681384 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m23:14:19.682312 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:14:19.683211 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m23:14:20.330450 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:322a8b6c-ba74-4d10-aad9-47931bd8d3ed&page=queryresults
[0m23:14:22.096598 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.41s]
[0m23:14:22.097358 [info ] [MainThread]: 
[0m23:14:22.098259 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:14:22.098849 [info ] [MainThread]: 
[0m23:14:22.103330 [debug] [Thread-1  ]: Began running node model.creditrisk.cohort_projection_model
[0m23:14:22.104622 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cohort_projection_model ............... [RUN]
[0m23:14:22.105861 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cohort_projection_model)
[0m23:14:22.106584 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohort_projection_model
[0m23:14:22.113382 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohort_projection_model"
[0m23:14:22.114673 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohort_projection_model
[0m23:14:22.186492 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohort_projection_model"
[0m23:14:22.187811 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:14:22.188995 [debug] [Thread-1  ]: On model.creditrisk.cohort_projection_model: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohort_projection_model"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohort_projection_model`
  OPTIONS()
  as WITH cohorts as (
    SELECT 
        *, 
        (reporting_day - 1) / 30 as reporting_month, 
        CASE
            WHEN reporting_day = 1 THEN amount_paid_percent
            ELSE amount_paid_percent - LAG(amount_paid_percent) OVER(PARTITION BY cohort_month ORDER BY reporting_day)
        END as amount_paid_percent_incr, 
    FROM `steam-outlet-209412`.`oscreditrisk`.`cohorts_beginner`
),

-- Step 1 : Building a reference dataset : containing for each month, the reference point for the last 6 available cohorts
last_6_reference as (
    SELECT 
        *,
    FROM cohorts
    QUALIFY ROW_NUMBER() OVER(PARTITION BY CAST(reporting_month AS INT64) ORDER BY cohort_month DESC) <= 6
),

last_6_aggregated as (
    SELECT 
        reporting_month,
        AVG(amount_paid_percent_incr)                           as projected_paid_percent_incr,
        AVG(amount_paid_percent - amount_paid_percent_incr)     as reference_paid_percent, -- this field will serve to apply the scale factor
    FROM last_6_reference
    GROUP BY ALL
),

-- Step 2 : Let's build the full dataset of cohorts including future months
cohort_months as (
    SELECT DISTINCT cohort_month FROM cohorts
),

reporting_months as (
    SELECT DISTINCT reporting_month FROM cohorts
),

full_cohort_spine as (
    SELECT * FROM cohort_months
    CROSS JOIN reporting_months
),

-- Step 3 : Joining the data back in this target dataset
joint as (
    SELECT 
        full_cohort_spine.*,
        cohorts.amount_paid_percent,
        cohorts.amount_paid_percent_incr,
    FROM full_cohort_spine 
    LEFT JOIN cohorts USING(cohort_month, reporting_month)
),

joint_with_projections as (
    SELECT 
        joint.*,
        last_6_aggregated.projected_paid_percent_incr,
        last_6_aggregated.reference_paid_percent,
        MAX(joint.amount_paid_percent) OVER(PARTITION BY cohort_month) / MIN(last_6_aggregated.reference_paid_percent) OVER(PARTITION BY cohort_month) as scale_factor,
    FROM joint 
    LEFT JOIN last_6_aggregated
    ON 
        joint.amount_paid_percent IS NULL AND 
        joint.reporting_month = last_6_aggregated.reporting_month
),

-- Step 4 : combine actuals and predictions, and calculate cumulative values
projected_and_actuals as (
    SELECT 
    *,
    COALESCE(amount_paid_percent_incr, projected_paid_percent_incr)                 as projected_and_actual_amount_paid_percent_incr,
    COALESCE(amount_paid_percent_incr, projected_paid_percent_incr * scale_factor)  as projected_and_actual_amount_paid_percent_incr_with_scale_factor,
    FROM joint_with_projections 
    GROUP BY ALL
)

SELECT 
    *,
    SUM(projected_and_actual_amount_paid_percent_incr) OVER(
        PARTITION BY cohort_month ORDER BY reporting_month ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
    ) as projected_and_actual_amount_paid_percent,
    SUM(projected_and_actual_amount_paid_percent_incr_with_scale_factor) OVER(
        PARTITION BY cohort_month ORDER BY reporting_month ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
    ) as projected_and_actual_amount_paid_percent_with_scale_factor,
FROM projected_and_actuals
ORDER BY 1, 2;


[0m23:14:22.993969 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:bc391ced-4d1a-4177-b9e7-7a68738af26f&page=queryresults
[0m23:14:23.668115 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4562be51-3644-41ac-af62-40d489454887', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f6f109820>]}
[0m23:14:23.669333 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.cohort_projection_model .......... [[32mCREATE VIEW (0 processed)[0m in 1.56s]
[0m23:14:23.671016 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohort_projection_model
[0m23:14:23.673253 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:14:23.674363 [debug] [MainThread]: Connection 'model.creditrisk.cohort_projection_model' was properly closed.
[0m23:14:23.675473 [info ] [MainThread]: 
[0m23:14:23.676222 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 7.76 seconds (7.76s).
[0m23:14:23.677873 [debug] [MainThread]: Command end result
[0m23:14:23.745592 [info ] [MainThread]: 
[0m23:14:23.746602 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:14:23.747459 [info ] [MainThread]: 
[0m23:14:23.748596 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:14:23.749811 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 13.50032, "process_user_time": 6.270182, "process_kernel_time": 1.104034, "process_mem_max_rss": "225443840", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:14:23.751058 [debug] [MainThread]: Command `dbt run` succeeded at 23:14:23.750859 after 13.50 seconds
[0m23:14:23.752266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f682215e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f699c9910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f699ca2e0>]}
[0m23:14:23.753080 [debug] [MainThread]: Flushing usage events
[0m00:37:44.977045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7850d2f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7855b71d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7855b713d0>]}


============================== 00:37:44.982130 | b3fc8471-18ed-44ef-befa-6b59a2d2b27b ==============================
[0m00:37:44.982130 [info ] [MainThread]: Running with dbt=1.8.8
[0m00:37:44.982972 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'log_cache_events': 'False', 'write_json': 'True', 'empty': 'None', 'log_format': 'default', 'partial_parse': 'True', 'static_parser': 'True', 'no_print': 'None', 'invocation_command': 'dbt seed --select raw_write_offs', 'target_path': 'None', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'warn_error': 'None', 'printer_width': '80', 'quiet': 'False', 'introspect': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'profiles_dir': '/Users/david/.dbt', 'debug': 'False', 'indirect_selection': 'eager'}
[0m00:37:49.146432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b3fc8471-18ed-44ef-befa-6b59a2d2b27b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f785a565e80>]}
[0m00:37:49.201570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b3fc8471-18ed-44ef-befa-6b59a2d2b27b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7855b50eb0>]}
[0m00:37:49.202282 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:37:49.228163 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m00:37:49.573752 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m00:37:49.574433 [debug] [MainThread]: Partial parsing: added file: creditrisk://seeds/raw_write_offs.csv
[0m00:37:49.812795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3fc8471-18ed-44ef-befa-6b59a2d2b27b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f785b193f10>]}
[0m00:37:49.979109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b3fc8471-18ed-44ef-befa-6b59a2d2b27b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f785b13a430>]}
[0m00:37:49.979815 [info ] [MainThread]: Found 8 models, 3 seeds, 1 operation, 480 macros
[0m00:37:49.980314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b3fc8471-18ed-44ef-befa-6b59a2d2b27b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f785b183070>]}
[0m00:37:49.981760 [info ] [MainThread]: 
[0m00:37:49.982480 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:37:49.983539 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m00:37:49.984035 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:37:53.137908 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m00:37:53.139737 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:37:53.758733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b3fc8471-18ed-44ef-befa-6b59a2d2b27b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f785b1b7610>]}
[0m00:37:53.759789 [info ] [MainThread]: 
[0m00:37:53.760369 [info ] [MainThread]: Running 1 on-run-start hook
[0m00:37:53.776715 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m00:37:53.785702 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m00:37:53.786535 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:37:53.787285 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m00:37:54.535908 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:91d887ab-75be-47c0-9cae-f05b790a4db8&page=queryresults
[0m00:37:55.831273 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.04s]
[0m00:37:55.832125 [info ] [MainThread]: 
[0m00:37:55.832994 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:37:55.833610 [info ] [MainThread]: 
[0m00:37:55.838111 [debug] [Thread-1  ]: Began running node seed.creditrisk.raw_write_offs
[0m00:37:55.839031 [info ] [Thread-1  ]: 1 of 1 START seed file oscreditrisk.raw_write_offs ............................. [RUN]
[0m00:37:55.839790 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now seed.creditrisk.raw_write_offs)
[0m00:37:55.840394 [debug] [Thread-1  ]: Began compiling node seed.creditrisk.raw_write_offs
[0m00:37:55.841007 [debug] [Thread-1  ]: Began executing node seed.creditrisk.raw_write_offs
[0m00:37:55.929477 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:38:01.169323 [debug] [Thread-1  ]: On seed.creditrisk.raw_write_offs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "seed.creditrisk.raw_write_offs"} */

    alter table `steam-outlet-209412`.`oscreditrisk`.`raw_write_offs` set OPTIONS()
  
[0m00:38:01.696242 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:a27cdf48-5e21-494c-bbec-cd47af03b13f&page=queryresults
[0m00:38:02.318941 [debug] [Thread-1  ]: Writing runtime SQL for node "seed.creditrisk.raw_write_offs"
[0m00:38:02.345928 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3fc8471-18ed-44ef-befa-6b59a2d2b27b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7854b762b0>]}
[0m00:38:02.346797 [info ] [Thread-1  ]: 1 of 1 OK loaded seed file oscreditrisk.raw_write_offs ......................... [[32mINSERT 1549[0m in 6.50s]
[0m00:38:02.347740 [debug] [Thread-1  ]: Finished running node seed.creditrisk.raw_write_offs
[0m00:38:02.349384 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:38:02.349839 [debug] [MainThread]: Connection 'seed.creditrisk.raw_write_offs' was properly closed.
[0m00:38:02.350314 [info ] [MainThread]: 
[0m00:38:02.350825 [info ] [MainThread]: Finished running 1 seed, 1 project hook in 0 hours 0 minutes and 12.37 seconds (12.37s).
[0m00:38:02.351766 [debug] [MainThread]: Command end result
[0m00:38:02.399626 [info ] [MainThread]: 
[0m00:38:02.400375 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:38:02.400859 [info ] [MainThread]: 
[0m00:38:02.401391 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m00:38:02.402170 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 17.51727, "process_user_time": 5.0999, "process_kernel_time": 0.964388, "process_mem_max_rss": "230490112", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:38:02.402987 [debug] [MainThread]: Command `dbt seed` succeeded at 00:38:02.402853 after 17.52 seconds
[0m00:38:02.403555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7850d2f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78553008e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7855b50eb0>]}
[0m00:38:02.404084 [debug] [MainThread]: Flushing usage events
[0m00:39:16.991507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc594ba3490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc597ab1dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc597ab10a0>]}


============================== 00:39:16.995691 | 9c3db80c-9950-4796-be6f-8a20e36b0157 ==============================
[0m00:39:16.995691 [info ] [MainThread]: Running with dbt=1.8.8
[0m00:39:16.996529 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'use_colors': 'True', 'log_format': 'default', 'empty': 'False', 'invocation_command': 'dbt run --select cleaned_write_offs', 'profiles_dir': '/Users/david/.dbt', 'use_experimental_parser': 'False', 'debug': 'False', 'cache_selected_only': 'False', 'introspect': 'True', 'write_json': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'version_check': 'True', 'no_print': 'None', 'quiet': 'False', 'partial_parse': 'True', 'log_cache_events': 'False', 'printer_width': '80'}
[0m00:39:20.074876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9c3db80c-9950-4796-be6f-8a20e36b0157', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5977d6ac0>]}
[0m00:39:20.132922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9c3db80c-9950-4796-be6f-8a20e36b0157', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc59bcca340>]}
[0m00:39:20.133673 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:39:20.158420 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m00:39:20.461351 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:39:20.461860 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:39:20.528495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9c3db80c-9950-4796-be6f-8a20e36b0157', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc59c966130>]}
[0m00:39:20.713380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9c3db80c-9950-4796-be6f-8a20e36b0157', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc59c98b5e0>]}
[0m00:39:20.714150 [info ] [MainThread]: Found 9 models, 3 seeds, 1 operation, 480 macros
[0m00:39:20.714670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c3db80c-9950-4796-be6f-8a20e36b0157', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc59c930e20>]}
[0m00:39:20.716248 [info ] [MainThread]: 
[0m00:39:20.717030 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:39:20.718204 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m00:39:20.718829 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:39:23.748999 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m00:39:23.750059 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:39:24.401104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c3db80c-9950-4796-be6f-8a20e36b0157', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc594fa41c0>]}
[0m00:39:24.402109 [info ] [MainThread]: 
[0m00:39:24.402785 [info ] [MainThread]: Running 1 on-run-start hook
[0m00:39:24.424340 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m00:39:24.432165 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m00:39:24.433250 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:39:24.434227 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m00:39:25.072419 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5744e2f4-c7af-4671-8a46-ee1800e21fd5&page=queryresults
[0m00:39:26.896516 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.46s]
[0m00:39:26.897258 [info ] [MainThread]: 
[0m00:39:26.898099 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:39:26.898696 [info ] [MainThread]: 
[0m00:39:26.902728 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_write_offs
[0m00:39:26.903692 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cleaned_write_offs .................... [RUN]
[0m00:39:26.904510 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_write_offs)
[0m00:39:26.905189 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_write_offs
[0m00:39:26.910186 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_write_offs"
[0m00:39:26.911740 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_write_offs
[0m00:39:26.958286 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_write_offs"
[0m00:39:26.959664 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:39:26.960435 [debug] [Thread-1  ]: On model.creditrisk.cleaned_write_offs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_write_offs"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
  OPTIONS()
  as WITH wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_write_offs`
)

SELECT 
    account_id,
    write_off_status,
    CAST(changed_date AS TIMESTAMP) as changed_date,
FROM wo;


[0m00:39:27.713167 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:cde67337-f085-40a4-9bca-49c6fa8e53a0&page=queryresults
[0m00:39:28.555389 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c3db80c-9950-4796-be6f-8a20e36b0157', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc59cf98f70>]}
[0m00:39:28.556337 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.cleaned_write_offs ............... [[32mCREATE VIEW (0 processed)[0m in 1.65s]
[0m00:39:28.557278 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_write_offs
[0m00:39:28.558823 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:39:28.559297 [debug] [MainThread]: Connection 'model.creditrisk.cleaned_write_offs' was properly closed.
[0m00:39:28.559775 [info ] [MainThread]: 
[0m00:39:28.560290 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 7.84 seconds (7.84s).
[0m00:39:28.561269 [debug] [MainThread]: Command end result
[0m00:39:28.615428 [info ] [MainThread]: 
[0m00:39:28.616290 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:39:28.616930 [info ] [MainThread]: 
[0m00:39:28.617496 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m00:39:28.618303 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.699545, "process_user_time": 4.940841, "process_kernel_time": 0.809274, "process_mem_max_rss": "227627008", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:39:28.619279 [debug] [MainThread]: Command `dbt run` succeeded at 00:39:28.619098 after 11.70 seconds
[0m00:39:28.619970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc594ba3490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5972637c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc59bcca340>]}
[0m00:39:28.620573 [debug] [MainThread]: Flushing usage events
[0m00:40:26.799743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd76c35e5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd76e371d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd76e3713d0>]}


============================== 00:40:26.804084 | 4509d926-a90d-41cb-85e8-5dbdd0b4112b ==============================
[0m00:40:26.804084 [info ] [MainThread]: Running with dbt=1.8.8
[0m00:40:26.805013 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'fail_fast': 'False', 'printer_width': '80', 'quiet': 'False', 'invocation_command': 'dbt run --select cleaned_write_offs', 'no_print': 'None', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'log_format': 'default', 'profiles_dir': '/Users/david/.dbt', 'target_path': 'None', 'version_check': 'True', 'write_json': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'use_colors': 'True', 'debug': 'False', 'empty': 'False'}
[0m00:40:30.040407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4509d926-a90d-41cb-85e8-5dbdd0b4112b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77258de80>]}
[0m00:40:30.114276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4509d926-a90d-41cb-85e8-5dbdd0b4112b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd76e355eb0>]}
[0m00:40:30.115114 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:40:30.144674 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m00:40:30.444639 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:40:30.445195 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:40:30.515650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4509d926-a90d-41cb-85e8-5dbdd0b4112b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd773166130>]}
[0m00:40:30.676193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4509d926-a90d-41cb-85e8-5dbdd0b4112b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77316d820>]}
[0m00:40:30.676984 [info ] [MainThread]: Found 9 models, 3 seeds, 1 operation, 480 macros
[0m00:40:30.677531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4509d926-a90d-41cb-85e8-5dbdd0b4112b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd773130580>]}
[0m00:40:30.679109 [info ] [MainThread]: 
[0m00:40:30.679889 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:40:30.681016 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m00:40:30.681611 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:40:33.209254 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m00:40:33.210202 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:40:33.869132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4509d926-a90d-41cb-85e8-5dbdd0b4112b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77316d970>]}
[0m00:40:33.870089 [info ] [MainThread]: 
[0m00:40:33.870669 [info ] [MainThread]: Running 1 on-run-start hook
[0m00:40:33.888659 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m00:40:33.895603 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m00:40:33.896438 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:40:33.897154 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m00:40:34.533466 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:6beb2b40-3dd6-4e55-b121-c7a6b1677bfc&page=queryresults
[0m00:40:35.966841 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.07s]
[0m00:40:35.967640 [info ] [MainThread]: 
[0m00:40:35.968510 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:40:35.969112 [info ] [MainThread]: 
[0m00:40:35.972023 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_write_offs
[0m00:40:35.972833 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.cleaned_write_offs .................... [RUN]
[0m00:40:35.973785 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_write_offs)
[0m00:40:35.974653 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_write_offs
[0m00:40:35.979970 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_write_offs"
[0m00:40:35.982103 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_write_offs
[0m00:40:36.027800 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_write_offs"
[0m00:40:36.028985 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:40:36.029681 [debug] [Thread-1  ]: On model.creditrisk.cleaned_write_offs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_write_offs"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
  OPTIONS()
  as WITH wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_write_offs`
)

-- Deduplication step in case there are several write offs or repossessions on the same account
SELECT 
    account_id,
    write_off_status,
    MIN(CAST(changed_date AS TIMESTAMP)) as changed_date, 
FROM wo
GROUP BY ALL;


[0m00:40:36.862481 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:cb33b90a-3d38-4837-8e37-f19f5a700a5f&page=queryresults
[0m00:40:37.676883 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4509d926-a90d-41cb-85e8-5dbdd0b4112b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd773a1b850>]}
[0m00:40:37.677929 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.cleaned_write_offs ............... [[32mCREATE VIEW (0 processed)[0m in 1.70s]
[0m00:40:37.678862 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_write_offs
[0m00:40:37.680415 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:40:37.680853 [debug] [MainThread]: Connection 'model.creditrisk.cleaned_write_offs' was properly closed.
[0m00:40:37.681307 [info ] [MainThread]: 
[0m00:40:37.681797 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 7.00 seconds (7.00s).
[0m00:40:37.682733 [debug] [MainThread]: Command end result
[0m00:40:37.733184 [info ] [MainThread]: 
[0m00:40:37.734046 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:40:37.734543 [info ] [MainThread]: 
[0m00:40:37.735098 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m00:40:37.735849 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.026405, "process_user_time": 5.26075, "process_kernel_time": 0.853918, "process_mem_max_rss": "227528704", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:40:37.736649 [debug] [MainThread]: Command `dbt run` succeeded at 00:40:37.736510 after 11.03 seconds
[0m00:40:37.737199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd76c35e5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd76da388e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd76e355eb0>]}
[0m00:40:37.737717 [debug] [MainThread]: Flushing usage events
[0m00:42:52.524828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94d515d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94d8a72d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94d8a723d0>]}


============================== 00:42:52.531467 | c87816ff-7710-4f3e-a3f8-b4438a61068b ==============================
[0m00:42:52.531467 [info ] [MainThread]: Running with dbt=1.8.8
[0m00:42:52.532580 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'static_parser': 'True', 'no_print': 'None', 'warn_error': 'None', 'debug': 'False', 'indirect_selection': 'eager', 'printer_width': '80', 'version_check': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'log_format': 'default', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'empty': 'False', 'profiles_dir': '/Users/david/.dbt', 'invocation_command': 'dbt run --select accounts_history_advanced', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'quiet': 'False', 'log_cache_events': 'False', 'target_path': 'None'}
[0m00:42:56.336595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c87816ff-7710-4f3e-a3f8-b4438a61068b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94d531f6a0>]}
[0m00:42:56.396955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c87816ff-7710-4f3e-a3f8-b4438a61068b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94dd3f4a00>]}
[0m00:42:56.397752 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:42:56.429460 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m00:42:56.794890 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:42:56.795497 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:42:56.892224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c87816ff-7710-4f3e-a3f8-b4438a61068b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94dd767130>]}
[0m00:42:57.085905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c87816ff-7710-4f3e-a3f8-b4438a61068b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94dd759c10>]}
[0m00:42:57.086680 [info ] [MainThread]: Found 9 models, 3 seeds, 1 operation, 480 macros
[0m00:42:57.087220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c87816ff-7710-4f3e-a3f8-b4438a61068b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94dd730580>]}
[0m00:42:57.088768 [info ] [MainThread]: 
[0m00:42:57.089536 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:42:57.090732 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m00:42:57.091362 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:42:59.998744 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m00:42:59.999662 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:43:00.645245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c87816ff-7710-4f3e-a3f8-b4438a61068b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94dd78c5e0>]}
[0m00:43:00.646115 [info ] [MainThread]: 
[0m00:43:00.646689 [info ] [MainThread]: Running 1 on-run-start hook
[0m00:43:00.663833 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m00:43:00.670376 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m00:43:00.671161 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:43:00.671866 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m00:43:01.337616 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:dc98ce0b-b1cb-4e5d-9c42-25f1fec9db7f&page=queryresults
[0m00:43:02.823855 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.15s]
[0m00:43:02.824626 [info ] [MainThread]: 
[0m00:43:02.825490 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:43:02.826031 [info ] [MainThread]: 
[0m00:43:02.829965 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m00:43:02.831028 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m00:43:02.832053 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m00:43:02.832821 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m00:43:02.838772 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m00:43:02.840919 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m00:43:02.864785 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:43:03.609896 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m00:43:03.615121 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
)

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    *,
    CASE 
        WHEN wo_status IS NOT NULL THEN wo_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_back_on_dataset
)

SELECT * FROM final_kpis
    );
  
[0m00:43:03.948577 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:9c0ac520-0b53-49cd-8a81-423fc23d34e7&page=queryresults
[0m00:43:03.966370 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected identifier "final_kpis" at [106:1]; reason: invalidQuery, location: query, message: Syntax error: Unexpected identifier "final_kpis" at [106:1]')
[0m00:43:04.652495 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5ab5d51d-af78-4d40-be9c-98ef18a1a516&page=queryresults
[0m00:43:04.653670 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5ab5d51d-af78-4d40-be9c-98ef18a1a516&page=queryresults
[0m00:43:04.668400 [debug] [Thread-1  ]: Database Error in model accounts_history_advanced (models/1_building_core_dataset/accounts_history_advanced.sql)
  Syntax error: Unexpected identifier "final_kpis" at [106:1]
  compiled code at target/run/creditrisk/models/1_building_core_dataset/accounts_history_advanced.sql
[0m00:43:04.670565 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c87816ff-7710-4f3e-a3f8-b4438a61068b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94de29a520>]}
[0m00:43:04.671524 [error] [Thread-1  ]: 1 of 1 ERROR creating sql table model oscreditrisk.accounts_history_advanced ... [[31mERROR[0m in 1.84s]
[0m00:43:04.672476 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m00:43:04.674075 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:43:04.674535 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m00:43:04.675017 [info ] [MainThread]: 
[0m00:43:04.675531 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 7.59 seconds (7.59s).
[0m00:43:04.676503 [debug] [MainThread]: Command end result
[0m00:43:04.732466 [info ] [MainThread]: 
[0m00:43:04.733849 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m00:43:04.735140 [info ] [MainThread]: 
[0m00:43:04.736085 [error] [MainThread]:   Database Error in model accounts_history_advanced (models/1_building_core_dataset/accounts_history_advanced.sql)
  Syntax error: Unexpected identifier "final_kpis" at [106:1]
  compiled code at target/run/creditrisk/models/1_building_core_dataset/accounts_history_advanced.sql
[0m00:43:04.736677 [info ] [MainThread]: 
[0m00:43:04.737343 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m00:43:04.738592 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 12.337181, "process_user_time": 5.160858, "process_kernel_time": 0.884739, "process_mem_max_rss": "227045376", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:43:04.739691 [debug] [MainThread]: Command `dbt run` failed at 00:43:04.739507 after 12.34 seconds
[0m00:43:04.740454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94d515d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94d552dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f94dd7850a0>]}
[0m00:43:04.741252 [debug] [MainThread]: Flushing usage events
[0m00:43:17.048637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2d960550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe30372b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe30372280>]}


============================== 00:43:17.053046 | a86e4289-12d9-49a7-bc89-e54045f4a009 ==============================
[0m00:43:17.053046 [info ] [MainThread]: Running with dbt=1.8.8
[0m00:43:17.053935 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'profiles_dir': '/Users/david/.dbt', 'use_colors': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'empty': 'False', 'version_check': 'True', 'target_path': 'None', 'introspect': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'log_cache_events': 'False', 'no_print': 'None', 'log_format': 'default', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'invocation_command': 'dbt run --select accounts_history_advanced', 'debug': 'False', 'static_parser': 'True', 'warn_error': 'None'}
[0m00:43:19.976456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a86e4289-12d9-49a7-bc89-e54045f4a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe33cce550>]}
[0m00:43:20.031151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a86e4289-12d9-49a7-bc89-e54045f4a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe33cdad00>]}
[0m00:43:20.031861 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:43:20.056021 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m00:43:20.343007 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:43:20.343459 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:43:20.399692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a86e4289-12d9-49a7-bc89-e54045f4a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe35167130>]}
[0m00:43:20.520505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a86e4289-12d9-49a7-bc89-e54045f4a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe35156a90>]}
[0m00:43:20.521077 [info ] [MainThread]: Found 9 models, 3 seeds, 1 operation, 480 macros
[0m00:43:20.521501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a86e4289-12d9-49a7-bc89-e54045f4a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe35130cd0>]}
[0m00:43:20.522675 [info ] [MainThread]: 
[0m00:43:20.523314 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:43:20.524131 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m00:43:20.524508 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:43:23.012390 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m00:43:23.013274 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:43:23.629724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a86e4289-12d9-49a7-bc89-e54045f4a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2d8eebe0>]}
[0m00:43:23.630566 [info ] [MainThread]: 
[0m00:43:23.631101 [info ] [MainThread]: Running 1 on-run-start hook
[0m00:43:23.646918 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m00:43:23.653979 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m00:43:23.654942 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:43:23.655757 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m00:43:24.277530 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:7f93255b-5c31-442f-a600-28e357331984&page=queryresults
[0m00:43:25.698471 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.04s]
[0m00:43:25.699273 [info ] [MainThread]: 
[0m00:43:25.700112 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:43:25.700701 [info ] [MainThread]: 
[0m00:43:25.705036 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m00:43:25.705996 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m00:43:25.706791 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m00:43:25.707403 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m00:43:25.713943 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m00:43:25.715860 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m00:43:25.740828 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:43:26.365844 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m00:43:26.367435 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    *,
    CASE 
        WHEN wo_status IS NOT NULL THEN wo_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_wo_statuses
)

SELECT * FROM final_kpis
    );
  
[0m00:43:27.100814 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:646460dc-4b6b-4cff-82f8-eb9a9e31bc11&page=queryresults
[0m00:43:27.573594 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: wo_status at [110:14]; reason: invalidQuery, location: query, message: Unrecognized name: wo_status at [110:14]')
[0m00:43:29.173261 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:3fe13dc4-a9b7-4f40-82cc-18b5e07be9c0&page=queryresults
[0m00:43:29.590219 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:3fe13dc4-a9b7-4f40-82cc-18b5e07be9c0&page=queryresults
[0m00:43:29.600751 [debug] [Thread-1  ]: Database Error in model accounts_history_advanced (models/1_building_core_dataset/accounts_history_advanced.sql)
  Unrecognized name: wo_status at [110:14]
  compiled code at target/run/creditrisk/models/1_building_core_dataset/accounts_history_advanced.sql
[0m00:43:29.603074 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a86e4289-12d9-49a7-bc89-e54045f4a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe35b92cd0>]}
[0m00:43:29.604234 [error] [Thread-1  ]: 1 of 1 ERROR creating sql table model oscreditrisk.accounts_history_advanced ... [[31mERROR[0m in 3.89s]
[0m00:43:29.605253 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m00:43:29.607070 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:43:29.607628 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m00:43:29.608227 [info ] [MainThread]: 
[0m00:43:29.608770 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 9.09 seconds (9.09s).
[0m00:43:29.609804 [debug] [MainThread]: Command end result
[0m00:43:29.662480 [info ] [MainThread]: 
[0m00:43:29.663274 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m00:43:29.663782 [info ] [MainThread]: 
[0m00:43:29.664415 [error] [MainThread]:   Database Error in model accounts_history_advanced (models/1_building_core_dataset/accounts_history_advanced.sql)
  Unrecognized name: wo_status at [110:14]
  compiled code at target/run/creditrisk/models/1_building_core_dataset/accounts_history_advanced.sql
[0m00:43:29.664941 [info ] [MainThread]: 
[0m00:43:29.665478 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m00:43:29.666274 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 12.707469, "process_user_time": 4.739593, "process_kernel_time": 0.706478, "process_mem_max_rss": "227606528", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:43:29.667111 [debug] [MainThread]: Command `dbt run` failed at 00:43:29.666965 after 12.71 seconds
[0m00:43:29.667795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2d960550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe3471fe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2fb40910>]}
[0m00:43:29.668469 [debug] [MainThread]: Flushing usage events
[0m00:44:02.172865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d53160550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d56abe280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d56abec10>]}


============================== 00:44:02.176777 | 4a72f4e2-e20e-4c90-887b-b0b026e0fed6 ==============================
[0m00:44:02.176777 [info ] [MainThread]: Running with dbt=1.8.8
[0m00:44:02.177713 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'partial_parse': 'True', 'log_cache_events': 'False', 'profiles_dir': '/Users/david/.dbt', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'use_colors': 'True', 'debug': 'False', 'target_path': 'None', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'quiet': 'False', 'empty': 'False', 'fail_fast': 'False', 'no_print': 'None', 'invocation_command': 'dbt run --select accounts_history_advanced', 'introspect': 'True', 'static_parser': 'True', 'version_check': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs'}
[0m00:44:05.118193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a72f4e2-e20e-4c90-887b-b0b026e0fed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d5ae0b370>]}
[0m00:44:05.187382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4a72f4e2-e20e-4c90-887b-b0b026e0fed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d56935e80>]}
[0m00:44:05.188430 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:44:05.218310 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m00:44:05.543058 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:44:05.543568 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:44:05.603432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a72f4e2-e20e-4c90-887b-b0b026e0fed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d5b167130>]}
[0m00:44:05.746557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4a72f4e2-e20e-4c90-887b-b0b026e0fed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d5b159a60>]}
[0m00:44:05.747394 [info ] [MainThread]: Found 9 models, 3 seeds, 1 operation, 480 macros
[0m00:44:05.747906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a72f4e2-e20e-4c90-887b-b0b026e0fed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d5b130370>]}
[0m00:44:05.749351 [info ] [MainThread]: 
[0m00:44:05.750065 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:44:05.751085 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m00:44:05.751554 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:44:08.306069 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m00:44:08.307053 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:44:08.908633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a72f4e2-e20e-4c90-887b-b0b026e0fed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d5b159700>]}
[0m00:44:08.909510 [info ] [MainThread]: 
[0m00:44:08.910116 [info ] [MainThread]: Running 1 on-run-start hook
[0m00:44:08.928195 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m00:44:08.935591 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m00:44:08.936439 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:44:08.937368 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m00:44:09.632777 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:645fe804-4d9d-4730-863b-fbbf31f229eb&page=queryresults
[0m00:44:10.850614 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 1.91s]
[0m00:44:10.851386 [info ] [MainThread]: 
[0m00:44:10.852249 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:44:10.852854 [info ] [MainThread]: 
[0m00:44:10.855956 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m00:44:10.856846 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m00:44:10.857792 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m00:44:10.858441 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m00:44:10.864194 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m00:44:10.865237 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m00:44:10.886514 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:44:11.581343 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m00:44:11.582742 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_wo_statuses
)

SELECT * FROM final_kpis
    );
  
[0m00:44:12.414013 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:0aa66447-1b02-4cfc-8958-d9c6a7cea5c8&page=queryresults
[0m00:44:27.905752 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a72f4e2-e20e-4c90-887b-b0b026e0fed6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d5a5da6d0>]}
[0m00:44:27.906793 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 486.0 MiB processed)[0m in 17.05s]
[0m00:44:27.907741 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m00:44:27.909227 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:44:27.909672 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m00:44:27.910133 [info ] [MainThread]: 
[0m00:44:27.910631 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 22.16 seconds (22.16s).
[0m00:44:27.911568 [debug] [MainThread]: Command end result
[0m00:44:27.957069 [info ] [MainThread]: 
[0m00:44:27.957799 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:44:27.958278 [info ] [MainThread]: 
[0m00:44:27.958833 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m00:44:27.959652 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 25.863668, "process_user_time": 4.913215, "process_kernel_time": 0.714556, "process_mem_max_rss": "227983360", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:44:27.960493 [debug] [MainThread]: Command `dbt run` succeeded at 00:44:27.960348 after 25.86 seconds
[0m00:44:27.961064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d53160550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d5ae832e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d56935e80>]}
[0m00:44:27.961600 [debug] [MainThread]: Flushing usage events
[0m00:51:57.095075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe50e361580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe510befbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe510bef190>]}


============================== 00:51:57.100408 | 1c4d967c-4861-4447-92a6-d3b1be4170ce ==============================
[0m00:51:57.100408 [info ] [MainThread]: Running with dbt=1.8.8
[0m00:51:57.101385 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'fail_fast': 'False', 'introspect': 'True', 'use_colors': 'True', 'write_json': 'True', 'invocation_command': 'dbt run --select +compute_defaults', 'no_print': 'None', 'log_cache_events': 'False', 'printer_width': '80', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'empty': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'profiles_dir': '/Users/david/.dbt', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'partial_parse': 'True', 'warn_error': 'None', 'log_format': 'default', 'version_check': 'True', 'target_path': 'None', 'use_experimental_parser': 'False', 'cache_selected_only': 'False'}
[0m00:52:00.951201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1c4d967c-4861-4447-92a6-d3b1be4170ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe514dcec70>]}
[0m00:52:01.006843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1c4d967c-4861-4447-92a6-d3b1be4170ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe514dda7f0>]}
[0m00:52:01.007655 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:52:01.032169 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m00:52:01.377921 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:52:01.378442 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:52:01.438973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1c4d967c-4861-4447-92a6-d3b1be4170ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe51596bdf0>]}
[0m00:52:01.581672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1c4d967c-4861-4447-92a6-d3b1be4170ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe515962400>]}
[0m00:52:01.582404 [info ] [MainThread]: Found 10 models, 3 seeds, 1 operation, 480 macros
[0m00:52:01.582905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c4d967c-4861-4447-92a6-d3b1be4170ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe515932880>]}
[0m00:52:01.584526 [info ] [MainThread]: 
[0m00:52:01.585348 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:52:01.586401 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m00:52:01.586955 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:52:04.854596 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m00:52:04.855537 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:52:05.558054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c4d967c-4861-4447-92a6-d3b1be4170ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe510bb7dc0>]}
[0m00:52:05.558977 [info ] [MainThread]: 
[0m00:52:05.559627 [info ] [MainThread]: Running 1 on-run-start hook
[0m00:52:05.576983 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m00:52:05.583384 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m00:52:05.584201 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:52:05.585039 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m00:52:06.286430 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:44dd907d-296d-422b-97df-bb2e3326241d&page=queryresults
[0m00:52:08.525469 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.94s]
[0m00:52:08.526240 [info ] [MainThread]: 
[0m00:52:08.527117 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:52:08.527722 [info ] [MainThread]: 
[0m00:52:08.531247 [debug] [Thread-1  ]: Began running node model.creditrisk.compute_defaults
[0m00:52:08.532080 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.compute_defaults ...................... [RUN]
[0m00:52:08.533082 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.compute_defaults)
[0m00:52:08.533767 [debug] [Thread-1  ]: Began compiling node model.creditrisk.compute_defaults
[0m00:52:08.537543 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.compute_defaults"
[0m00:52:08.539152 [debug] [Thread-1  ]: Began executing node model.creditrisk.compute_defaults
[0m00:52:08.586089 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.compute_defaults"
[0m00:52:08.587730 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:52:08.588612 [debug] [Thread-1  ]: On model.creditrisk.compute_defaults: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.compute_defaults"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`compute_defaults`
  OPTIONS()
  as WITH history as (
    SELECT * FROM accounts_history_advanced
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

detect_defaults as (
    SELECT 
        account_id,
        paid_total_excl_dp / (unlock_price_excl_dp)
    
);


[0m00:52:09.182992 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:3c059093-4299-4e9f-adef-d8a9170243cd&page=queryresults
[0m00:52:09.183992 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected ";" at [16:2]; reason: invalidQuery, location: query, message: Syntax error: Unexpected ";" at [16:2]')
[0m00:52:09.986811 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:7075ac3e-fc0e-4cff-bb5f-b1a1befdedb8&page=queryresults
[0m00:52:09.988050 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:7075ac3e-fc0e-4cff-bb5f-b1a1befdedb8&page=queryresults
[0m00:52:10.004668 [debug] [Thread-1  ]: Database Error in model compute_defaults (models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_defaults.sql)
  Syntax error: Unexpected ";" at [16:2]
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_defaults.sql
[0m00:52:10.006828 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c4d967c-4861-4447-92a6-d3b1be4170ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe515fa2ee0>]}
[0m00:52:10.007779 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.compute_defaults ............. [[31mERROR[0m in 1.47s]
[0m00:52:10.008747 [debug] [Thread-1  ]: Finished running node model.creditrisk.compute_defaults
[0m00:52:10.010432 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:52:10.010914 [debug] [MainThread]: Connection 'model.creditrisk.compute_defaults' was properly closed.
[0m00:52:10.011408 [info ] [MainThread]: 
[0m00:52:10.011970 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 8.43 seconds (8.43s).
[0m00:52:10.013431 [debug] [MainThread]: Command end result
[0m00:52:10.067047 [info ] [MainThread]: 
[0m00:52:10.067810 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m00:52:10.068323 [info ] [MainThread]: 
[0m00:52:10.068950 [error] [MainThread]:   Database Error in model compute_defaults (models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_defaults.sql)
  Syntax error: Unexpected ";" at [16:2]
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_defaults.sql
[0m00:52:10.069452 [info ] [MainThread]: 
[0m00:52:10.070011 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m00:52:10.070851 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 13.0637455, "process_user_time": 5.163184, "process_kernel_time": 0.963949, "process_mem_max_rss": "227430400", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:52:10.071707 [debug] [MainThread]: Command `dbt run` failed at 00:52:10.071551 after 13.06 seconds
[0m00:52:10.072300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe50e361580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe514dda7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5102738e0>]}
[0m00:52:10.072874 [debug] [MainThread]: Flushing usage events
[0m00:52:32.052631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16835e5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16a19cd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16a19c3d0>]}


============================== 00:52:32.055587 | 013d9065-ecca-40fc-875c-989f8e4de645 ==============================
[0m00:52:32.055587 [info ] [MainThread]: Running with dbt=1.8.8
[0m00:52:32.056240 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'introspect': 'True', 'invocation_command': 'dbt run --select +compute_defaults', 'debug': 'False', 'profiles_dir': '/Users/david/.dbt', 'static_parser': 'True', 'no_print': 'None', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'log_format': 'default', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'quiet': 'False', 'target_path': 'None', 'printer_width': '80', 'empty': 'False', 'write_json': 'True'}
[0m00:52:35.373021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '013d9065-ecca-40fc-875c-989f8e4de645', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16e5944c0>]}
[0m00:52:35.425456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '013d9065-ecca-40fc-875c-989f8e4de645', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16ed9c280>]}
[0m00:52:35.426108 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:52:35.451902 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m00:52:35.749966 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:52:35.750498 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:52:35.821850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '013d9065-ecca-40fc-875c-989f8e4de645', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16f86be80>]}
[0m00:52:35.987473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '013d9065-ecca-40fc-875c-989f8e4de645', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16f862490>]}
[0m00:52:35.988197 [info ] [MainThread]: Found 10 models, 3 seeds, 1 operation, 480 macros
[0m00:52:35.988702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '013d9065-ecca-40fc-875c-989f8e4de645', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16f832220>]}
[0m00:52:35.990504 [info ] [MainThread]: 
[0m00:52:35.991647 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:52:35.992829 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m00:52:35.993471 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:52:38.948913 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m00:52:38.950713 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:52:39.562078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '013d9065-ecca-40fc-875c-989f8e4de645', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16f845f10>]}
[0m00:52:39.563031 [info ] [MainThread]: 
[0m00:52:39.563694 [info ] [MainThread]: Running 1 on-run-start hook
[0m00:52:39.581007 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m00:52:39.587638 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m00:52:39.588592 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:52:39.589446 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m00:52:40.209770 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:e0428f6f-4f0d-4cb9-b320-3c1280a1db3f&page=queryresults
[0m00:52:41.702407 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.11s]
[0m00:52:41.703152 [info ] [MainThread]: 
[0m00:52:41.703995 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:52:41.704574 [info ] [MainThread]: 
[0m00:52:41.711214 [debug] [Thread-1  ]: Began running node model.creditrisk.compute_defaults
[0m00:52:41.712256 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.compute_defaults ...................... [RUN]
[0m00:52:41.713122 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.compute_defaults)
[0m00:52:41.713743 [debug] [Thread-1  ]: Began compiling node model.creditrisk.compute_defaults
[0m00:52:41.717308 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.compute_defaults"
[0m00:52:41.718797 [debug] [Thread-1  ]: Began executing node model.creditrisk.compute_defaults
[0m00:52:41.763361 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.compute_defaults"
[0m00:52:41.764540 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:52:41.765259 [debug] [Thread-1  ]: On model.creditrisk.compute_defaults: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.compute_defaults"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`compute_defaults`
  OPTIONS()
  as WITH history as (
    SELECT * FROM accounts_history_advanced
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

detect_defaults as (
    SELECT 
        account_id,
        paid_total_excl_dp / unlock_price_excl_dp as perc_paid,
    FROM history   
)

SELECT * FROM detect_defaults;


[0m00:52:42.420414 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:c47afb05-8ba3-46fd-84c8-4e61df423055&page=queryresults
[0m00:52:42.421651 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Table "accounts_history_advanced" must be qualified with a dataset (e.g. dataset.table).; reason: invalid, location: accounts_history_advanced, message: Table "accounts_history_advanced" must be qualified with a dataset (e.g. dataset.table).')
[0m00:52:43.487954 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5f133fdb-76cb-4457-b2c3-0b2f38b00ab6&page=queryresults
[0m00:52:43.489176 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5f133fdb-76cb-4457-b2c3-0b2f38b00ab6&page=queryresults
[0m00:52:43.508971 [debug] [Thread-1  ]: Database Error in model compute_defaults (models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_defaults.sql)
  Table "accounts_history_advanced" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_defaults.sql
[0m00:52:43.511302 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '013d9065-ecca-40fc-875c-989f8e4de645', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1500205e0>]}
[0m00:52:43.512295 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.compute_defaults ............. [[31mERROR[0m in 1.80s]
[0m00:52:43.513293 [debug] [Thread-1  ]: Finished running node model.creditrisk.compute_defaults
[0m00:52:43.515082 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:52:43.515577 [debug] [MainThread]: Connection 'model.creditrisk.compute_defaults' was properly closed.
[0m00:52:43.516084 [info ] [MainThread]: 
[0m00:52:43.516626 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 7.52 seconds (7.52s).
[0m00:52:43.517898 [debug] [MainThread]: Command end result
[0m00:52:43.571590 [info ] [MainThread]: 
[0m00:52:43.572347 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m00:52:43.572860 [info ] [MainThread]: 
[0m00:52:43.573570 [error] [MainThread]:   Database Error in model compute_defaults (models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_defaults.sql)
  Table "accounts_history_advanced" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_defaults.sql
[0m00:52:43.574141 [info ] [MainThread]: 
[0m00:52:43.574709 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m00:52:43.575537 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 11.59012, "process_user_time": 4.832819, "process_kernel_time": 0.807587, "process_mem_max_rss": "227971072", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:52:43.576426 [debug] [MainThread]: Command `dbt run` failed at 00:52:43.576272 after 11.59 seconds
[0m00:52:43.577028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16835e5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc168798a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc16ed373d0>]}
[0m00:52:43.577615 [debug] [MainThread]: Flushing usage events
[0m00:53:38.581260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feef925d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feefd270d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feefd2703d0>]}


============================== 00:53:38.586009 | 80eff527-ac20-45cb-91ea-21fdd2081616 ==============================
[0m00:53:38.586009 [info ] [MainThread]: Running with dbt=1.8.8
[0m00:53:38.586996 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'introspect': 'True', 'log_format': 'default', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'empty': 'False', 'indirect_selection': 'eager', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'partial_parse': 'True', 'cache_selected_only': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'log_cache_events': 'False', 'use_colors': 'True', 'static_parser': 'True', 'profiles_dir': '/Users/david/.dbt', 'target_path': 'None', 'warn_error': 'None', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'quiet': 'False', 'invocation_command': 'dbt run --select +compute_defaults'}
[0m00:53:42.222416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef01561310>]}
[0m00:53:42.290393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef014d7730>]}
[0m00:53:42.291228 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:53:42.317074 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m00:53:42.586192 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:53:42.586621 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:53:42.643199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef0216bf10>]}
[0m00:53:42.766976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef021627c0>]}
[0m00:53:42.767539 [info ] [MainThread]: Found 10 models, 3 seeds, 1 operation, 480 macros
[0m00:53:42.767932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef02138f40>]}
[0m00:53:42.769560 [info ] [MainThread]: 
[0m00:53:42.770223 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:53:42.775360 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m00:53:42.775933 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:53:45.714153 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m00:53:45.715225 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:53:46.319315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef017e03d0>]}
[0m00:53:46.320251 [info ] [MainThread]: 
[0m00:53:46.320879 [info ] [MainThread]: Running 1 on-run-start hook
[0m00:53:46.339379 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m00:53:46.347558 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m00:53:46.348601 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:53:46.349764 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m00:53:47.035280 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:35b48eb7-640b-4467-9e0b-11bac45932e0&page=queryresults
[0m00:53:48.366732 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.02s]
[0m00:53:48.367530 [info ] [MainThread]: 
[0m00:53:48.368470 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:53:48.368997 [info ] [MainThread]: 
[0m00:53:48.372074 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m00:53:48.372932 [info ] [Thread-1  ]: 1 of 7 START sql view model oscreditrisk.cleaned_accounts ...................... [RUN]
[0m00:53:48.373818 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m00:53:48.374428 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m00:53:48.379508 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m00:53:48.382542 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m00:53:48.427278 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m00:53:48.429537 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:53:48.430362 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m00:53:49.283707 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:08768653-9717-4baa-8f21-73c30afa029c&page=queryresults
[0m00:53:49.987407 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef015ce130>]}
[0m00:53:49.988377 [info ] [Thread-1  ]: 1 of 7 OK created sql view model oscreditrisk.cleaned_accounts ................. [[32mCREATE VIEW (0 processed)[0m in 1.61s]
[0m00:53:49.989343 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m00:53:49.990085 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_payments
[0m00:53:49.990948 [info ] [Thread-1  ]: 2 of 7 START sql view model oscreditrisk.cleaned_payments ...................... [RUN]
[0m00:53:49.991645 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_accounts, now model.creditrisk.cleaned_payments)
[0m00:53:49.992212 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_payments
[0m00:53:50.001812 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_payments"
[0m00:53:50.003323 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_payments
[0m00:53:50.007866 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_payments"
[0m00:53:50.008980 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:53:50.009719 [debug] [Thread-1  ]: On model.creditrisk.cleaned_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_payments"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`
)

SELECT 
  account_id,
  CAST(down_payment             AS BOOLEAN)         as down_payment,
  CAST(payment_effective_date   AS TIMESTAMP)       as payment_effective_date,
  CAST(amount                   AS FLOAT64)         as amount,
FROM payments;


[0m00:53:50.717074 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:605a7b82-0dfc-4e0c-bb72-e43b20fa12e4&page=queryresults
[0m00:53:51.368283 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feee2c74790>]}
[0m00:53:51.369287 [info ] [Thread-1  ]: 2 of 7 OK created sql view model oscreditrisk.cleaned_payments ................. [[32mCREATE VIEW (0 processed)[0m in 1.38s]
[0m00:53:51.370434 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_payments
[0m00:53:51.371392 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_write_offs
[0m00:53:51.372723 [info ] [Thread-1  ]: 3 of 7 START sql view model oscreditrisk.cleaned_write_offs .................... [RUN]
[0m00:53:51.374020 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_payments, now model.creditrisk.cleaned_write_offs)
[0m00:53:51.374670 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_write_offs
[0m00:53:51.392416 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_write_offs"
[0m00:53:51.403737 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_write_offs
[0m00:53:51.409375 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_write_offs"
[0m00:53:51.410514 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:53:51.411261 [debug] [Thread-1  ]: On model.creditrisk.cleaned_write_offs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_write_offs"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
  OPTIONS()
  as WITH wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_write_offs`
)

-- Deduplication step in case there are several write offs or repossessions on the same account
SELECT 
    account_id,
    write_off_status,
    MIN(CAST(changed_date AS TIMESTAMP)) as changed_date, 
FROM wo
GROUP BY ALL;


[0m00:53:52.120352 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:bbb62840-9aee-476a-9c4b-6aaceee5dd4f&page=queryresults
[0m00:53:52.725724 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feee2f62670>]}
[0m00:53:52.726773 [info ] [Thread-1  ]: 3 of 7 OK created sql view model oscreditrisk.cleaned_write_offs ............... [[32mCREATE VIEW (0 processed)[0m in 1.35s]
[0m00:53:52.727740 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_write_offs
[0m00:53:52.728430 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m00:53:52.729294 [info ] [Thread-1  ]: 4 of 7 START sql table model oscreditrisk.date_spine ........................... [RUN]
[0m00:53:52.730030 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_write_offs, now model.creditrisk.date_spine)
[0m00:53:52.730620 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m00:53:52.735694 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m00:53:52.737547 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m00:53:52.759448 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:53:53.406760 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m00:53:53.407945 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`date_spine`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating a dataset containing one row for each day betwee : 
    - The first day you opened an account
    - Today. With artificial data here we consider today being the day after we received the last payment.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

min_max_dates as (
    SELECT 
        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,
        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,
    FROM payments
)

SELECT
    CAST(
        TIMESTAMP_ADD(
            (SELECT min_date FROM min_max_dates), 
            INTERVAL n DAY
        ) AS TIMESTAMP
    ) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            DAY
        )
    )
) AS n
    );
  
[0m00:53:54.063173 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:275d1d20-9033-4a19-8475-8347a57bae9a&page=queryresults
[0m00:53:56.892958 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feee2f0cf10>]}
[0m00:53:56.894091 [info ] [Thread-1  ]: 4 of 7 OK created sql table model oscreditrisk.date_spine ...................... [[32mCREATE TABLE (1.1k rows, 3.4 MiB processed)[0m in 4.16s]
[0m00:53:56.895135 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m00:53:56.896250 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m00:53:56.897039 [info ] [Thread-1  ]: 5 of 7 START sql table model oscreditrisk.accounts_history_beginner ............ [RUN]
[0m00:53:56.897726 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.date_spine, now model.creditrisk.accounts_history_beginner)
[0m00:53:56.898295 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_beginner
[0m00:53:56.903712 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_beginner"
[0m00:53:56.905271 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_beginner
[0m00:53:56.909671 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:53:57.540295 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_beginner"
[0m00:53:57.541707 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_beginner"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the first version of the core dataset (beginner version). 
    It is essentially : 
    - Joining the accounts dataset with a date spine for the target granuarity
    - Grouping the payment by day, and joining them to the accounts history
    - Calculating cumulated sums to describe the cumulated amount paid, and a few other useful fields
*/

WITH accounts as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

payments as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

date_spine as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

accounts_with_spine as (
  SELECT 
    *,
    TIMESTAMP_DIFF(reporting_date, registration_date, DAY) + 1 as reporting_day,
  FROM accounts
  LEFT JOIN date_spine
  ON accounts.registration_date <= date_spine.reporting_date
),

payments_grouped_by_day as (
  SELECT 
    account_id,
    
    DATE_ADD(
      DATE_TRUNC(payment_effective_date, DAY), 
      INTERVAL 1 DAY
    ) as reporting_date,

    SUM(amount) as amount,
    SUM(
      IF(not down_payment, amount, 0)
    ) as amount_excl_dp,

  FROM payments
  GROUP BY ALL
),

joint as (
  SELECT 
    * EXCEPT(amount, amount_excl_dp),
    COALESCE(amount,          0) as amount,
    COALESCE(amount_excl_dp,  0) as amount_excl_dp,
  FROM accounts_with_spine 
  LEFT JOIN payments_grouped_by_day 
  USING(account_id, reporting_date)
),

calc_paid_total as (
  SELECT 
    *,
    SUM(amount)         OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total,
    SUM(amount_excl_dp) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_excl_dp,
    
    unlock_price - down_payment as unlock_price_excl_dp,

    SAFE_DIVIDE(unlock_price - down_payment, daily_rate) + down_payment_days_included as nominal_term,
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate)                              as nominal_term_excl_dp,

    MAX(reporting_day) OVER(PARTITION BY account_id) as account_age_in_days,
    GREATEST(
            0,
            MAX(reporting_day - down_payment_days_included) OVER(PARTITION BY account_id)
    ) as account_age_excl_dp_in_days,

    DATE_TRUNC(registration_date, MONTH) as cohort_month,
    DATE_TRUNC(registration_date, QUARTER) as cohort_quarter,
    DATE_TRUNC(registration_date, YEAR) as cohort_year,

  FROM joint
)

SELECT * FROM calc_paid_total
    );
  
[0m00:53:58.287335 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:3ca9d6b0-de82-4e43-a6df-4ff8a0ee63ab&page=queryresults
[0m00:54:04.972867 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feee2f852e0>]}
[0m00:54:04.992009 [info ] [Thread-1  ]: 5 of 7 OK created sql table model oscreditrisk.accounts_history_beginner ....... [[32mCREATE TABLE (3.4m rows, 6.2 MiB processed)[0m in 8.07s]
[0m00:54:04.993735 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m00:54:04.994898 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m00:54:04.995982 [info ] [Thread-1  ]: 6 of 7 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m00:54:04.997136 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_beginner, now model.creditrisk.accounts_history_advanced)
[0m00:54:04.997901 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m00:54:05.008216 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m00:54:05.010692 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m00:54:05.015284 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:54:05.618687 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m00:54:05.620499 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_wo_statuses
)

SELECT * FROM final_kpis
    );
  
[0m00:54:06.364724 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:d812de63-b1cb-40ce-b5b2-20378369bfe7&page=queryresults
[0m00:54:22.772793 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feee2c607c0>]}
[0m00:54:22.773911 [info ] [Thread-1  ]: 6 of 7 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 511.5 MiB processed)[0m in 17.78s]
[0m00:54:22.775043 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m00:54:22.776228 [debug] [Thread-1  ]: Began running node model.creditrisk.compute_defaults
[0m00:54:22.776974 [info ] [Thread-1  ]: 7 of 7 START sql view model oscreditrisk.compute_defaults ...................... [RUN]
[0m00:54:22.777710 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_advanced, now model.creditrisk.compute_defaults)
[0m00:54:22.778282 [debug] [Thread-1  ]: Began compiling node model.creditrisk.compute_defaults
[0m00:54:22.789243 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.compute_defaults"
[0m00:54:22.791658 [debug] [Thread-1  ]: Began executing node model.creditrisk.compute_defaults
[0m00:54:22.795745 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.compute_defaults"
[0m00:54:22.796673 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:54:22.797386 [debug] [Thread-1  ]: On model.creditrisk.compute_defaults: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.compute_defaults"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`compute_defaults`
  OPTIONS()
  as WITH history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

detect_defaults as (
    SELECT 
        account_id,
        paid_total_excl_dp / unlock_price_excl_dp as perc_paid,
        CASE 
            WHEN reporting_date_status in ('UNLOCKED', 'DETACHED', 'WRITTEN_OFF') THEN 1
            ELSE 0
        END as definitive_status,
    FROM history
)

SELECT * FROM detect_defaults;


[0m00:54:23.530509 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:fe6ba599-05f9-47a8-9d97-90c34627d0a4&page=queryresults
[0m00:54:24.140040 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '80eff527-ac20-45cb-91ea-21fdd2081616', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feee2f8c190>]}
[0m00:54:24.141155 [info ] [Thread-1  ]: 7 of 7 OK created sql view model oscreditrisk.compute_defaults ................. [[32mCREATE VIEW (0 processed)[0m in 1.36s]
[0m00:54:24.142302 [debug] [Thread-1  ]: Finished running node model.creditrisk.compute_defaults
[0m00:54:24.143974 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:54:24.144459 [debug] [MainThread]: Connection 'model.creditrisk.compute_defaults' was properly closed.
[0m00:54:24.145084 [info ] [MainThread]: 
[0m00:54:24.145635 [info ] [MainThread]: Finished running 4 view models, 3 table models, 1 project hook in 0 hours 0 minutes and 41.37 seconds (41.37s).
[0m00:54:24.148152 [debug] [MainThread]: Command end result
[0m00:54:24.199563 [info ] [MainThread]: 
[0m00:54:24.200547 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:54:24.201097 [info ] [MainThread]: 
[0m00:54:24.201762 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m00:54:24.202556 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 45.716366, "process_user_time": 5.574976, "process_kernel_time": 0.916261, "process_mem_max_rss": "230330368", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:54:24.203362 [debug] [MainThread]: Command `dbt run` succeeded at 00:54:24.203219 after 45.72 seconds
[0m00:54:24.203926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feef925d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef021628b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef014d7730>]}
[0m00:54:24.204454 [debug] [MainThread]: Flushing usage events
[0m08:31:46.060446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b6360580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b996abe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b996a190>]}


============================== 08:31:46.065233 | c24c3cdb-de71-4ed9-b7f7-dab19f64816d ==============================
[0m08:31:46.065233 [info ] [MainThread]: Running with dbt=1.8.8
[0m08:31:46.066177 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'version_check': 'True', 'static_parser': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'fail_fast': 'False', 'quiet': 'False', 'write_json': 'True', 'target_path': 'None', 'empty': 'False', 'invocation_command': 'dbt run --select default_history', 'introspect': 'True', 'warn_error': 'None', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/david/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_format': 'default', 'log_cache_events': 'False', 'cache_selected_only': 'False'}
[0m08:31:48.696144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c24c3cdb-de71-4ed9-b7f7-dab19f64816d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0bdd8b5e0>]}
[0m08:31:48.752352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c24c3cdb-de71-4ed9-b7f7-dab19f64816d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b8a9fb80>]}
[0m08:31:48.753076 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:31:48.828494 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m08:31:49.116884 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:31:49.117319 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:31:49.175067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c24c3cdb-de71-4ed9-b7f7-dab19f64816d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0bea6a130>]}
[0m08:31:49.372380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c24c3cdb-de71-4ed9-b7f7-dab19f64816d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0bea54760>]}
[0m08:31:49.373853 [info ] [MainThread]: Found 11 models, 3 seeds, 1 operation, 480 macros
[0m08:31:49.392377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c24c3cdb-de71-4ed9-b7f7-dab19f64816d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0bea81b80>]}
[0m08:31:49.394717 [info ] [MainThread]: 
[0m08:31:49.395722 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:31:49.397214 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m08:31:49.397889 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:31:54.335325 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m08:31:54.336214 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:31:55.989508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c24c3cdb-de71-4ed9-b7f7-dab19f64816d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0bea6bb80>]}
[0m08:31:55.990551 [info ] [MainThread]: 
[0m08:31:55.991165 [info ] [MainThread]: Running 1 on-run-start hook
[0m08:31:56.008623 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m08:31:56.015607 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m08:31:56.016457 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:31:56.017196 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m08:31:57.518252 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:7286a045-17a1-4d9a-b5a5-fd0c4b655796&page=queryresults
[0m08:31:59.118046 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.10s]
[0m08:31:59.118714 [info ] [MainThread]: 
[0m08:31:59.119424 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:31:59.119916 [info ] [MainThread]: 
[0m08:31:59.123462 [debug] [Thread-1  ]: Began running node model.creditrisk.default_history
[0m08:31:59.124326 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.default_history ....................... [RUN]
[0m08:31:59.125169 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.default_history)
[0m08:31:59.125803 [debug] [Thread-1  ]: Began compiling node model.creditrisk.default_history
[0m08:31:59.130424 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.default_history"
[0m08:31:59.131528 [debug] [Thread-1  ]: Began executing node model.creditrisk.default_history
[0m08:31:59.252210 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.default_history"
[0m08:31:59.253278 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:31:59.253956 [debug] [Thread-1  ]: On model.creditrisk.default_history: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.default_history"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`default_history`
  OPTIONS()
  as WITH history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

detect_defaults as (
    SELECT 
        account_id,
        paid_total_excl_dp / unlock_price_excl_dp as perc_paid,
        CASE 
            WHEN reporting_date_status in ('UNLOCKED') THEN 0
            WHEN reporting_date_status in ('DETACHED', 'WRITTEN_OFF') THEN 1
            WHEN days_disabled >= 180 THEN 1
            ELSE 0
        END as has_defaulted,

    FROM history
)

SELECT * FROM detect_defaults;


[0m08:32:00.749857 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:456bc376-cd5e-43c0-aecd-4f3d2e911ce2&page=queryresults
[0m08:32:01.893075 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c24c3cdb-de71-4ed9-b7f7-dab19f64816d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0bf2246d0>]}
[0m08:32:01.894026 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.default_history .................. [[32mCREATE VIEW (0 processed)[0m in 2.77s]
[0m08:32:01.894983 [debug] [Thread-1  ]: Finished running node model.creditrisk.default_history
[0m08:32:01.896676 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:32:01.897137 [debug] [MainThread]: Connection 'model.creditrisk.default_history' was properly closed.
[0m08:32:01.897674 [info ] [MainThread]: 
[0m08:32:01.898247 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 12.50 seconds (12.50s).
[0m08:32:01.899324 [debug] [MainThread]: Command end result
[0m08:32:01.949540 [info ] [MainThread]: 
[0m08:32:01.950241 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:32:01.950701 [info ] [MainThread]: 
[0m08:32:01.951202 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:32:01.951913 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 15.978732, "process_user_time": 4.539341, "process_kernel_time": 0.734732, "process_mem_max_rss": "226889728", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m08:32:01.952695 [debug] [MainThread]: Command `dbt run` succeeded at 08:32:01.952557 after 15.98 seconds
[0m08:32:01.953225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b6360580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0bdd2cdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b923c6a0>]}
[0m08:32:01.953726 [debug] [MainThread]: Flushing usage events
[0m08:42:20.031194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa3a60580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa6a0adc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa6a0a3d0>]}


============================== 08:42:20.035843 | 7f60ee90-bca1-4179-814c-fc92e090f142 ==============================
[0m08:42:20.035843 [info ] [MainThread]: Running with dbt=1.8.8
[0m08:42:20.037054 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'invocation_command': 'dbt run --select default_history', 'debug': 'False', 'log_format': 'default', 'log_cache_events': 'False', 'partial_parse': 'True', 'static_parser': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'printer_width': '80', 'empty': 'False', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'fail_fast': 'False', 'version_check': 'True', 'write_json': 'True', 'introspect': 'True', 'use_colors': 'True', 'target_path': 'None', 'no_print': 'None', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/Users/david/.dbt'}
[0m08:42:22.941817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7f60ee90-bca1-4179-814c-fc92e090f142', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfaa4c1940>]}
[0m08:42:22.994632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7f60ee90-bca1-4179-814c-fc92e090f142', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa69d2bb0>]}
[0m08:42:22.995299 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:42:23.019664 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m08:42:23.306418 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:42:23.306952 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:42:23.367868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7f60ee90-bca1-4179-814c-fc92e090f142', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfab96d130>]}
[0m08:42:23.495811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7f60ee90-bca1-4179-814c-fc92e090f142', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfab972640>]}
[0m08:42:23.496513 [info ] [MainThread]: Found 11 models, 3 seeds, 1 operation, 480 macros
[0m08:42:23.496988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f60ee90-bca1-4179-814c-fc92e090f142', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfab9344f0>]}
[0m08:42:23.498424 [info ] [MainThread]: 
[0m08:42:23.499122 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:42:23.500143 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m08:42:23.500598 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:42:27.434155 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m08:42:27.435083 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:42:29.028502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f60ee90-bca1-4179-814c-fc92e090f142', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa62dbd60>]}
[0m08:42:29.029377 [info ] [MainThread]: 
[0m08:42:29.030115 [info ] [MainThread]: Running 1 on-run-start hook
[0m08:42:29.048544 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m08:42:29.055051 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m08:42:29.055772 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:42:29.056485 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m08:42:30.629338 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ad4eb6d5-9065-42f3-9234-f5857152c17b&page=queryresults
[0m08:42:32.517871 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.46s]
[0m08:42:32.518649 [info ] [MainThread]: 
[0m08:42:32.519511 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:42:32.520133 [info ] [MainThread]: 
[0m08:42:32.525765 [debug] [Thread-1  ]: Began running node model.creditrisk.default_history
[0m08:42:32.526619 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.default_history ....................... [RUN]
[0m08:42:32.527338 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.default_history)
[0m08:42:32.527936 [debug] [Thread-1  ]: Began compiling node model.creditrisk.default_history
[0m08:42:32.533045 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.default_history"
[0m08:42:32.534314 [debug] [Thread-1  ]: Began executing node model.creditrisk.default_history
[0m08:42:32.577585 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.default_history"
[0m08:42:32.578609 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:42:32.579431 [debug] [Thread-1  ]: On model.creditrisk.default_history: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.default_history"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`default_history`
  OPTIONS()
  as /*
    This transformations creates a dataset containing one line per account and contains the information if the account has defaulted or not. 
*/

WITH history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

date_spine as (
    SELECT reporting_date as horizon_end_date FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

detect_defaults as (
    SELECT 
        account_id,
        registration_date,
        paid_total_excl_dp / unlock_price_excl_dp as perc_paid,
        CASE 
            WHEN reporting_date_status in ('UNLOCKED') THEN 0
            WHEN reporting_date_status in ('DETACHED', 'WRITTEN_OFF') THEN 1
            WHEN days_disabled >= 180 THEN 1
            ELSE 0
        END as has_defaulted,
    FROM history
)

SELECT * FROM detect_defaults;


[0m08:42:34.237716 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:401d19d3-3b3a-404f-905f-b1ada786dee6&page=queryresults
[0m08:42:35.516167 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f60ee90-bca1-4179-814c-fc92e090f142', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfaa4c16d0>]}
[0m08:42:35.517133 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.default_history .................. [[32mCREATE VIEW (0 processed)[0m in 2.99s]
[0m08:42:35.518097 [debug] [Thread-1  ]: Finished running node model.creditrisk.default_history
[0m08:42:35.519689 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:42:35.520157 [debug] [MainThread]: Connection 'model.creditrisk.default_history' was properly closed.
[0m08:42:35.520643 [info ] [MainThread]: 
[0m08:42:35.521170 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 12.02 seconds (12.02s).
[0m08:42:35.522157 [debug] [MainThread]: Command end result
[0m08:42:35.566162 [info ] [MainThread]: 
[0m08:42:35.566851 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:42:35.567315 [info ] [MainThread]: 
[0m08:42:35.567814 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:42:35.568519 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 15.614176, "process_user_time": 4.653119, "process_kernel_time": 0.731834, "process_mem_max_rss": "227696640", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m08:42:35.569282 [debug] [MainThread]: Command `dbt run` succeeded at 08:42:35.569151 after 15.62 seconds
[0m08:42:35.569809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa3a60580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfab561730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa62da6a0>]}
[0m08:42:35.570310 [debug] [MainThread]: Flushing usage events
[0m08:42:40.621644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865b332580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865da76430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865da76e80>]}


============================== 08:42:40.625565 | 5e40b4e0-be3b-4e60-8288-41c31341920f ==============================
[0m08:42:40.625565 [info ] [MainThread]: Running with dbt=1.8.8
[0m08:42:40.626421 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'cache_selected_only': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'empty': 'False', 'log_format': 'default', 'log_cache_events': 'False', 'fail_fast': 'False', 'quiet': 'False', 'version_check': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'static_parser': 'True', 'warn_error': 'None', 'write_json': 'True', 'profiles_dir': '/Users/david/.dbt', 'partial_parse': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'use_experimental_parser': 'False', 'printer_width': '80', 'target_path': 'None', 'invocation_command': 'dbt run --select default_history'}
[0m08:42:44.487792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5e40b4e0-be3b-4e60-8288-41c31341920f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8661bbac70>]}
[0m08:42:44.545219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5e40b4e0-be3b-4e60-8288-41c31341920f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8661bc87f0>]}
[0m08:42:44.545913 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:42:44.570882 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m08:42:44.809880 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:42:44.810478 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:42:44.877795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e40b4e0-be3b-4e60-8288-41c31341920f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f866296d130>]}
[0m08:42:45.012662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e40b4e0-be3b-4e60-8288-41c31341920f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86629725e0>]}
[0m08:42:45.013281 [info ] [MainThread]: Found 11 models, 3 seeds, 1 operation, 480 macros
[0m08:42:45.013843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e40b4e0-be3b-4e60-8288-41c31341920f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8662984400>]}
[0m08:42:45.015134 [info ] [MainThread]: 
[0m08:42:45.015746 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:42:45.016612 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m08:42:45.017047 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:42:48.673616 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m08:42:48.674531 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:42:50.240287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e40b4e0-be3b-4e60-8288-41c31341920f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8661c04c70>]}
[0m08:42:50.241150 [info ] [MainThread]: 
[0m08:42:50.241751 [info ] [MainThread]: Running 1 on-run-start hook
[0m08:42:50.259261 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m08:42:50.265680 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m08:42:50.266443 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:42:50.267184 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m08:42:51.885358 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:9633152b-51d3-4a7c-9d92-ad35d6952ea1&page=queryresults
[0m08:42:53.801830 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.54s]
[0m08:42:53.802613 [info ] [MainThread]: 
[0m08:42:53.803475 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:42:53.804087 [info ] [MainThread]: 
[0m08:42:53.807928 [debug] [Thread-1  ]: Began running node model.creditrisk.default_history
[0m08:42:53.808868 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.default_history ....................... [RUN]
[0m08:42:53.809637 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.default_history)
[0m08:42:53.810433 [debug] [Thread-1  ]: Began compiling node model.creditrisk.default_history
[0m08:42:53.815460 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.default_history"
[0m08:42:53.816528 [debug] [Thread-1  ]: Began executing node model.creditrisk.default_history
[0m08:42:53.856364 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.default_history"
[0m08:42:53.857353 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:42:53.858019 [debug] [Thread-1  ]: On model.creditrisk.default_history: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.default_history"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`default_history`
  OPTIONS()
  as /*
    This transformations creates a dataset containing one line per account and contains the information if the account has defaulted or not. 
*/

WITH history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

detect_defaults as (
    SELECT 
        account_id,
        registration_date,
        paid_total_excl_dp / unlock_price_excl_dp as perc_paid,
        CASE 
            WHEN reporting_date_status in ('UNLOCKED') THEN 0
            WHEN reporting_date_status in ('DETACHED', 'WRITTEN_OFF') THEN 1
            WHEN days_disabled >= 180 THEN 1
            ELSE 0
        END as has_defaulted,
    FROM history
)

SELECT * FROM detect_defaults;


[0m08:42:55.596325 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:08e3099f-f1f4-4a1f-9759-ecafcc319569&page=queryresults
[0m08:42:56.972623 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e40b4e0-be3b-4e60-8288-41c31341920f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86633247c0>]}
[0m08:42:56.973581 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.default_history .................. [[32mCREATE VIEW (0 processed)[0m in 3.16s]
[0m08:42:56.974552 [debug] [Thread-1  ]: Finished running node model.creditrisk.default_history
[0m08:42:56.976146 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:42:56.976613 [debug] [MainThread]: Connection 'model.creditrisk.default_history' was properly closed.
[0m08:42:56.977110 [info ] [MainThread]: 
[0m08:42:56.977616 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 11.96 seconds (11.96s).
[0m08:42:56.978584 [debug] [MainThread]: Command end result
[0m08:42:57.111170 [info ] [MainThread]: 
[0m08:42:57.111988 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:42:57.112516 [info ] [MainThread]: 
[0m08:42:57.113096 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:42:57.113909 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 16.567123, "process_user_time": 4.843616, "process_kernel_time": 0.849751, "process_mem_max_rss": "226947072", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m08:42:57.114788 [debug] [MainThread]: Command `dbt run` succeeded at 08:42:57.114630 after 16.57 seconds
[0m08:42:57.115402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865b332580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865d8fb0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8661bc87f0>]}
[0m08:42:57.115967 [debug] [MainThread]: Flushing usage events
[0m08:59:31.468663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e3aa0580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e799bbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e799b190>]}


============================== 08:59:31.473230 | 729e1c9a-42dd-476f-b215-c39b07ef4928 ==============================
[0m08:59:31.473230 [info ] [MainThread]: Running with dbt=1.8.8
[0m08:59:31.474233 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'debug': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'static_parser': 'True', 'introspect': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'write_json': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'version_check': 'True', 'quiet': 'False', 'indirect_selection': 'eager', 'warn_error': 'None', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/david/.dbt', 'target_path': 'None', 'log_format': 'default', 'use_colors': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt run --select accounts_history_advanced', 'printer_width': '80'}
[0m08:59:34.160073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '729e1c9a-42dd-476f-b215-c39b07ef4928', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ebd8b5e0>]}
[0m08:59:34.221346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '729e1c9a-42dd-476f-b215-c39b07ef4928', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ec5364c0>]}
[0m08:59:34.222040 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:59:34.246017 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m08:59:34.519084 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:59:34.519519 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:59:34.579227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '729e1c9a-42dd-476f-b215-c39b07ef4928', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ec975df0>]}
[0m08:59:34.721147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '729e1c9a-42dd-476f-b215-c39b07ef4928', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ec96e0d0>]}
[0m08:59:34.721819 [info ] [MainThread]: Found 12 models, 3 seeds, 1 operation, 480 macros
[0m08:59:34.722310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '729e1c9a-42dd-476f-b215-c39b07ef4928', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e3f78d00>]}
[0m08:59:34.723801 [info ] [MainThread]: 
[0m08:59:34.724554 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:59:34.725618 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m08:59:34.726162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:59:40.198219 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m08:59:40.199182 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:59:42.087184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '729e1c9a-42dd-476f-b215-c39b07ef4928', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ebd16c70>]}
[0m08:59:42.088039 [info ] [MainThread]: 
[0m08:59:42.088602 [info ] [MainThread]: Running 1 on-run-start hook
[0m08:59:42.104322 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m08:59:42.111872 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m08:59:42.112752 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:59:42.113493 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m08:59:44.068312 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:59fd000a-23bb-4f2a-93df-b055987e7e92&page=queryresults
[0m08:59:46.115139 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 4.00s]
[0m08:59:46.115767 [info ] [MainThread]: 
[0m08:59:46.116464 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:59:46.116970 [info ] [MainThread]: 
[0m08:59:46.121335 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m08:59:46.122303 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m08:59:46.123159 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m08:59:46.124118 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m08:59:46.131177 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m08:59:46.133713 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m08:59:46.157179 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:59:47.918911 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m08:59:47.922052 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_wo_statuses
)

SELECT 
    *,
    AVG(IF(reporting_date_status = 'ENABLED', 1, 0)) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN 180 PRECEDING AND CURRENT ROW) as usage_rate_last_180d,
FROM final_kpis
    );
  
[0m08:59:48.934123 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5da28653-5d10-4111-8b5f-17cb3a2bc177&page=queryresults
[0m09:00:07.694630 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '729e1c9a-42dd-476f-b215-c39b07ef4928', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3ebcda700>]}
[0m09:00:07.695646 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 511.5 MiB processed)[0m in 21.57s]
[0m09:00:07.696626 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m09:00:07.698277 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:00:07.698755 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m09:00:07.699256 [info ] [MainThread]: 
[0m09:00:07.699784 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 32.97 seconds (32.97s).
[0m09:00:07.700803 [debug] [MainThread]: Command end result
[0m09:00:07.745802 [info ] [MainThread]: 
[0m09:00:07.746533 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:00:07.747007 [info ] [MainThread]: 
[0m09:00:07.747518 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:00:07.748267 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 36.36932, "process_user_time": 4.587194, "process_kernel_time": 0.67499, "process_mem_max_rss": "227766272", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:00:07.749049 [debug] [MainThread]: Command `dbt run` succeeded at 09:00:07.748915 after 36.37 seconds
[0m09:00:07.749597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e3aa0580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e3f6cac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e726b6a0>]}
[0m09:00:07.750112 [debug] [MainThread]: Flushing usage events
[0m09:01:34.354848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccda85d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccde971d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccde9713d0>]}


============================== 09:01:34.359331 | 49468a3f-b5f8-4855-8baa-658333429929 ==============================
[0m09:01:34.359331 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:01:34.360548 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'write_json': 'True', 'no_print': 'None', 'introspect': 'True', 'cache_selected_only': 'False', 'use_colors': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_format': 'default', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'log_cache_events': 'False', 'quiet': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'version_check': 'True', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/david/.dbt', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'invocation_command': 'dbt run --select accounts_history_advanced', 'empty': 'False'}
[0m09:01:37.571683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '49468a3f-b5f8-4855-8baa-658333429929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce2594e80>]}
[0m09:01:37.627143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '49468a3f-b5f8-4855-8baa-658333429929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccde954eb0>]}
[0m09:01:37.627830 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:01:37.652662 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:01:37.961283 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:01:37.961801 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:01:38.027433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49468a3f-b5f8-4855-8baa-658333429929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce3875e20>]}
[0m09:01:38.207699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49468a3f-b5f8-4855-8baa-658333429929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce386e250>]}
[0m09:01:38.209090 [info ] [MainThread]: Found 12 models, 3 seeds, 1 operation, 480 macros
[0m09:01:38.210079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49468a3f-b5f8-4855-8baa-658333429929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce383efa0>]}
[0m09:01:38.214131 [info ] [MainThread]: 
[0m09:01:38.215972 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:01:38.218076 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:01:38.218791 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:01:42.612843 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:01:42.613775 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:01:44.186659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49468a3f-b5f8-4855-8baa-658333429929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce3871370>]}
[0m09:01:44.187493 [info ] [MainThread]: 
[0m09:01:44.188051 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:01:44.206859 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:01:44.213584 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:01:44.214532 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:01:44.215422 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:01:45.864584 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:539fe637-f653-4e34-8eef-09c87ec7da63&page=queryresults
[0m09:01:47.828833 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.61s]
[0m09:01:47.829680 [info ] [MainThread]: 
[0m09:01:47.830569 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:01:47.831191 [info ] [MainThread]: 
[0m09:01:47.834533 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m09:01:47.835498 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m09:01:47.836433 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m09:01:47.837115 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m09:01:47.843201 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m09:01:47.845352 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m09:01:47.870317 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:01:49.476984 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m09:01:49.478408 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
additional_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_wo_statuses
),

usage_rates as (
    SELECT 
        *,
        AVG(
            IF(reporting_date_status in ('ENABLED', 'UNLOCKED'), 1, 0)
        ) OVER(
            PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN 180 PRECEDING AND CURRENT ROW
        ) as usage_rate_last_180d,
    FROM final_kpis
),

segmentations as (
    SELECT 
        *,
        CASE 
            WHEN usage_rate_last_180d >= 0.95 THEN 'A'
            WHEN usage_rate_last_180d >= 0.90 THEN 'B'
            WHEN usage_rate_last_180d >= 0.60 THEN 'C'
            WHEN usage_rate_last_180d < 0.60  THEN 'D'
        END as account_segmentation,
    FROM usage_rates
)

SELECT * FROM segmentations
    );
  
[0m09:01:50.238045 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:e0ade316-6674-4624-8901-3fa9eadd5cf7&page=queryresults
[0m09:01:50.239446 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Table "final_kpis" must be qualified with a dataset (e.g. dataset.table).; reason: invalid, location: final_kpis, message: Table "final_kpis" must be qualified with a dataset (e.g. dataset.table).')
[0m09:01:51.211024 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:54602b0a-0605-4aaf-b64b-b1983fe2f237&page=queryresults
[0m09:01:51.212465 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:54602b0a-0605-4aaf-b64b-b1983fe2f237&page=queryresults
[0m09:01:51.224973 [debug] [Thread-1  ]: Database Error in model accounts_history_advanced (models/1_building_core_dataset/accounts_history_advanced.sql)
  Table "final_kpis" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/1_building_core_dataset/accounts_history_advanced.sql
[0m09:01:51.227623 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49468a3f-b5f8-4855-8baa-658333429929', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce3ea9910>]}
[0m09:01:51.228713 [error] [Thread-1  ]: 1 of 1 ERROR creating sql table model oscreditrisk.accounts_history_advanced ... [[31mERROR[0m in 3.39s]
[0m09:01:51.229979 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m09:01:51.231913 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:01:51.232460 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m09:01:51.232991 [info ] [MainThread]: 
[0m09:01:51.233553 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 13.02 seconds (13.02s).
[0m09:01:51.234695 [debug] [MainThread]: Command end result
[0m09:01:51.286646 [info ] [MainThread]: 
[0m09:01:51.287304 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m09:01:51.287763 [info ] [MainThread]: 
[0m09:01:51.288339 [error] [MainThread]:   Database Error in model accounts_history_advanced (models/1_building_core_dataset/accounts_history_advanced.sql)
  Table "final_kpis" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/creditrisk/models/1_building_core_dataset/accounts_history_advanced.sql
[0m09:01:51.288808 [info ] [MainThread]: 
[0m09:01:51.289303 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:01:51.290039 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 17.023338, "process_user_time": 4.921206, "process_kernel_time": 0.776566, "process_mem_max_rss": "227127296", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:01:51.290829 [debug] [MainThread]: Command `dbt run` failed at 09:01:51.290686 after 17.02 seconds
[0m09:01:51.291384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccda85d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccdae2dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce2f82100>]}
[0m09:01:51.291905 [debug] [MainThread]: Flushing usage events
[0m09:02:09.658719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8cdaa0550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8d02bd280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8d02bdc10>]}


============================== 09:02:09.662899 | 70299eff-bb32-4bbb-9160-b4688542e447 ==============================
[0m09:02:09.662899 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:02:09.663799 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'version_check': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'empty': 'False', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'printer_width': '80', 'use_colors': 'True', 'introspect': 'True', 'quiet': 'False', 'invocation_command': 'dbt run --select accounts_history_advanced', 'fail_fast': 'False', 'write_json': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'profiles_dir': '/Users/david/.dbt'}
[0m09:02:12.646063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '70299eff-bb32-4bbb-9160-b4688542e447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8d3e8bfa0>]}
[0m09:02:12.701412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '70299eff-bb32-4bbb-9160-b4688542e447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8d4514430>]}
[0m09:02:12.702113 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:02:12.727549 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:02:13.042207 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:02:13.042729 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:02:13.106330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '70299eff-bb32-4bbb-9160-b4688542e447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8d516f130>]}
[0m09:02:13.235532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '70299eff-bb32-4bbb-9160-b4688542e447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8d516e2b0>]}
[0m09:02:13.236235 [info ] [MainThread]: Found 12 models, 3 seeds, 1 operation, 480 macros
[0m09:02:13.236736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '70299eff-bb32-4bbb-9160-b4688542e447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8d513e4f0>]}
[0m09:02:13.238258 [info ] [MainThread]: 
[0m09:02:13.239088 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:02:13.240205 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:02:13.240697 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:02:17.882322 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:02:17.883251 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:02:19.634899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '70299eff-bb32-4bbb-9160-b4688542e447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8d43c7d30>]}
[0m09:02:19.635771 [info ] [MainThread]: 
[0m09:02:19.636373 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:02:19.656019 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:02:19.662291 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:02:19.663013 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:02:19.663712 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:02:21.405304 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:1212829a-ae23-4622-bddb-d9d26098cab0&page=queryresults
[0m09:02:23.577704 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.91s]
[0m09:02:23.578364 [info ] [MainThread]: 
[0m09:02:23.579091 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:02:23.579601 [info ] [MainThread]: 
[0m09:02:23.582443 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m09:02:23.583284 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m09:02:23.584174 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m09:02:23.584871 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m09:02:23.590648 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m09:02:23.591975 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m09:02:23.613735 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:02:25.413001 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m09:02:25.414522 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
additional_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_wo_statuses
),

usage_rates as (
    SELECT 
        *,
        AVG(
            IF(reporting_date_status in ('ENABLED', 'UNLOCKED'), 1, 0)
        ) OVER(
            PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN 180 PRECEDING AND CURRENT ROW
        ) as usage_rate_last_180d,
    FROM additional_kpis
),

segmentations as (
    SELECT 
        *,
        CASE 
            WHEN usage_rate_last_180d >= 0.95 THEN 'A'
            WHEN usage_rate_last_180d >= 0.90 THEN 'B'
            WHEN usage_rate_last_180d >= 0.60 THEN 'C'
            WHEN usage_rate_last_180d < 0.60  THEN 'D'
        END as account_segmentation,
    FROM usage_rates
)

SELECT * FROM segmentations
    );
  
[0m09:02:26.661785 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b8ced683-6a80-4502-a7b6-0e637bb01464&page=queryresults
[0m09:02:27.379828 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Duplicate alias additional_kpis for WITH subquery at [106:1]; reason: invalidQuery, location: query, message: Duplicate alias additional_kpis for WITH subquery at [106:1]')
[0m09:02:29.013963 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:af623a93-fdd9-4aff-8740-799ab6cc58f8&page=queryresults
[0m09:02:29.698559 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:af623a93-fdd9-4aff-8740-799ab6cc58f8&page=queryresults
[0m09:02:29.703601 [debug] [Thread-1  ]: Database Error in model accounts_history_advanced (models/1_building_core_dataset/accounts_history_advanced.sql)
  Duplicate alias additional_kpis for WITH subquery at [106:1]
  compiled code at target/run/creditrisk/models/1_building_core_dataset/accounts_history_advanced.sql
[0m09:02:29.705933 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70299eff-bb32-4bbb-9160-b4688542e447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8d5a94d90>]}
[0m09:02:29.706929 [error] [Thread-1  ]: 1 of 1 ERROR creating sql table model oscreditrisk.accounts_history_advanced ... [[31mERROR[0m in 6.12s]
[0m09:02:29.707942 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m09:02:29.710123 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:02:29.710856 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m09:02:29.711485 [info ] [MainThread]: 
[0m09:02:29.712055 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 16.47 seconds (16.47s).
[0m09:02:29.714121 [debug] [MainThread]: Command end result
[0m09:02:29.769485 [info ] [MainThread]: 
[0m09:02:29.770200 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m09:02:29.770663 [info ] [MainThread]: 
[0m09:02:29.771237 [error] [MainThread]:   Database Error in model accounts_history_advanced (models/1_building_core_dataset/accounts_history_advanced.sql)
  Duplicate alias additional_kpis for WITH subquery at [106:1]
  compiled code at target/run/creditrisk/models/1_building_core_dataset/accounts_history_advanced.sql
[0m09:02:29.771699 [info ] [MainThread]: 
[0m09:02:29.772193 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:02:29.772946 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 20.251097, "process_user_time": 4.799405, "process_kernel_time": 0.715831, "process_mem_max_rss": "228540416", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:02:29.773737 [debug] [MainThread]: Command `dbt run` failed at 09:02:29.773599 after 20.25 seconds
[0m09:02:29.774298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8cdaa0550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8cdeabe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8cfa73220>]}
[0m09:02:29.774948 [debug] [MainThread]: Flushing usage events
[0m09:03:00.388363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfc43644f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfc62be310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfc62bef10>]}


============================== 09:03:00.392754 | 9031568f-10e4-46de-8f46-8fb6a1ef0b8d ==============================
[0m09:03:00.392754 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:03:00.393658 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'introspect': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'no_print': 'None', 'printer_width': '80', 'static_parser': 'True', 'debug': 'False', 'target_path': 'None', 'write_json': 'True', 'quiet': 'False', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/david/.dbt', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'empty': 'False', 'use_colors': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'invocation_command': 'dbt run --select accounts_history_advanced', 'partial_parse': 'True', 'version_check': 'True', 'fail_fast': 'False'}
[0m09:03:03.653020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9031568f-10e4-46de-8f46-8fb6a1ef0b8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfca596520>]}
[0m09:03:03.709895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9031568f-10e4-46de-8f46-8fb6a1ef0b8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcad364f0>]}
[0m09:03:03.710602 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:03:03.736340 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:03:04.007143 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:03:04.007605 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:03:04.066786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9031568f-10e4-46de-8f46-8fb6a1ef0b8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcb06f130>]}
[0m09:03:04.214462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9031568f-10e4-46de-8f46-8fb6a1ef0b8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcb06e9a0>]}
[0m09:03:04.215282 [info ] [MainThread]: Found 12 models, 3 seeds, 1 operation, 480 macros
[0m09:03:04.215818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9031568f-10e4-46de-8f46-8fb6a1ef0b8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcb03e130>]}
[0m09:03:04.217452 [info ] [MainThread]: 
[0m09:03:04.218218 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:03:04.219323 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:03:04.219852 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:03:09.020020 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:03:09.020860 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:03:10.697488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9031568f-10e4-46de-8f46-8fb6a1ef0b8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcadb4370>]}
[0m09:03:10.698462 [info ] [MainThread]: 
[0m09:03:10.699070 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:03:10.720424 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:03:10.727567 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:03:10.728742 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:03:10.729843 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:03:12.416032 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:d6998795-ab34-47ab-8e8d-babd8bb13cf6&page=queryresults
[0m09:03:14.328661 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.60s]
[0m09:03:14.329453 [info ] [MainThread]: 
[0m09:03:14.330322 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:03:14.330935 [info ] [MainThread]: 
[0m09:03:14.334879 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m09:03:14.335846 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m09:03:14.336605 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m09:03:14.337227 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m09:03:14.343503 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m09:03:14.345164 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m09:03:14.368968 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:03:16.345383 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m09:03:16.346790 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
  FROM join_wo_statuses
),

usage_rates as (
    SELECT 
        *,
        AVG(
            IF(reporting_date_status in ('ENABLED', 'UNLOCKED'), 1, 0)
        ) OVER(
            PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN 180 PRECEDING AND CURRENT ROW
        ) as usage_rate_last_180d,
    FROM final_kpis
),

segmentations as (
    SELECT 
        *,
        CASE 
            WHEN usage_rate_last_180d >= 0.95 THEN 'A'
            WHEN usage_rate_last_180d >= 0.90 THEN 'B'
            WHEN usage_rate_last_180d >= 0.60 THEN 'C'
            WHEN usage_rate_last_180d < 0.60  THEN 'D'
        END as account_segmentation,
    FROM usage_rates
)

SELECT * FROM segmentations
    );
  
[0m09:03:17.478014 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:83455103-7e88-4e38-a61d-778c642b45f4&page=queryresults
[0m09:03:39.681433 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9031568f-10e4-46de-8f46-8fb6a1ef0b8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfca4da670>]}
[0m09:03:39.682510 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 511.5 MiB processed)[0m in 25.34s]
[0m09:03:39.683422 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m09:03:39.685014 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:03:39.685479 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m09:03:39.685946 [info ] [MainThread]: 
[0m09:03:39.686437 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 35.47 seconds (35.47s).
[0m09:03:39.687413 [debug] [MainThread]: Command end result
[0m09:03:39.737469 [info ] [MainThread]: 
[0m09:03:39.738240 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:03:39.738863 [info ] [MainThread]: 
[0m09:03:39.739430 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:03:39.740217 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 39.42838, "process_user_time": 4.943716, "process_kernel_time": 0.860244, "process_mem_max_rss": "226963456", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:03:39.741083 [debug] [MainThread]: Command `dbt run` succeeded at 09:03:39.740930 after 39.43 seconds
[0m09:03:39.741877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfc43644f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfc47a3ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfcad364f0>]}
[0m09:03:39.742522 [debug] [MainThread]: Flushing usage events
[0m09:07:35.663577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadfcb644c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadff2f6250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadff2f6f70>]}


============================== 09:07:35.668366 | 77c0d4f8-bdf2-4b8b-b2a0-5e68450828ea ==============================
[0m09:07:35.668366 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:07:35.669262 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'quiet': 'False', 'warn_error': 'None', 'no_print': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'fail_fast': 'False', 'static_parser': 'True', 'debug': 'False', 'profiles_dir': '/Users/david/.dbt', 'version_check': 'True', 'invocation_command': 'dbt run --select accounts_history_advanced', 'log_format': 'default', 'partial_parse': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'printer_width': '80'}
[0m09:07:39.151846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '77c0d4f8-bdf2-4b8b-b2a0-5e68450828ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadff2ca730>]}
[0m09:07:39.220506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '77c0d4f8-bdf2-4b8b-b2a0-5e68450828ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae04dc0d60>]}
[0m09:07:39.221362 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:07:39.249265 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:07:39.571659 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:07:39.572171 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:07:39.639330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '77c0d4f8-bdf2-4b8b-b2a0-5e68450828ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae05729130>]}
[0m09:07:39.816310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '77c0d4f8-bdf2-4b8b-b2a0-5e68450828ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae05728310>]}
[0m09:07:39.817080 [info ] [MainThread]: Found 12 models, 3 seeds, 1 operation, 480 macros
[0m09:07:39.817619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '77c0d4f8-bdf2-4b8b-b2a0-5e68450828ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae056f8310>]}
[0m09:07:39.819344 [info ] [MainThread]: 
[0m09:07:39.820149 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:07:39.821265 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:07:39.821866 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:07:44.920890 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:07:44.921852 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:07:46.772313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '77c0d4f8-bdf2-4b8b-b2a0-5e68450828ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadff178880>]}
[0m09:07:46.773197 [info ] [MainThread]: 
[0m09:07:46.773789 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:07:46.791471 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:07:46.798922 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:07:46.799725 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:07:46.800444 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:07:48.594520 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:547eb62b-ad1d-496d-8380-96b5e335cc0a&page=queryresults
[0m09:07:50.862386 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 4.06s]
[0m09:07:50.863149 [info ] [MainThread]: 
[0m09:07:50.863992 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:07:50.864595 [info ] [MainThread]: 
[0m09:07:50.869000 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m09:07:50.869939 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m09:07:50.870689 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m09:07:50.871308 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m09:07:50.877674 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m09:07:50.879205 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m09:07:50.901865 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:07:52.836073 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m09:07:52.837731 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
    paid_total_excl_dp / unlock_price_excl_dp as perc_paid,
  FROM join_wo_statuses
),

usage_rates as (
    SELECT 
        *,
        AVG(
            IF(reporting_date_status in ('ENABLED', 'UNLOCKED'), 1, 0)
        ) OVER(
            PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN 180 PRECEDING AND CURRENT ROW
        ) as usage_rate_last_180d,
    FROM final_kpis
),

segmentations as (
    SELECT 
        *,
        CASE 
            WHEN usage_rate_last_180d >= 0.95 THEN 'A'
            WHEN usage_rate_last_180d >= 0.90 THEN 'B'
            WHEN usage_rate_last_180d >= 0.60 THEN 'C'
            WHEN usage_rate_last_180d < 0.60  THEN 'D'
        END as account_segmentation,
    FROM usage_rates
)

SELECT * FROM segmentations
    );
  
[0m09:07:53.937126 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:8613f193-fdc1-4b5e-97e6-68ee04a63f0c&page=queryresults
[0m09:08:17.157790 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77c0d4f8-bdf2-4b8b-b2a0-5e68450828ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae04dc0610>]}
[0m09:08:17.158816 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 511.5 MiB processed)[0m in 26.29s]
[0m09:08:17.159870 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m09:08:17.161434 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:08:17.161904 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m09:08:17.162395 [info ] [MainThread]: 
[0m09:08:17.162925 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 37.34 seconds (37.34s).
[0m09:08:17.163931 [debug] [MainThread]: Command end result
[0m09:08:17.210055 [info ] [MainThread]: 
[0m09:08:17.210861 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:08:17.211384 [info ] [MainThread]: 
[0m09:08:17.211889 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:08:17.212621 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 41.62645, "process_user_time": 4.923486, "process_kernel_time": 0.924353, "process_mem_max_rss": "227368960", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:08:17.213394 [debug] [MainThread]: Command `dbt run` succeeded at 09:08:17.213259 after 41.63 seconds
[0m09:08:17.213929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadfcb644c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadfebb87c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae0543e5b0>]}
[0m09:08:17.214441 [debug] [MainThread]: Flushing usage events
[0m09:10:35.642912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f9b60550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3fd969d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3fd969400>]}


============================== 09:10:35.647274 | bbfa88a1-5e65-4d26-bac3-3523fd9a4799 ==============================
[0m09:10:35.647274 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:10:35.648333 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run --select compute_samples', 'version_check': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'profiles_dir': '/Users/david/.dbt', 'partial_parse': 'True', 'printer_width': '80', 'empty': 'False', 'debug': 'False', 'log_cache_events': 'False', 'write_json': 'True', 'use_colors': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error': 'None', 'log_format': 'default', 'no_print': 'None', 'quiet': 'False', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False'}
[0m09:10:38.265878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bbfa88a1-5e65-4d26-bac3-3523fd9a4799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff401dbea90>]}
[0m09:10:38.339620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bbfa88a1-5e65-4d26-bac3-3523fd9a4799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40259c250>]}
[0m09:10:38.340608 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:10:38.370192 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:10:38.673345 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:10:38.673841 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:10:38.741669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bbfa88a1-5e65-4d26-bac3-3523fd9a4799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff403071130>]}
[0m09:10:38.888578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bbfa88a1-5e65-4d26-bac3-3523fd9a4799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff403070dc0>]}
[0m09:10:38.889252 [info ] [MainThread]: Found 13 models, 3 seeds, 1 operation, 480 macros
[0m09:10:38.889757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bbfa88a1-5e65-4d26-bac3-3523fd9a4799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40303c9a0>]}
[0m09:10:38.891282 [info ] [MainThread]: 
[0m09:10:38.892067 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:10:38.893157 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:10:38.893705 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:10:42.632910 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:10:42.633792 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:10:44.221803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bbfa88a1-5e65-4d26-bac3-3523fd9a4799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f9aedbe0>]}
[0m09:10:44.223707 [info ] [MainThread]: 
[0m09:10:44.224485 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:10:44.242659 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:10:44.249272 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:10:44.250025 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:10:44.250724 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:10:45.839927 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:9e0a846c-5e0a-4522-bd85-09906a0817e7&page=queryresults
[0m09:10:47.625096 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.37s]
[0m09:10:47.625656 [info ] [MainThread]: 
[0m09:10:47.626329 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:10:47.626851 [info ] [MainThread]: 
[0m09:10:47.630391 [debug] [Thread-1  ]: Began running node model.creditrisk.compute_samples
[0m09:10:47.630991 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.compute_samples ....................... [RUN]
[0m09:10:47.632128 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.compute_samples)
[0m09:10:47.632632 [debug] [Thread-1  ]: Began compiling node model.creditrisk.compute_samples
[0m09:10:47.636632 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.compute_samples"
[0m09:10:47.637724 [debug] [Thread-1  ]: Began executing node model.creditrisk.compute_samples
[0m09:10:47.668641 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.compute_samples"
[0m09:10:47.669503 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:10:47.670072 [debug] [Thread-1  ]: On model.creditrisk.compute_samples: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.compute_samples"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`compute_samples`
  OPTIONS()
  as /*
    This transformation is quite essential to produce an unbiaised model
    For every chunk of repayment [0-10%], [10-20%], etc... it estimates what is the sample of accounts we can use for estimating probabilities of default.
    For example, if for 40 - 50% the sample end date is 2020-12-03, it means that we must use only accounts registered prior to this date.
    Otherwise, we are going to produce biaised (selection bias) estimates, as too many accounts will not have finished paying or will not have defaulted.
*/

WITH default_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
),

date_spine as (
    SELECT reporting_date as sample_end_date FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

-- Generates a table containing 10 rows, representing the different chunks of repayment : 0 to 10%, 10 to 20%, etc...
split_chunks as (
    SELECT 
        *,
        index_chunk / 10 as perc_paid_chunk_start,
        COALESCE(
            LEAD(index_chunk / 10) OVER(ORDER BY index_chunk),
            1
        ) as perc_paid_chunk_end,
    FROM UNNEST(GENERATE_ARRAY(0, 9)) as index_chunk
),

crossjoint as (
    SELECT 
        *,
        IF(perc_paid < perc_paid_chunk_end AND has_defaulted = 0, 1, 0) as is_censored,
    FROM default_history
    CROSS JOIN split_chunks
),

grouped as (
    SELECT 
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        sample_end_date,
        AVG(is_censored) as censored_percent,
    FROM crossjoint
    LEFT JOIN date_spine
    ON date_spine.sample_end_date >= crossjoint.registration_date
    GROUP BY ALL
    HAVING censored_percent <= 0.05 -- Here the tolerance to censoring is 5%.
),

get_chunck_dates as (
    SELECT 
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        MAX(sample_end_date) as sample_end_date,
    FROM grouped 
    GROUP BY ALL
)

SELECT * FROM get_chunck_dates;


[0m09:10:49.330873 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:98989369-e89e-4310-97f4-ef68ea97f963&page=queryresults
[0m09:10:49.331800 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:98989369-e89e-4310-97f4-ef68ea97f963&page=queryresults
[0m09:10:49.347984 [debug] [Thread-1  ]: Database Error in model compute_samples (models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_samples.sql)
  Not found: Table steam-outlet-209412:oscreditrisk.history_defaults was not found in location EU
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_samples.sql
[0m09:10:49.349968 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bbfa88a1-5e65-4d26-bac3-3523fd9a4799', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3e3f6f310>]}
[0m09:10:49.350824 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.compute_samples .............. [[31mERROR[0m in 1.72s]
[0m09:10:49.351872 [debug] [Thread-1  ]: Finished running node model.creditrisk.compute_samples
[0m09:10:49.353373 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:10:49.353804 [debug] [MainThread]: Connection 'model.creditrisk.compute_samples' was properly closed.
[0m09:10:49.354259 [info ] [MainThread]: 
[0m09:10:49.354750 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 10.46 seconds (10.46s).
[0m09:10:49.355737 [debug] [MainThread]: Command end result
[0m09:10:49.403204 [info ] [MainThread]: 
[0m09:10:49.403877 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m09:10:49.404326 [info ] [MainThread]: 
[0m09:10:49.404942 [error] [MainThread]:   Database Error in model compute_samples (models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_samples.sql)
  Not found: Table steam-outlet-209412:oscreditrisk.history_defaults was not found in location EU
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_1_lifetime_ecl_model/compute_samples.sql
[0m09:10:49.405466 [info ] [MainThread]: 
[0m09:10:49.406002 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:10:49.406726 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 13.842853, "process_user_time": 4.460696, "process_kernel_time": 0.658477, "process_mem_max_rss": "227344384", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:10:49.407501 [debug] [MainThread]: Command `dbt run` failed at 09:10:49.407367 after 13.84 seconds
[0m09:10:49.408036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f9b60550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f9e5b550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4025a61f0>]}
[0m09:10:49.408538 [debug] [MainThread]: Flushing usage events
[0m09:11:53.247891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e161634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e18971d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e18971100>]}


============================== 09:11:53.252806 | 00d24156-bfe6-406b-9bb3-4d082e70932f ==============================
[0m09:11:53.252806 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:11:53.253736 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/david/.dbt', 'warn_error': 'None', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'no_print': 'None', 'use_colors': 'True', 'version_check': 'True', 'invocation_command': 'dbt run --select 4_baobabplus_methodology', 'quiet': 'False', 'log_cache_events': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'debug': 'False', 'introspect': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_format': 'default', 'write_json': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'empty': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'fail_fast': 'False'}
[0m09:11:56.917969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '00d24156-bfe6-406b-9bb3-4d082e70932f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1dc0c370>]}
[0m09:11:56.971982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '00d24156-bfe6-406b-9bb3-4d082e70932f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1d4daf70>]}
[0m09:11:56.990828 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:11:57.038388 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:11:57.375017 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:11:57.375538 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:11:57.433864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '00d24156-bfe6-406b-9bb3-4d082e70932f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1e872130>]}
[0m09:11:57.580406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '00d24156-bfe6-406b-9bb3-4d082e70932f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1e874130>]}
[0m09:11:57.581165 [info ] [MainThread]: Found 13 models, 3 seeds, 1 operation, 480 macros
[0m09:11:57.581706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '00d24156-bfe6-406b-9bb3-4d082e70932f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1e83c850>]}
[0m09:11:57.583465 [info ] [MainThread]: 
[0m09:11:57.584248 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:11:57.590752 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:11:57.591443 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:12:01.462427 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:12:01.463432 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:12:03.076377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '00d24156-bfe6-406b-9bb3-4d082e70932f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e16471cd0>]}
[0m09:12:03.077339 [info ] [MainThread]: 
[0m09:12:03.077945 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:12:03.096471 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:12:03.103695 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:12:03.104498 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:12:03.105216 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:12:04.710055 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ff4943a6-1e00-432f-b1b4-cb59b059fc9e&page=queryresults
[0m09:12:06.557866 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.45s]
[0m09:12:06.558718 [info ] [MainThread]: 
[0m09:12:06.559596 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:12:06.560219 [info ] [MainThread]: 
[0m09:12:06.564414 [debug] [Thread-1  ]: Began running node model.creditrisk.history_defaults
[0m09:12:06.565473 [info ] [Thread-1  ]: 1 of 4 START sql view model oscreditrisk.history_defaults ...................... [RUN]
[0m09:12:06.566245 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.history_defaults)
[0m09:12:06.566853 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_defaults
[0m09:12:06.571614 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_defaults"
[0m09:12:06.572644 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_defaults
[0m09:12:06.616183 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_defaults"
[0m09:12:06.617210 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:12:06.617897 [debug] [Thread-1  ]: On model.creditrisk.history_defaults: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_defaults"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
  OPTIONS()
  as /*
    This transformations creates a dataset containing one line per account and contains the information if the account has defaulted or not. 
*/

WITH history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

detect_defaults as (
    SELECT 
        account_id,
        registration_date,
        perc_paid,
        CASE 
            WHEN reporting_date_status in ('UNLOCKED') THEN 0
            WHEN reporting_date_status in ('DETACHED', 'WRITTEN_OFF') THEN 1
            WHEN days_disabled >= 180 THEN 1
            ELSE 0
        END as has_defaulted,
    FROM history
)

SELECT * FROM detect_defaults;


[0m09:12:08.357477 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:90802f91-fa20-436f-a8f4-5333906f91a1&page=queryresults
[0m09:12:09.798954 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00d24156-bfe6-406b-9bb3-4d082e70932f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dff4b9640>]}
[0m09:12:09.799934 [info ] [Thread-1  ]: 1 of 4 OK created sql view model oscreditrisk.history_defaults ................. [[32mCREATE VIEW (0 processed)[0m in 3.23s]
[0m09:12:09.800897 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_defaults
[0m09:12:09.801605 [debug] [Thread-1  ]: Began running node model.creditrisk.history_segmentations
[0m09:12:09.802330 [info ] [Thread-1  ]: 2 of 4 START sql view model oscreditrisk.history_segmentations ................. [RUN]
[0m09:12:09.803204 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_defaults, now model.creditrisk.history_segmentations)
[0m09:12:09.803786 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_segmentations
[0m09:12:09.812882 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_segmentations"
[0m09:12:09.813942 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_segmentations
[0m09:12:09.818738 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_segmentations"
[0m09:12:09.819841 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:12:09.820852 [debug] [Thread-1  ]: On model.creditrisk.history_segmentations: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_segmentations"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_segmentations`
  OPTIONS()
  as WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
)

segmentation_at_0 as (
  SELECT 
    account_id,
    0 as perc_paid_chunk,
    '0. At registration' as account_segmentation,
  FROM accounts_history
  WHERE reporting_day = 1
),

segmentation_at_10 as (
  SELECT 
    account_id,
    0.1 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.1
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_20 as (
  SELECT 
    account_id,
    0.2 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.2
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_30 as (
  SELECT 
    account_id,
    0.3 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.3
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_40 as (
  SELECT 
    account_id,
    0.4 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.4
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_50 as (
  SELECT 
    account_id,
    0.5 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.5
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_60 as (
  SELECT 
    account_id,
    0.6 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.6
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_70 as (
  SELECT 
    account_id,
    0.7 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.7
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_80 as (
  SELECT 
    account_id,
    0.8 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.8
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_90 as (
  SELECT 
    account_id,
    0.9 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.9
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
)

SELECT * FROM segmentation_at_0 
UNION ALL
SELECT * FROM segmentation_at_10
UNION ALL
SELECT * FROM segmentation_at_20
UNION ALL
SELECT * FROM segmentation_at_30
UNION ALL
SELECT * FROM segmentation_at_40
UNION ALL
SELECT * FROM segmentation_at_50
UNION ALL
SELECT * FROM segmentation_at_60
UNION ALL
SELECT * FROM segmentation_at_70
UNION ALL
SELECT * FROM segmentation_at_80
UNION ALL
SELECT * FROM segmentation_at_90;


[0m09:12:11.334152 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:114afae8-b3d9-4b8b-b103-0cea99a64e7b&page=queryresults
[0m09:12:11.334903 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected identifier "segmentation_at_0" at [10:1]; reason: invalidQuery, location: query, message: Syntax error: Unexpected identifier "segmentation_at_0" at [10:1]')
[0m09:12:12.852438 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ccdd1f11-1a07-40dc-9f7c-6fea9a38758c&page=queryresults
[0m09:12:12.853904 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ccdd1f11-1a07-40dc-9f7c-6fea9a38758c&page=queryresults
[0m09:12:12.869326 [debug] [Thread-1  ]: Database Error in model history_segmentations (models/4_baobabplus_methodology/4_1_lifetime_ecl_model/history_segmentations.sql)
  Syntax error: Unexpected identifier "segmentation_at_0" at [10:1]
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_1_lifetime_ecl_model/history_segmentations.sql
[0m09:12:12.870156 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00d24156-bfe6-406b-9bb3-4d082e70932f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dff4b9250>]}
[0m09:12:12.871141 [error] [Thread-1  ]: 2 of 4 ERROR creating sql view model oscreditrisk.history_segmentations ........ [[31mERROR[0m in 3.07s]
[0m09:12:12.872291 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_segmentations
[0m09:12:12.873179 [debug] [Thread-1  ]: Began running node model.creditrisk.compute_samples
[0m09:12:12.874180 [info ] [Thread-1  ]: 3 of 4 START sql view model oscreditrisk.compute_samples ....................... [RUN]
[0m09:12:12.874933 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_segmentations, now model.creditrisk.compute_samples)
[0m09:12:12.875546 [debug] [Thread-1  ]: Began compiling node model.creditrisk.compute_samples
[0m09:12:12.882313 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.compute_samples"
[0m09:12:12.883640 [debug] [Thread-1  ]: Began executing node model.creditrisk.compute_samples
[0m09:12:12.888026 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.compute_samples"
[0m09:12:12.889003 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:12:12.889775 [debug] [Thread-1  ]: On model.creditrisk.compute_samples: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.compute_samples"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`compute_samples`
  OPTIONS()
  as /*
    This transformation is quite essential to produce an unbiaised model
    For every chunk of repayment [0-10%], [10-20%], etc... it estimates what is the sample of accounts we can use for estimating probabilities of default.
    For example, if for 40 - 50% the sample end date is 2020-12-03, it means that we must use only accounts registered prior to this date.
    Otherwise, we are going to produce biaised (selection bias) estimates, as too many accounts will not have finished paying or will not have defaulted.
*/

WITH default_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
),

date_spine as (
    SELECT reporting_date as sample_end_date FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

-- Generates a table containing 10 rows, representing the different chunks of repayment : 0 to 10%, 10 to 20%, etc...
split_chunks as (
    SELECT 
        *,
        index_chunk / 10 as perc_paid_chunk_start,
        COALESCE(
            LEAD(index_chunk / 10) OVER(ORDER BY index_chunk),
            1
        ) as perc_paid_chunk_end,
    FROM UNNEST(GENERATE_ARRAY(0, 9)) as index_chunk
),

crossjoint as (
    SELECT 
        *,
        IF(perc_paid < perc_paid_chunk_end AND has_defaulted = 0, 1, 0) as is_censored,
    FROM default_history
    CROSS JOIN split_chunks
),

grouped as (
    SELECT 
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        sample_end_date,
        AVG(is_censored) as censored_percent,
    FROM crossjoint
    LEFT JOIN date_spine
    ON date_spine.sample_end_date >= crossjoint.registration_date
    GROUP BY ALL
    HAVING censored_percent <= 0.05 -- Here the tolerance to censoring is 5%.
),

get_chunck_dates as (
    SELECT 
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        MAX(sample_end_date) as sample_end_date,
    FROM grouped 
    GROUP BY ALL
)

SELECT * FROM get_chunck_dates;


[0m09:12:14.876511 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:0110c084-c618-4270-afe5-c7e42a7af163&page=queryresults
[0m09:12:16.162935 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00d24156-bfe6-406b-9bb3-4d082e70932f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1dcb5340>]}
[0m09:12:16.164090 [info ] [Thread-1  ]: 3 of 4 OK created sql view model oscreditrisk.compute_samples .................. [[32mCREATE VIEW (0 processed)[0m in 3.29s]
[0m09:12:16.165236 [debug] [Thread-1  ]: Finished running node model.creditrisk.compute_samples
[0m09:12:16.166435 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_inputs
[0m09:12:16.167125 [info ] [Thread-1  ]: 4 of 4 SKIP relation oscreditrisk.prepare_model_inputs ......................... [[33mSKIP[0m]
[0m09:12:16.167931 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_inputs
[0m09:12:16.169470 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:12:16.169958 [debug] [MainThread]: Connection 'model.creditrisk.compute_samples' was properly closed.
[0m09:12:16.170573 [info ] [MainThread]: 
[0m09:12:16.171218 [info ] [MainThread]: Finished running 4 view models, 1 project hook in 0 hours 0 minutes and 18.59 seconds (18.59s).
[0m09:12:16.172851 [debug] [MainThread]: Command end result
[0m09:12:16.225098 [info ] [MainThread]: 
[0m09:12:16.225950 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m09:12:16.226451 [info ] [MainThread]: 
[0m09:12:16.227056 [error] [MainThread]:   Database Error in model history_segmentations (models/4_baobabplus_methodology/4_1_lifetime_ecl_model/history_segmentations.sql)
  Syntax error: Unexpected identifier "segmentation_at_0" at [10:1]
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_1_lifetime_ecl_model/history_segmentations.sql
[0m09:12:16.227545 [info ] [MainThread]: 
[0m09:12:16.228060 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=1 TOTAL=4
[0m09:12:16.228820 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 23.059702, "process_user_time": 4.902139, "process_kernel_time": 0.951551, "process_mem_max_rss": "227577856", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:12:16.229631 [debug] [MainThread]: Command `dbt run` failed at 09:12:16.229495 after 23.06 seconds
[0m09:12:16.230180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e161634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e181493d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1dcaa130>]}
[0m09:12:16.230709 [debug] [MainThread]: Flushing usage events
[0m09:13:11.499120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae461634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae49a76310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae49a76f10>]}


============================== 09:13:11.504584 | 40ef8830-f858-4de7-be02-644f9d968073 ==============================
[0m09:13:11.504584 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:13:11.505835 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'introspect': 'True', 'profiles_dir': '/Users/david/.dbt', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'static_parser': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select history_segmentations', 'warn_error': 'None', 'write_json': 'True', 'log_format': 'default', 'debug': 'False', 'version_check': 'True', 'target_path': 'None', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'quiet': 'False'}
[0m09:13:15.560119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '40ef8830-f858-4de7-be02-644f9d968073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae4dc8b520>]}
[0m09:13:15.614730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '40ef8830-f858-4de7-be02-644f9d968073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae4e3374f0>]}
[0m09:13:15.615445 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:13:15.641945 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:13:15.988017 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:13:15.988535 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:13:16.051109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '40ef8830-f858-4de7-be02-644f9d968073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae4e772130>]}
[0m09:13:16.194751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '40ef8830-f858-4de7-be02-644f9d968073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae4e771790>]}
[0m09:13:16.195463 [info ] [MainThread]: Found 13 models, 3 seeds, 1 operation, 480 macros
[0m09:13:16.196017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '40ef8830-f858-4de7-be02-644f9d968073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae4e73c0a0>]}
[0m09:13:16.197685 [info ] [MainThread]: 
[0m09:13:16.198469 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:13:16.199547 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:13:16.203030 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:13:20.089656 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:13:20.090817 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:13:21.565270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '40ef8830-f858-4de7-be02-644f9d968073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae4e38dc70>]}
[0m09:13:21.567482 [info ] [MainThread]: 
[0m09:13:21.568623 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:13:21.593543 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:13:21.606102 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:13:21.607607 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:13:21.608897 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:13:22.990071 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:e1a270e9-c348-40ae-9c6d-e8e12ef3b672&page=queryresults
[0m09:13:24.754919 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.15s]
[0m09:13:24.755535 [info ] [MainThread]: 
[0m09:13:24.756237 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:13:24.756719 [info ] [MainThread]: 
[0m09:13:24.759799 [debug] [Thread-1  ]: Began running node model.creditrisk.history_segmentations
[0m09:13:24.760628 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.history_segmentations ................. [RUN]
[0m09:13:24.761445 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.history_segmentations)
[0m09:13:24.762073 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_segmentations
[0m09:13:24.767305 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_segmentations"
[0m09:13:24.768366 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_segmentations
[0m09:13:24.818231 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_segmentations"
[0m09:13:24.819290 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:13:24.820101 [debug] [Thread-1  ]: On model.creditrisk.history_segmentations: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_segmentations"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_segmentations`
  OPTIONS()
  as WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

segmentation_at_0 as (
  SELECT 
    account_id,
    0 as perc_paid_chunk,
    '0. At registration' as account_segmentation,
  FROM accounts_history
  WHERE reporting_day = 1
),

segmentation_at_10 as (
  SELECT 
    account_id,
    0.1 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.1
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_20 as (
  SELECT 
    account_id,
    0.2 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.2
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_30 as (
  SELECT 
    account_id,
    0.3 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.3
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_40 as (
  SELECT 
    account_id,
    0.4 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.4
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_50 as (
  SELECT 
    account_id,
    0.5 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.5
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_60 as (
  SELECT 
    account_id,
    0.6 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.6
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_70 as (
  SELECT 
    account_id,
    0.7 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.7
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_80 as (
  SELECT 
    account_id,
    0.8 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.8
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_90 as (
  SELECT 
    account_id,
    0.9 as perc_paid_chunk,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.9
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
)

SELECT * FROM segmentation_at_0
UNION ALL
SELECT * FROM segmentation_at_10
UNION ALL
SELECT * FROM segmentation_at_20
UNION ALL
SELECT * FROM segmentation_at_30
UNION ALL
SELECT * FROM segmentation_at_40
UNION ALL
SELECT * FROM segmentation_at_50
UNION ALL
SELECT * FROM segmentation_at_60
UNION ALL
SELECT * FROM segmentation_at_70
UNION ALL
SELECT * FROM segmentation_at_80
UNION ALL
SELECT * FROM segmentation_at_90;


[0m09:13:26.519315 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ef3afdd4-a0f9-4705-a360-84d1d5297be3&page=queryresults
[0m09:13:27.808516 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40ef8830-f858-4de7-be02-644f9d968073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae48bd4dc0>]}
[0m09:13:27.809529 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.history_segmentations ............ [[32mCREATE VIEW (0 processed)[0m in 3.05s]
[0m09:13:27.810504 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_segmentations
[0m09:13:27.812102 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:13:27.812647 [debug] [MainThread]: Connection 'model.creditrisk.history_segmentations' was properly closed.
[0m09:13:27.813138 [info ] [MainThread]: 
[0m09:13:27.813649 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 11.61 seconds (11.61s).
[0m09:13:27.814620 [debug] [MainThread]: Command end result
[0m09:13:27.861930 [info ] [MainThread]: 
[0m09:13:27.862617 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:13:27.863082 [info ] [MainThread]: 
[0m09:13:27.863570 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:13:27.864274 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 16.4524, "process_user_time": 4.834878, "process_kernel_time": 0.928175, "process_mem_max_rss": "227237888", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:13:27.865055 [debug] [MainThread]: Command `dbt run` succeeded at 09:13:27.864920 after 16.45 seconds
[0m09:13:27.865599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae461634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae4e2fed90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae4dbbe730>]}
[0m09:13:27.866156 [debug] [MainThread]: Flushing usage events
[0m09:13:40.225461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92d2b61580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92d53f0be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92d53f0190>]}


============================== 09:13:40.230365 | d694407a-1ec7-4140-ab9d-a1d2eb9a8f55 ==============================
[0m09:13:40.230365 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:13:40.231355 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'invocation_command': 'dbt run --select prepare_model_inputs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'empty': 'False', 'write_json': 'True', 'quiet': 'False', 'log_cache_events': 'False', 'static_parser': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'printer_width': '80', 'cache_selected_only': 'False', 'warn_error': 'None', 'log_format': 'default', 'introspect': 'True', 'version_check': 'True', 'no_print': 'None', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/david/.dbt', 'indirect_selection': 'eager'}
[0m09:13:44.320818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd694407a-1ec7-4140-ab9d-a1d2eb9a8f55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92d9d5fa30>]}
[0m09:13:44.381240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd694407a-1ec7-4140-ab9d-a1d2eb9a8f55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92d9d17ca0>]}
[0m09:13:44.381946 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:13:44.410166 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:13:44.756368 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:13:44.756818 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:13:44.816168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd694407a-1ec7-4140-ab9d-a1d2eb9a8f55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92da0b2130>]}
[0m09:13:44.963148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd694407a-1ec7-4140-ab9d-a1d2eb9a8f55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92da0b15b0>]}
[0m09:13:44.963869 [info ] [MainThread]: Found 13 models, 3 seeds, 1 operation, 480 macros
[0m09:13:44.964402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd694407a-1ec7-4140-ab9d-a1d2eb9a8f55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92da07c4f0>]}
[0m09:13:44.966130 [info ] [MainThread]: 
[0m09:13:44.967082 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:13:44.968292 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:13:44.968911 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:13:51.351863 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:13:51.353148 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:13:51.970149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd694407a-1ec7-4140-ab9d-a1d2eb9a8f55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92d9df5b50>]}
[0m09:13:51.971004 [info ] [MainThread]: 
[0m09:13:51.971738 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:13:51.989449 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:13:51.997038 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:13:51.997834 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:13:51.998656 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:13:52.579708 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:0af88520-f926-48bf-b988-c86c4fb525c5&page=queryresults
[0m09:13:54.074487 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.08s]
[0m09:13:54.075295 [info ] [MainThread]: 
[0m09:13:54.076407 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:13:54.076973 [info ] [MainThread]: 
[0m09:13:54.080623 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_inputs
[0m09:13:54.081591 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.prepare_model_inputs .................. [RUN]
[0m09:13:54.082325 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.prepare_model_inputs)
[0m09:13:54.082937 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_inputs
[0m09:13:54.088831 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_inputs"
[0m09:13:54.089895 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_inputs
[0m09:13:54.136846 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_inputs"
[0m09:13:54.138025 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:13:54.138750 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_inputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_inputs"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
  OPTIONS()
  as WITH accs as (
  SELECT 
    *,
  FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
  LEFT JOIN `steam-outlet-209412`.`oscreditrisk`.`history_segmentations` USING(account_id)
),

samples as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`compute_samples`
),

joint as (
  SELECT 
    accs.*,
    samples.*,
    RAND() as rnd,
  FROM accs
  INNER JOIN samples
  ON 
    accs.registration_date < CAST(samples.sample_end_date AS TIMESTAMP)
)

SELECT * FROM joint;


[0m09:13:55.202131 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:6e344ea8-8198-4718-89c3-c8f0cbcd21eb&page=queryresults
[0m09:13:55.843058 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd694407a-1ec7-4140-ab9d-a1d2eb9a8f55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92d94ef700>]}
[0m09:13:55.844067 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.prepare_model_inputs ............. [[32mCREATE VIEW (0 processed)[0m in 1.76s]
[0m09:13:55.845046 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_inputs
[0m09:13:55.846783 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:13:55.847251 [debug] [MainThread]: Connection 'model.creditrisk.prepare_model_inputs' was properly closed.
[0m09:13:55.847736 [info ] [MainThread]: 
[0m09:13:55.848254 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 10.88 seconds (10.88s).
[0m09:13:55.849272 [debug] [MainThread]: Command end result
[0m09:13:55.896290 [info ] [MainThread]: 
[0m09:13:55.897022 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:13:55.897511 [info ] [MainThread]: 
[0m09:13:55.898016 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:13:55.898745 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 15.767252, "process_user_time": 5.320094, "process_kernel_time": 0.952705, "process_mem_max_rss": "226922496", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:13:55.899517 [debug] [MainThread]: Command `dbt run` succeeded at 09:13:55.899382 after 15.77 seconds
[0m09:13:55.900052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92d2b61580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92d4a848e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92d2e2d6a0>]}
[0m09:13:55.900554 [debug] [MainThread]: Flushing usage events
[0m09:25:39.893737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf818274f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf83830dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf83830070>]}


============================== 09:25:39.898071 | 2a9272b2-6d39-4395-858d-32507ffe1ec6 ==============================
[0m09:25:39.898071 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:25:39.899117 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'fail_fast': 'False', 'target_path': 'None', 'use_colors': 'True', 'profiles_dir': '/Users/david/.dbt', 'partial_parse': 'True', 'introspect': 'True', 'empty': 'False', 'write_json': 'True', 'log_format': 'default', 'debug': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'warn_error': 'None', 'invocation_command': 'dbt run --select history_segmentations', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'version_check': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'static_parser': 'True', 'cache_selected_only': 'False'}
[0m09:25:42.725443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2a9272b2-6d39-4395-858d-32507ffe1ec6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8a60c280>]}
[0m09:25:42.799499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2a9272b2-6d39-4395-858d-32507ffe1ec6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8a5fee50>]}
[0m09:25:42.801036 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:25:42.843967 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:25:43.306799 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:25:43.307419 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:25:43.382947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2a9272b2-6d39-4395-858d-32507ffe1ec6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8a975130>]}
[0m09:25:43.561338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2a9272b2-6d39-4395-858d-32507ffe1ec6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8a99a6a0>]}
[0m09:25:43.562157 [info ] [MainThread]: Found 14 models, 3 seeds, 1 operation, 480 macros
[0m09:25:43.562981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a9272b2-6d39-4395-858d-32507ffe1ec6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf81c63220>]}
[0m09:25:43.564850 [info ] [MainThread]: 
[0m09:25:43.565687 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:25:43.566845 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:25:43.567437 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:25:47.189014 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:25:47.189930 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:25:47.789556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a9272b2-6d39-4395-858d-32507ffe1ec6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf817b2b80>]}
[0m09:25:47.790462 [info ] [MainThread]: 
[0m09:25:47.791015 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:25:47.807813 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:25:47.814710 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:25:47.815454 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:25:47.816131 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:25:48.453902 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:c78d3f02-256e-4546-8055-44f2163d277e&page=queryresults
[0m09:25:50.186204 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.37s]
[0m09:25:50.187059 [info ] [MainThread]: 
[0m09:25:50.187921 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:25:50.188516 [info ] [MainThread]: 
[0m09:25:50.192699 [debug] [Thread-1  ]: Began running node model.creditrisk.history_segmentations
[0m09:25:50.193965 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.history_segmentations ................. [RUN]
[0m09:25:50.194849 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.history_segmentations)
[0m09:25:50.195496 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_segmentations
[0m09:25:50.200749 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_segmentations"
[0m09:25:50.202751 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_segmentations
[0m09:25:50.247315 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_segmentations"
[0m09:25:50.248341 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:25:50.249108 [debug] [Thread-1  ]: On model.creditrisk.history_segmentations: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_segmentations"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_segmentations`
  OPTIONS()
  as WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

segmentation_at_0 as (
  SELECT 
    account_id,
    0 as perc_paid_current,
    '0. At registration' as account_segmentation,
  FROM accounts_history
  WHERE reporting_day = 1
),

segmentation_at_10 as (
  SELECT 
    account_id,
    0.1 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.1
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_20 as (
  SELECT 
    account_id,
    0.2 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.2
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_30 as (
  SELECT 
    account_id,
    0.3 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.3
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_40 as (
  SELECT 
    account_id,
    0.4 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.4
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_50 as (
  SELECT 
    account_id,
    0.5 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.5
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_60 as (
  SELECT 
    account_id,
    0.6 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.6
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_70 as (
  SELECT 
    account_id,
    0.7 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.7
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_80 as (
  SELECT 
    account_id,
    0.8 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.8
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_90 as (
  SELECT 
    account_id,
    0.9 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.9
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
)

SELECT * FROM segmentation_at_0
UNION ALL
SELECT * FROM segmentation_at_10
UNION ALL
SELECT * FROM segmentation_at_20
UNION ALL
SELECT * FROM segmentation_at_30
UNION ALL
SELECT * FROM segmentation_at_40
UNION ALL
SELECT * FROM segmentation_at_50
UNION ALL
SELECT * FROM segmentation_at_60
UNION ALL
SELECT * FROM segmentation_at_70
UNION ALL
SELECT * FROM segmentation_at_80
UNION ALL
SELECT * FROM segmentation_at_90;


[0m09:25:50.972693 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ce927cf0-d626-40d3-9dbf-9f8527cffd3e&page=queryresults
[0m09:25:51.668247 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a9272b2-6d39-4395-858d-32507ffe1ec6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf89dba640>]}
[0m09:25:51.669170 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.history_segmentations ............ [[32mCREATE VIEW (0 processed)[0m in 1.47s]
[0m09:25:51.670066 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_segmentations
[0m09:25:51.671659 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:25:51.672120 [debug] [MainThread]: Connection 'model.creditrisk.history_segmentations' was properly closed.
[0m09:25:51.672598 [info ] [MainThread]: 
[0m09:25:51.673113 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 8.11 seconds (8.11s).
[0m09:25:51.674126 [debug] [MainThread]: Command end result
[0m09:25:51.721249 [info ] [MainThread]: 
[0m09:25:51.721941 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:25:51.722417 [info ] [MainThread]: 
[0m09:25:51.722934 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:25:51.723696 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.905495, "process_user_time": 4.567574, "process_kernel_time": 0.684037, "process_mem_max_rss": "227799040", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:25:51.724540 [debug] [MainThread]: Command `dbt run` succeeded at 09:25:51.724379 after 11.91 seconds
[0m09:25:51.725126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf818274f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8a791bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8a5fee50>]}
[0m09:25:51.725649 [debug] [MainThread]: Flushing usage events
[0m09:26:13.774856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce3d260550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce3f271d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce3f271400>]}


============================== 09:26:13.779974 | 54c60edf-8017-4bbe-b556-f1527ac9abe0 ==============================
[0m09:26:13.779974 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:26:13.780929 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error': 'None', 'profiles_dir': '/Users/david/.dbt', 'indirect_selection': 'eager', 'target_path': 'None', 'version_check': 'True', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'write_json': 'True', 'printer_width': '80', 'use_colors': 'True', 'fail_fast': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'cache_selected_only': 'False', 'invocation_command': 'dbt run --select 4_baobabplus_methodology', 'introspect': 'True', 'no_print': 'None'}
[0m09:26:17.456174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce43ec7550>]}
[0m09:26:17.512140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce4459c2e0>]}
[0m09:26:17.512872 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:26:17.540918 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:26:17.872803 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:26:17.873341 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:26:17.937879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce4507beb0>]}
[0m09:26:18.092819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce45099250>]}
[0m09:26:18.093702 [info ] [MainThread]: Found 14 models, 3 seeds, 1 operation, 480 macros
[0m09:26:18.094271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce3d771d90>]}
[0m09:26:18.096132 [info ] [MainThread]: 
[0m09:26:18.096929 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:26:18.103591 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:26:18.104350 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:26:23.093625 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:26:23.094614 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:26:24.629266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce4459ca60>]}
[0m09:26:24.630349 [info ] [MainThread]: 
[0m09:26:24.631599 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:26:24.654837 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:26:24.664990 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:26:24.666171 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:26:24.667250 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:26:26.357037 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:54cc1dd9-386c-4fde-962d-59d4e2643f2c&page=queryresults
[0m09:26:28.221819 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.56s]
[0m09:26:28.222495 [info ] [MainThread]: 
[0m09:26:28.223721 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:26:28.224501 [info ] [MainThread]: 
[0m09:26:28.228258 [debug] [Thread-1  ]: Began running node model.creditrisk.history_defaults
[0m09:26:28.229621 [info ] [Thread-1  ]: 1 of 5 START sql view model oscreditrisk.history_defaults ...................... [RUN]
[0m09:26:28.230416 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.history_defaults)
[0m09:26:28.231148 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_defaults
[0m09:26:28.236904 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_defaults"
[0m09:26:28.238552 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_defaults
[0m09:26:28.282146 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_defaults"
[0m09:26:28.283242 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:26:28.283950 [debug] [Thread-1  ]: On model.creditrisk.history_defaults: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_defaults"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
  OPTIONS()
  as /*
    This transformations creates a dataset containing one line per account and contains the information if the account has defaulted or not. 
*/

WITH history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

detect_defaults as (
    SELECT 
        account_id,
        registration_date,
        perc_paid,
        CASE 
            WHEN reporting_date_status in ('UNLOCKED') THEN 0
            WHEN reporting_date_status in ('DETACHED', 'WRITTEN_OFF') THEN 1
            WHEN days_disabled >= 180 THEN 1
            ELSE 0
        END as has_defaulted,
    FROM history
)

SELECT * FROM detect_defaults;


[0m09:26:30.045921 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:581ec582-5884-4d06-b4c6-1b6dd956a2fb&page=queryresults
[0m09:26:31.304471 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce43e1a6d0>]}
[0m09:26:31.305635 [info ] [Thread-1  ]: 1 of 5 OK created sql view model oscreditrisk.history_defaults ................. [[32mCREATE VIEW (0 processed)[0m in 3.07s]
[0m09:26:31.306549 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_defaults
[0m09:26:31.307205 [debug] [Thread-1  ]: Began running node model.creditrisk.history_segmentations
[0m09:26:31.307832 [info ] [Thread-1  ]: 2 of 5 START sql view model oscreditrisk.history_segmentations ................. [RUN]
[0m09:26:31.308632 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_defaults, now model.creditrisk.history_segmentations)
[0m09:26:31.309166 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_segmentations
[0m09:26:31.313466 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_segmentations"
[0m09:26:31.314688 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_segmentations
[0m09:26:31.318734 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_segmentations"
[0m09:26:31.320177 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:26:31.321119 [debug] [Thread-1  ]: On model.creditrisk.history_segmentations: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_segmentations"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_segmentations`
  OPTIONS()
  as WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

segmentation_at_0 as (
  SELECT 
    account_id,
    0 as perc_paid_current,
    '0. At registration' as account_segmentation,
  FROM accounts_history
  WHERE reporting_day = 1
),

segmentation_at_10 as (
  SELECT 
    account_id,
    0.1 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.1
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_20 as (
  SELECT 
    account_id,
    0.2 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.2
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_30 as (
  SELECT 
    account_id,
    0.3 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.3
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_40 as (
  SELECT 
    account_id,
    0.4 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.4
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_50 as (
  SELECT 
    account_id,
    0.5 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.5
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_60 as (
  SELECT 
    account_id,
    0.6 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.6
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_70 as (
  SELECT 
    account_id,
    0.7 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.7
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_80 as (
  SELECT 
    account_id,
    0.8 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.8
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_90 as (
  SELECT 
    account_id,
    0.9 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.9
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
)

SELECT * FROM segmentation_at_0
UNION ALL
SELECT * FROM segmentation_at_10
UNION ALL
SELECT * FROM segmentation_at_20
UNION ALL
SELECT * FROM segmentation_at_30
UNION ALL
SELECT * FROM segmentation_at_40
UNION ALL
SELECT * FROM segmentation_at_50
UNION ALL
SELECT * FROM segmentation_at_60
UNION ALL
SELECT * FROM segmentation_at_70
UNION ALL
SELECT * FROM segmentation_at_80
UNION ALL
SELECT * FROM segmentation_at_90;


[0m09:26:33.000529 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:9aaf6b04-df22-4e81-bfdf-1a947912ed42&page=queryresults
[0m09:26:34.347471 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce259c4ac0>]}
[0m09:26:34.348602 [info ] [Thread-1  ]: 2 of 5 OK created sql view model oscreditrisk.history_segmentations ............ [[32mCREATE VIEW (0 processed)[0m in 3.04s]
[0m09:26:34.349654 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_segmentations
[0m09:26:34.350332 [debug] [Thread-1  ]: Began running node model.creditrisk.compute_samples
[0m09:26:34.351031 [info ] [Thread-1  ]: 3 of 5 START sql view model oscreditrisk.compute_samples ....................... [RUN]
[0m09:26:34.351791 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_segmentations, now model.creditrisk.compute_samples)
[0m09:26:34.352370 [debug] [Thread-1  ]: Began compiling node model.creditrisk.compute_samples
[0m09:26:34.359202 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.compute_samples"
[0m09:26:34.362652 [debug] [Thread-1  ]: Began executing node model.creditrisk.compute_samples
[0m09:26:34.367779 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.compute_samples"
[0m09:26:34.368876 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:26:34.369658 [debug] [Thread-1  ]: On model.creditrisk.compute_samples: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.compute_samples"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`compute_samples`
  OPTIONS()
  as /*
    This transformation is quite essential to produce an unbiaised model
    For every chunk of repayment [0-10%], [10-20%], etc... it estimates what is the sample of accounts we can use for estimating probabilities of default.
    For example, if for 40 - 50% the sample end date is 2020-12-03, it means that we must use only accounts registered prior to this date.
    Otherwise, we are going to produce biaised (selection bias) estimates, as too many accounts will not have finished paying or will not have defaulted.
*/

WITH default_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
),

date_spine as (
    SELECT reporting_date as sample_end_date FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

-- Generates a table containing 10 rows, representing the different chunks of repayment : 0 to 10%, 10 to 20%, etc...
split_chunks as (
    SELECT 
        *,
        index_chunk / 10 as perc_paid_chunk_start,
        COALESCE(
            LEAD(index_chunk / 10) OVER(ORDER BY index_chunk),
            1
        ) as perc_paid_chunk_end,
    FROM UNNEST(GENERATE_ARRAY(0, 9)) as index_chunk
),

crossjoint as (
    SELECT 
        *,
        IF(perc_paid < perc_paid_chunk_end AND has_defaulted = 0, 1, 0) as is_censored,
    FROM default_history
    CROSS JOIN split_chunks
),

grouped as (
    SELECT 
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        sample_end_date,
        AVG(is_censored) as censored_percent,
    FROM crossjoint
    LEFT JOIN date_spine
    ON date_spine.sample_end_date >= crossjoint.registration_date
    GROUP BY ALL
    HAVING censored_percent <= 0.05 -- Here the tolerance to censoring is 5%.
),

get_chunck_dates as (
    SELECT 
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        MAX(sample_end_date) as sample_end_date,
    FROM grouped 
    GROUP BY ALL
)

SELECT * FROM get_chunck_dates;


[0m09:26:36.389366 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:8b1ee2dc-9687-4637-b08b-73cd3f748ce7&page=queryresults
[0m09:26:37.615771 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce259215b0>]}
[0m09:26:37.616868 [info ] [Thread-1  ]: 3 of 5 OK created sql view model oscreditrisk.compute_samples .................. [[32mCREATE VIEW (0 processed)[0m in 3.26s]
[0m09:26:37.617902 [debug] [Thread-1  ]: Finished running node model.creditrisk.compute_samples
[0m09:26:37.619108 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_inputs
[0m09:26:37.619881 [info ] [Thread-1  ]: 4 of 5 START sql view model oscreditrisk.prepare_model_inputs .................. [RUN]
[0m09:26:37.620693 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.compute_samples, now model.creditrisk.prepare_model_inputs)
[0m09:26:37.621301 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_inputs
[0m09:26:37.628554 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_inputs"
[0m09:26:37.629616 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_inputs
[0m09:26:37.635940 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_inputs"
[0m09:26:37.637060 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:26:37.637784 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_inputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_inputs"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
  OPTIONS()
  as WITH accs as (
  SELECT 
    *,
  FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
  LEFT JOIN `steam-outlet-209412`.`oscreditrisk`.`history_segmentations` USING(account_id)
),

samples as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`compute_samples`
),

joint as (
  SELECT 
    accs.*,
    samples.*,
    RAND() as rnd,
  FROM accs
  INNER JOIN samples
  ON 
    accs.registration_date < CAST(samples.sample_end_date AS TIMESTAMP)
)

SELECT * FROM joint;


[0m09:26:39.583581 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:bdf1b67e-6a62-48bd-b75d-550a375c62fb&page=queryresults
[0m09:26:40.815394 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce25a70c10>]}
[0m09:26:40.816538 [info ] [Thread-1  ]: 4 of 5 OK created sql view model oscreditrisk.prepare_model_inputs ............. [[32mCREATE VIEW (0 processed)[0m in 3.19s]
[0m09:26:40.817816 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_inputs
[0m09:26:40.818923 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_outputs
[0m09:26:40.819837 [info ] [Thread-1  ]: 5 of 5 START sql table model oscreditrisk.prepare_model_outputs ................ [RUN]
[0m09:26:40.820696 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.prepare_model_inputs, now model.creditrisk.prepare_model_outputs)
[0m09:26:40.821305 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_outputs
[0m09:26:40.828324 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_outputs"
[0m09:26:40.829468 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_outputs
[0m09:26:40.874833 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_outputs"
[0m09:26:40.876069 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:26:40.876816 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_outputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_outputs"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`
      
    
    

    OPTIONS()
    as (
      

WITH input as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
),

calculated as (
  SELECT 
    perc_paid_chunk,
    account_segmentation,
    sample_end_date, 
    perc_paid_chunk_start,
    perc_paid_chunk_end,
    -- MAX(CAST(perc_paid_bucket as STRING)) as perc_paid_bucket_category,
    COUNT(*) as number_of_accounts,
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1
        WHEN 
            has_defaulted = 0 
            AND perc_paid < perc_paid_chunk_start AND 
            rnd < 0.4
        THEN 1
        ELSE 0
      END
    ) as p_churn_incr,
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1 - perc_paid
        WHEN 
            has_defaulted = 0 AND 
            perc_paid < perc_paid_chunk_end AND 
            rnd < 0.4
        THEN 1 - perc_paid_chunk_start
        ELSE 0
      END
    ) as r_churn_incr,
  FROM input
  GROUP BY ALL
)

SELECT 
    *,

    SUM(p_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_chunk AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as p_churn,

    SUM(r_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_chunk AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as r_churn, 

FROM calculated
    );
  
[0m09:26:42.784355 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:1dfc7638-7708-4ddb-8a98-ac5e7ad82c00&page=queryresults
[0m09:26:43.362984 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: perc_paid_chunk; Did you mean perc_paid_chunk_end? at [21:5]; reason: invalidQuery, location: query, message: Unrecognized name: perc_paid_chunk; Did you mean perc_paid_chunk_end? at [21:5]')
[0m09:26:45.183384 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:574971a5-d670-4666-9b38-7e36779b0c95&page=queryresults
[0m09:26:45.783428 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:574971a5-d670-4666-9b38-7e36779b0c95&page=queryresults
[0m09:26:45.801711 [debug] [Thread-1  ]: Database Error in model prepare_model_outputs (models/4_baobabplus_methodology/4_1_lifetime_ecl_model/prepare_model_outputs.sql)
  Unrecognized name: perc_paid_chunk; Did you mean perc_paid_chunk_end? at [21:5]
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_1_lifetime_ecl_model/prepare_model_outputs.sql
[0m09:26:45.802497 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54c60edf-8017-4bbe-b556-f1527ac9abe0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce259390d0>]}
[0m09:26:45.803434 [error] [Thread-1  ]: 5 of 5 ERROR creating sql table model oscreditrisk.prepare_model_outputs ....... [[31mERROR[0m in 4.98s]
[0m09:26:45.804477 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_outputs
[0m09:26:45.806121 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:26:45.806623 [debug] [MainThread]: Connection 'model.creditrisk.prepare_model_outputs' was properly closed.
[0m09:26:45.807241 [info ] [MainThread]: 
[0m09:26:45.807807 [info ] [MainThread]: Finished running 4 view models, 1 table model, 1 project hook in 0 hours 0 minutes and 27.71 seconds (27.71s).
[0m09:26:45.809973 [debug] [MainThread]: Command end result
[0m09:26:45.863004 [info ] [MainThread]: 
[0m09:26:45.863880 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m09:26:45.864382 [info ] [MainThread]: 
[0m09:26:45.865030 [error] [MainThread]:   Database Error in model prepare_model_outputs (models/4_baobabplus_methodology/4_1_lifetime_ecl_model/prepare_model_outputs.sql)
  Unrecognized name: perc_paid_chunk; Did you mean perc_paid_chunk_end? at [21:5]
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_1_lifetime_ecl_model/prepare_model_outputs.sql
[0m09:26:45.865749 [info ] [MainThread]: 
[0m09:26:45.866289 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m09:26:45.867086 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 32.169945, "process_user_time": 5.205776, "process_kernel_time": 0.959696, "process_mem_max_rss": "229445632", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:26:45.867918 [debug] [MainThread]: Command `dbt run` failed at 09:26:45.867771 after 32.17 seconds
[0m09:26:45.868496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce3d260550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce44646ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce4451f850>]}
[0m09:26:45.869233 [debug] [MainThread]: Flushing usage events
[0m09:27:15.651835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea85b2f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea8816ad90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea8816a3d0>]}


============================== 09:27:15.655766 | 217db13a-e826-4ae1-91c4-a0c26b9f20ee ==============================
[0m09:27:15.655766 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:27:15.656592 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'quiet': 'False', 'profiles_dir': '/Users/david/.dbt', 'invocation_command': 'dbt run --select prepare_model_outputs', 'debug': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'use_experimental_parser': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'no_print': 'None', 'fail_fast': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'log_format': 'default', 'log_cache_events': 'False', 'empty': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'static_parser': 'True', 'printer_width': '80'}
[0m09:27:19.379416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '217db13a-e826-4ae1-91c4-a0c26b9f20ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea85e1f6a0>]}
[0m09:27:19.435793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '217db13a-e826-4ae1-91c4-a0c26b9f20ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea87fffaf0>]}
[0m09:27:19.436503 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:27:19.464459 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:27:19.805698 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:27:19.806161 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:27:19.866130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '217db13a-e826-4ae1-91c4-a0c26b9f20ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea8f17be20>]}
[0m09:27:20.020219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '217db13a-e826-4ae1-91c4-a0c26b9f20ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea8f19a7c0>]}
[0m09:27:20.021112 [info ] [MainThread]: Found 14 models, 3 seeds, 1 operation, 480 macros
[0m09:27:20.021642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '217db13a-e826-4ae1-91c4-a0c26b9f20ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea8f1461c0>]}
[0m09:27:20.023382 [info ] [MainThread]: 
[0m09:27:20.024252 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:27:20.025385 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:27:20.025924 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:27:24.317841 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:27:24.319322 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:27:25.653483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '217db13a-e826-4ae1-91c4-a0c26b9f20ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea873772b0>]}
[0m09:27:25.654333 [info ] [MainThread]: 
[0m09:27:25.654915 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:27:25.672487 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:27:25.679339 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:27:25.680155 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:27:25.680877 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:27:27.137188 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:a44a81eb-6863-41e1-bcfd-f785b8ffeb59&page=queryresults
[0m09:27:28.907682 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.23s]
[0m09:27:28.908461 [info ] [MainThread]: 
[0m09:27:28.909328 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:27:28.909926 [info ] [MainThread]: 
[0m09:27:28.914491 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_outputs
[0m09:27:28.915601 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.prepare_model_outputs ................ [RUN]
[0m09:27:28.916431 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.prepare_model_outputs)
[0m09:27:28.917064 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_outputs
[0m09:27:28.923033 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_outputs"
[0m09:27:28.924202 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_outputs
[0m09:27:28.980347 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_outputs"
[0m09:27:28.981353 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:27:28.982092 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_outputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_outputs"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`
      
    
    

    OPTIONS()
    as (
      

WITH input as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
),

calculated as (
  SELECT 
    perc_paid_current,
    account_segmentation,
    sample_end_date, 
    perc_paid_chunk_start,
    perc_paid_chunk_end,
    -- MAX(CAST(perc_paid_bucket as STRING)) as perc_paid_bucket_category,
    COUNT(*) as number_of_accounts,
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1
        WHEN 
            has_defaulted = 0 
            AND perc_paid < perc_paid_chunk_start AND 
            rnd < 0.4
        THEN 1
        ELSE 0
      END
    ) as p_churn_incr,
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1 - perc_paid
        WHEN 
            has_defaulted = 0 AND 
            perc_paid < perc_paid_chunk_end AND 
            rnd < 0.4
        THEN 1 - perc_paid_chunk_start
        ELSE 0
      END
    ) as r_churn_incr,
  FROM input
  GROUP BY ALL
)

SELECT 
    *,

    SUM(p_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as p_churn,

    SUM(r_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as r_churn, 

FROM calculated
    );
  
[0m09:27:30.767672 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:f18fe306-6d5c-4f29-a484-7b02cb31e05c&page=queryresults
[0m09:27:38.380363 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '217db13a-e826-4ae1-91c4-a0c26b9f20ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea8dbd6730>]}
[0m09:27:38.382427 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.prepare_model_outputs ........... [[32mCREATE TABLE (369.0 rows, 178.1 MiB processed)[0m in 9.46s]
[0m09:27:38.383539 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_outputs
[0m09:27:38.385184 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:27:38.385647 [debug] [MainThread]: Connection 'model.creditrisk.prepare_model_outputs' was properly closed.
[0m09:27:38.386135 [info ] [MainThread]: 
[0m09:27:38.386655 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 18.36 seconds (18.36s).
[0m09:27:38.387668 [debug] [MainThread]: Command end result
[0m09:27:38.436047 [info ] [MainThread]: 
[0m09:27:38.436849 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:27:38.437337 [info ] [MainThread]: 
[0m09:27:38.437914 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:27:38.438751 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 22.859007, "process_user_time": 4.829487, "process_kernel_time": 0.942014, "process_mem_max_rss": "227270656", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:27:38.439555 [debug] [MainThread]: Command `dbt run` succeeded at 09:27:38.439414 after 22.86 seconds
[0m09:27:38.440102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea85b2f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea873772b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea87fffaf0>]}
[0m09:27:38.440630 [debug] [MainThread]: Flushing usage events
[0m09:31:09.751913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9ad361550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9af376280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9af376c10>]}


============================== 09:31:09.757358 | 69157de7-6f44-4032-9006-7b9a8aba9949 ==============================
[0m09:31:09.757358 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:31:09.758552 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'profiles_dir': '/Users/david/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'log_format': 'default', 'version_check': 'True', 'printer_width': '80', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'no_print': 'None', 'partial_parse': 'True', 'warn_error': 'None', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'cache_selected_only': 'False', 'invocation_command': 'dbt run --select prepare_model_outputs', 'fail_fast': 'False', 'use_colors': 'True'}
[0m09:31:13.914063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '69157de7-6f44-4032-9006-7b9a8aba9949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b2d9c880>]}
[0m09:31:13.982214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '69157de7-6f44-4032-9006-7b9a8aba9949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9af1f5e80>]}
[0m09:31:13.983050 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:31:14.020713 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:31:14.322038 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:31:14.322548 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:31:14.399834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '69157de7-6f44-4032-9006-7b9a8aba9949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b40bbdf0>]}
[0m09:31:14.576382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '69157de7-6f44-4032-9006-7b9a8aba9949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b40a4bb0>]}
[0m09:31:14.577089 [info ] [MainThread]: Found 14 models, 3 seeds, 1 operation, 480 macros
[0m09:31:14.577625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69157de7-6f44-4032-9006-7b9a8aba9949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b40c2eb0>]}
[0m09:31:14.579332 [info ] [MainThread]: 
[0m09:31:14.580116 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:31:14.581229 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:31:14.581731 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:31:19.223490 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:31:19.224763 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:31:20.643498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69157de7-6f44-4032-9006-7b9a8aba9949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9ad6627c0>]}
[0m09:31:20.644368 [info ] [MainThread]: 
[0m09:31:20.645070 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:31:20.663334 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:31:20.669887 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:31:20.670749 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:31:20.671523 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:31:22.045451 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:e279f468-1799-41f4-894e-d2e1288c8ee1&page=queryresults
[0m09:31:23.837832 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.17s]
[0m09:31:23.838495 [info ] [MainThread]: 
[0m09:31:23.839228 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:31:23.839762 [info ] [MainThread]: 
[0m09:31:23.843296 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_outputs
[0m09:31:23.844142 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.prepare_model_outputs ................ [RUN]
[0m09:31:23.845146 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.prepare_model_outputs)
[0m09:31:23.845781 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_outputs
[0m09:31:23.850997 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_outputs"
[0m09:31:23.852383 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_outputs
[0m09:31:23.876198 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:31:25.298571 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_outputs"
[0m09:31:25.299704 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_outputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_outputs"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`
      
    
    

    OPTIONS()
    as (
      

WITH input as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
),

calculated as (
  SELECT 
    perc_paid_current,
    account_segmentation,
    sample_end_date, 
    perc_paid_chunk_start,
    perc_paid_chunk_end,
    -- MAX(CAST(perc_paid_bucket as STRING)) as perc_paid_bucket_category,
    COUNT(*) as number_of_accounts,
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1
        WHEN 
            has_defaulted = 0 
            AND perc_paid < perc_paid_chunk_start AND 
            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10)
        THEN 1
        ELSE 0
      END
    ) as p_churn_incr,
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1 - perc_paid
        WHEN 
            has_defaulted = 0 AND 
            perc_paid < perc_paid_chunk_end AND 
            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10)
        THEN 1 - perc_paid_chunk_start
        ELSE 0
      END
    ) as r_churn_incr,
  FROM input
  GROUP BY ALL
)

SELECT 
    *,

    SUM(p_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as p_churn,

    SUM(r_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as r_churn, 

FROM calculated
    );
  
[0m09:31:26.408124 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:50c9b27c-2aee-4002-93f0-689cb51e6d1c&page=queryresults
[0m09:31:38.469873 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69157de7-6f44-4032-9006-7b9a8aba9949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b2cef6d0>]}
[0m09:31:38.471003 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.prepare_model_outputs ........... [[32mCREATE TABLE (369.0 rows, 178.1 MiB processed)[0m in 14.62s]
[0m09:31:38.472055 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_outputs
[0m09:31:38.473664 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:31:38.474237 [debug] [MainThread]: Connection 'model.creditrisk.prepare_model_outputs' was properly closed.
[0m09:31:38.474762 [info ] [MainThread]: 
[0m09:31:38.475304 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 23.89 seconds (23.89s).
[0m09:31:38.476329 [debug] [MainThread]: Command end result
[0m09:31:38.531576 [info ] [MainThread]: 
[0m09:31:38.532410 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:31:38.532945 [info ] [MainThread]: 
[0m09:31:38.533515 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:31:38.534335 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 28.87894, "process_user_time": 5.306325, "process_kernel_time": 0.968322, "process_mem_max_rss": "227753984", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:31:38.535278 [debug] [MainThread]: Command `dbt run` succeeded at 09:31:38.535103 after 28.88 seconds
[0m09:31:38.535974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9ad361550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b35dc4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9af1f5e80>]}
[0m09:31:38.536593 [debug] [MainThread]: Flushing usage events
[0m09:32:46.356676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e24b644f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e28271d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e28271100>]}


============================== 09:32:46.362312 | d1f8b59d-a591-4c12-96bd-c1594cdba367 ==============================
[0m09:32:46.362312 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:32:46.363311 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'indirect_selection': 'eager', 'printer_width': '80', 'cache_selected_only': 'False', 'target_path': 'None', 'write_json': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'debug': 'False', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'empty': 'False', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'profiles_dir': '/Users/david/.dbt', 'log_cache_events': 'False', 'no_print': 'None', 'static_parser': 'True', 'invocation_command': 'dbt run --select prepare_model_outputs'}
[0m09:32:50.468567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd1f8b59d-a591-4c12-96bd-c1594cdba367', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e2bd8b520>]}
[0m09:32:50.538656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd1f8b59d-a591-4c12-96bd-c1594cdba367', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e2cb54100>]}
[0m09:32:50.539518 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:32:50.572250 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:32:50.885457 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:32:50.885980 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:32:50.961567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd1f8b59d-a591-4c12-96bd-c1594cdba367', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e2d175130>]}
[0m09:32:51.133094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1f8b59d-a591-4c12-96bd-c1594cdba367', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e2d14bd90>]}
[0m09:32:51.133820 [info ] [MainThread]: Found 14 models, 3 seeds, 1 operation, 480 macros
[0m09:32:51.134351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1f8b59d-a591-4c12-96bd-c1594cdba367', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e2d1469a0>]}
[0m09:32:51.136161 [info ] [MainThread]: 
[0m09:32:51.137080 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:32:51.138534 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:32:51.139226 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:32:55.167737 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:32:55.169382 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:32:55.913133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1f8b59d-a591-4c12-96bd-c1594cdba367', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e2d14b760>]}
[0m09:32:55.914042 [info ] [MainThread]: 
[0m09:32:55.914649 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:32:55.933088 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:32:55.939590 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:32:55.940356 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:32:55.941331 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:32:56.706051 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:52e2c1af-6541-4933-ab7e-9ff89b74aeb5&page=queryresults
[0m09:32:58.160494 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.22s]
[0m09:32:58.161257 [info ] [MainThread]: 
[0m09:32:58.162107 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:32:58.162712 [info ] [MainThread]: 
[0m09:32:58.166386 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_outputs
[0m09:32:58.168342 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.prepare_model_outputs ................ [RUN]
[0m09:32:58.169504 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.prepare_model_outputs)
[0m09:32:58.170262 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_outputs
[0m09:32:58.176178 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_outputs"
[0m09:32:58.177567 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_outputs
[0m09:32:58.200109 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:32:58.831049 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_outputs"
[0m09:32:58.832182 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_outputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_outputs"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`
      
    
    

    OPTIONS()
    as (
      

WITH input as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
),

calculated as (
  SELECT 
    perc_paid_current,
    account_segmentation,
    sample_end_date, 
    perc_paid_chunk_start,
    perc_paid_chunk_end,
    COUNT(*) as number_of_accounts,
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1
        WHEN 
            has_defaulted = 0 
            AND perc_paid < perc_paid_chunk_start AND 
            -- This formula takes an assumption for future default rates of censored accounts.
            -- Here we consider the account will have 40% chances of defaulting in the remaining repayment
            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10) 
        THEN 1
        ELSE 0
      END
    ) as p_churn_incr, -- p_churn represents the probability of default
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1 - perc_paid
        WHEN 
            has_defaulted = 0 AND 
            perc_paid < perc_paid_chunk_end AND 
            -- This formula takes an assumption for future default rates of censored accounts.
            -- Here we consider the account will have 40% chances of defaulting in the remaining repayment
            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10)
        THEN 1 - perc_paid_chunk_start
        ELSE 0
      END
    ) as r_churn_incr, -- r_churn represents the expected loss in receivable PD * EAD.
  FROM input
  GROUP BY ALL
)

SELECT 
    *,

    SUM(p_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as p_churn,

    SUM(r_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as r_churn, 

FROM calculated
    );
  
[0m09:32:59.595574 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5a5c8a22-b7f5-4256-ae29-8f206f2946eb&page=queryresults
[0m09:33:06.551778 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1f8b59d-a591-4c12-96bd-c1594cdba367', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e2bccc670>]}
[0m09:33:06.555336 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.prepare_model_outputs ........... [[32mCREATE TABLE (369.0 rows, 178.1 MiB processed)[0m in 8.38s]
[0m09:33:06.559342 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_outputs
[0m09:33:06.562613 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:33:06.563890 [debug] [MainThread]: Connection 'model.creditrisk.prepare_model_outputs' was properly closed.
[0m09:33:06.564641 [info ] [MainThread]: 
[0m09:33:06.565523 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 15.43 seconds (15.43s).
[0m09:33:06.567786 [debug] [MainThread]: Command end result
[0m09:33:06.653278 [info ] [MainThread]: 
[0m09:33:06.654445 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:33:06.655126 [info ] [MainThread]: 
[0m09:33:06.656013 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:33:06.657199 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 20.398708, "process_user_time": 5.440919, "process_kernel_time": 0.998228, "process_mem_max_rss": "227905536", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:33:06.658644 [debug] [MainThread]: Command `dbt run` succeeded at 09:33:06.658202 after 20.40 seconds
[0m09:33:06.659740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e24b644f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e2cbc0070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e2cb54100>]}
[0m09:33:06.660772 [debug] [MainThread]: Flushing usage events
[0m09:34:39.978557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd140b32520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd142a71a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd142a71340>]}


============================== 09:34:39.984085 | eefac3dd-473d-49ca-9c93-0ea5f371671a ==============================
[0m09:34:39.984085 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:34:39.985086 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'introspect': 'True', 'log_cache_events': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'fail_fast': 'False', 'debug': 'False', 'version_check': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'printer_width': '80', 'target_path': 'None', 'invocation_command': 'dbt run --select 4_baobabplus_methodology', 'cache_selected_only': 'False', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'partial_parse': 'True', 'profiles_dir': '/Users/david/.dbt', 'use_experimental_parser': 'False', 'empty': 'False', 'write_json': 'True', 'static_parser': 'True', 'log_format': 'default'}
[0m09:34:44.113665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd146bd3a90>]}
[0m09:34:44.262490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd146be17f0>]}
[0m09:34:44.264060 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:34:44.303563 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:34:44.642122 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:34:44.642642 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:34:44.717148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd147875130>]}
[0m09:34:44.913340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd14784d610>]}
[0m09:34:44.914109 [info ] [MainThread]: Found 14 models, 3 seeds, 1 operation, 480 macros
[0m09:34:44.914937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd147864e80>]}
[0m09:34:44.916903 [info ] [MainThread]: 
[0m09:34:44.917898 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:34:44.925698 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:34:44.926590 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:34:50.913847 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:34:50.915096 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:34:51.564452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd14754fd60>]}
[0m09:34:51.565348 [info ] [MainThread]: 
[0m09:34:51.566008 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:34:51.616681 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:34:51.626009 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:34:51.627076 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:34:51.627836 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:34:52.233909 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:0695ebfa-bc80-4797-81f2-1c9e0eeebd6c&page=queryresults
[0m09:34:53.627917 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.00s]
[0m09:34:53.628597 [info ] [MainThread]: 
[0m09:34:53.629373 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:34:53.630021 [info ] [MainThread]: 
[0m09:34:53.634027 [debug] [Thread-1  ]: Began running node model.creditrisk.history_defaults
[0m09:34:53.635071 [info ] [Thread-1  ]: 1 of 5 START sql view model oscreditrisk.history_defaults ...................... [RUN]
[0m09:34:53.635927 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.history_defaults)
[0m09:34:53.636569 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_defaults
[0m09:34:53.642873 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_defaults"
[0m09:34:53.644206 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_defaults
[0m09:34:53.693967 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_defaults"
[0m09:34:53.695031 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:34:53.695751 [debug] [Thread-1  ]: On model.creditrisk.history_defaults: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_defaults"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
  OPTIONS()
  as /*
    This transformations creates a dataset containing one line per account and contains the information if the account has defaulted or not. 
*/

WITH history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

detect_defaults as (
    SELECT 
        account_id,
        registration_date,
        perc_paid,
        CASE 
            WHEN reporting_date_status in ('UNLOCKED') THEN 0
            WHEN reporting_date_status in ('DETACHED', 'WRITTEN_OFF') THEN 1
            WHEN days_disabled >= 180 THEN 1
            ELSE 0
        END as has_defaulted,
    FROM history
)

SELECT * FROM detect_defaults;


[0m09:34:54.432021 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:ac45c668-d9f1-4ed6-93ec-9c5597c378d0&page=queryresults
[0m09:34:55.158957 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd146be16a0>]}
[0m09:34:55.160026 [info ] [Thread-1  ]: 1 of 5 OK created sql view model oscreditrisk.history_defaults ................. [[32mCREATE VIEW (0 processed)[0m in 1.52s]
[0m09:34:55.160986 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_defaults
[0m09:34:55.161692 [debug] [Thread-1  ]: Began running node model.creditrisk.history_segmentations
[0m09:34:55.162396 [info ] [Thread-1  ]: 2 of 5 START sql view model oscreditrisk.history_segmentations ................. [RUN]
[0m09:34:55.163265 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_defaults, now model.creditrisk.history_segmentations)
[0m09:34:55.163833 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_segmentations
[0m09:34:55.168333 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_segmentations"
[0m09:34:55.169524 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_segmentations
[0m09:34:55.175650 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_segmentations"
[0m09:34:55.176818 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:34:55.177679 [debug] [Thread-1  ]: On model.creditrisk.history_segmentations: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_segmentations"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_segmentations`
  OPTIONS()
  as WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

segmentation_at_0 as (
  SELECT 
    account_id,
    0 as perc_paid_current,
    '0. At registration' as account_segmentation,
  FROM accounts_history
  WHERE reporting_day = 1
),

segmentation_at_10 as (
  SELECT 
    account_id,
    0.1 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.1
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_20 as (
  SELECT 
    account_id,
    0.2 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.2
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_30 as (
  SELECT 
    account_id,
    0.3 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.3
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_40 as (
  SELECT 
    account_id,
    0.4 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.4
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_50 as (
  SELECT 
    account_id,
    0.5 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.5
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_60 as (
  SELECT 
    account_id,
    0.6 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.6
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_70 as (
  SELECT 
    account_id,
    0.7 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.7
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_80 as (
  SELECT 
    account_id,
    0.8 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.8
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_90 as (
  SELECT 
    account_id,
    0.9 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.9
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
)

SELECT * FROM segmentation_at_0
UNION ALL
SELECT * FROM segmentation_at_10
UNION ALL
SELECT * FROM segmentation_at_20
UNION ALL
SELECT * FROM segmentation_at_30
UNION ALL
SELECT * FROM segmentation_at_40
UNION ALL
SELECT * FROM segmentation_at_50
UNION ALL
SELECT * FROM segmentation_at_60
UNION ALL
SELECT * FROM segmentation_at_70
UNION ALL
SELECT * FROM segmentation_at_80
UNION ALL
SELECT * FROM segmentation_at_90;


[0m09:34:55.921311 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:7404b61d-9e21-491c-bf88-c4746564b7f9&page=queryresults
[0m09:34:56.648002 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd14787b2b0>]}
[0m09:34:56.649010 [info ] [Thread-1  ]: 2 of 5 OK created sql view model oscreditrisk.history_segmentations ............ [[32mCREATE VIEW (0 processed)[0m in 1.48s]
[0m09:34:56.650040 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_segmentations
[0m09:34:56.650736 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_date_samples
[0m09:34:56.651529 [info ] [Thread-1  ]: 3 of 5 START sql view model oscreditrisk.prepare_date_samples .................. [RUN]
[0m09:34:56.652395 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_segmentations, now model.creditrisk.prepare_date_samples)
[0m09:34:56.652974 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_date_samples
[0m09:34:56.660056 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_date_samples"
[0m09:34:56.661138 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_date_samples
[0m09:34:56.666366 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_date_samples"
[0m09:34:56.667459 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:34:56.668252 [debug] [Thread-1  ]: On model.creditrisk.prepare_date_samples: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_date_samples"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`prepare_date_samples`
  OPTIONS()
  as /*
    This transformation is quite essential to produce an unbiaised model
    For every chunk of repayment [0-10%], [10-20%], etc... it estimates what is the sample of accounts we can use for estimating probabilities of default.
    For example, if for 40 - 50% the sample end date is 2020-12-03, it means that we must use only accounts registered prior to this date.
    Otherwise, we are going to produce biaised (selection bias) estimates, as too many accounts will not have finished paying or will not have defaulted.
*/

WITH default_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
),

date_spine as (
    SELECT reporting_date as sample_end_date FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

-- Generates a table containing 10 rows, representing the different chunks of repayment : 0 to 10%, 10 to 20%, etc...
split_chunks as (
    SELECT 
        *,
        index_chunk / 10 as perc_paid_chunk_start,
        COALESCE(
            LEAD(index_chunk / 10) OVER(ORDER BY index_chunk),
            1
        ) as perc_paid_chunk_end,
    FROM UNNEST(GENERATE_ARRAY(0, 9)) as index_chunk
),

crossjoint as (
    SELECT 
        *,
        IF(perc_paid < perc_paid_chunk_end AND has_defaulted = 0, 1, 0) as is_censored,
    FROM default_history
    CROSS JOIN split_chunks
),

grouped as (
    SELECT 
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        sample_end_date,
        AVG(is_censored) as censored_percent,
    FROM crossjoint
    LEFT JOIN date_spine
    ON date_spine.sample_end_date >= crossjoint.registration_date
    GROUP BY ALL
    HAVING censored_percent <= 0.05 -- Here the tolerance to censoring is 5%.
),

get_chunck_dates as (
    SELECT 
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        MAX(sample_end_date) as sample_end_date,
    FROM grouped 
    GROUP BY ALL
)

SELECT * FROM get_chunck_dates;


[0m09:34:57.636030 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:93225506-aed5-494d-982b-d107ef1131d8&page=queryresults
[0m09:34:58.237253 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1474c09a0>]}
[0m09:34:58.238218 [info ] [Thread-1  ]: 3 of 5 OK created sql view model oscreditrisk.prepare_date_samples ............. [[32mCREATE VIEW (0 processed)[0m in 1.58s]
[0m09:34:58.239211 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_date_samples
[0m09:34:58.240677 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_inputs
[0m09:34:58.241537 [info ] [Thread-1  ]: 4 of 5 START sql view model oscreditrisk.prepare_model_inputs .................. [RUN]
[0m09:34:58.242257 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.prepare_date_samples, now model.creditrisk.prepare_model_inputs)
[0m09:34:58.242821 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_inputs
[0m09:34:58.250165 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_inputs"
[0m09:34:58.251248 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_inputs
[0m09:34:58.257976 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_inputs"
[0m09:34:58.259165 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:34:58.259935 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_inputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_inputs"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
  OPTIONS()
  as WITH accs as (
  SELECT 
    *,
  FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
  LEFT JOIN `steam-outlet-209412`.`oscreditrisk`.`history_segmentations` USING(account_id)
),

samples as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_date_samples`
),

joint as (
  SELECT 
    accs.*,
    samples.*,
    RAND() as rnd,
  FROM accs
  INNER JOIN samples
  ON 
    accs.registration_date < CAST(samples.sample_end_date AS TIMESTAMP)
)

SELECT * FROM joint;


[0m09:34:59.237917 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:90eb7c7d-9220-4664-9e24-891dbe027342&page=queryresults
[0m09:34:59.828868 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1474c09a0>]}
[0m09:34:59.830069 [info ] [Thread-1  ]: 4 of 5 OK created sql view model oscreditrisk.prepare_model_inputs ............. [[32mCREATE VIEW (0 processed)[0m in 1.59s]
[0m09:34:59.831251 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_inputs
[0m09:34:59.832588 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_outputs
[0m09:34:59.833493 [info ] [Thread-1  ]: 5 of 5 START sql table model oscreditrisk.prepare_model_outputs ................ [RUN]
[0m09:34:59.834338 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.prepare_model_inputs, now model.creditrisk.prepare_model_outputs)
[0m09:34:59.834974 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_outputs
[0m09:34:59.841952 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_outputs"
[0m09:34:59.843050 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_outputs
[0m09:34:59.859719 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:35:00.508568 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_outputs"
[0m09:35:00.509828 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_outputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_outputs"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`
      
    
    

    OPTIONS()
    as (
      

WITH input as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
),

calculated as (
  SELECT 
    perc_paid_current,
    account_segmentation,
    sample_end_date, 
    perc_paid_chunk_start,
    perc_paid_chunk_end,
    COUNT(*) as number_of_accounts,
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1
        WHEN 
            has_defaulted = 0 
            AND perc_paid < perc_paid_chunk_start AND 
            -- This formula takes an assumption for future default rates of censored accounts.
            -- Here we consider the account will have 40% chances of defaulting in the remaining repayment
            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10) 
        THEN 1
        ELSE 0
      END
    ) as p_churn_incr, -- p_churn represents the probability of default
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1 - perc_paid
        WHEN 
            has_defaulted = 0 AND 
            perc_paid < perc_paid_chunk_end AND 
            -- This formula takes an assumption for future default rates of censored accounts.
            -- Here we consider the account will have 40% chances of defaulting in the remaining repayment
            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10)
        THEN 1 - perc_paid_chunk_start
        ELSE 0
      END
    ) as r_churn_incr, -- r_churn represents the expected loss in receivable PD * EAD.
  FROM input
  GROUP BY ALL
)

SELECT 
    *,

    SUM(p_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as p_churn,

    SUM(r_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as r_churn, 

FROM calculated
    );
  
[0m09:35:01.183395 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:1136a2a8-a635-4438-9f71-12fc031061a6&page=queryresults
[0m09:35:09.085448 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eefac3dd-473d-49ca-9c93-0ea5f371671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd148404fd0>]}
[0m09:35:09.086555 [info ] [Thread-1  ]: 5 of 5 OK created sql table model oscreditrisk.prepare_model_outputs ........... [[32mCREATE TABLE (369.0 rows, 178.1 MiB processed)[0m in 9.25s]
[0m09:35:09.087675 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_outputs
[0m09:35:09.089221 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:35:09.089768 [debug] [MainThread]: Connection 'model.creditrisk.prepare_model_outputs' was properly closed.
[0m09:35:09.090374 [info ] [MainThread]: 
[0m09:35:09.091061 [info ] [MainThread]: Finished running 4 view models, 1 table model, 1 project hook in 0 hours 0 minutes and 24.17 seconds (24.17s).
[0m09:35:09.093149 [debug] [MainThread]: Command end result
[0m09:35:09.147904 [info ] [MainThread]: 
[0m09:35:09.148694 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:35:09.149440 [info ] [MainThread]: 
[0m09:35:09.150024 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m09:35:09.150851 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 29.264833, "process_user_time": 5.515186, "process_kernel_time": 1.094832, "process_mem_max_rss": "229146624", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:35:09.151790 [debug] [MainThread]: Command `dbt run` succeeded at 09:35:09.151637 after 29.27 seconds
[0m09:35:09.152377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd140b32520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1428f5af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd147448190>]}
[0m09:35:09.152918 [debug] [MainThread]: Flushing usage events
[0m09:49:21.006582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c1b60550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c3a6f280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c3a6fc10>]}


============================== 09:49:21.011774 | 55d70574-bc5c-4f05-91a7-044ec6cf4805 ==============================
[0m09:49:21.011774 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:49:21.012885 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'introspect': 'True', 'version_check': 'True', 'empty': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'profiles_dir': '/Users/david/.dbt', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'use_experimental_parser': 'False', 'printer_width': '80', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select accounts_history_advanced', 'target_path': 'None', 'write_json': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True'}
[0m09:49:25.034342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '55d70574-bc5c-4f05-91a7-044ec6cf4805', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c7ccea90>]}
[0m09:49:25.092437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '55d70574-bc5c-4f05-91a7-044ec6cf4805', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c849c250>]}
[0m09:49:25.093156 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:49:25.122557 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:49:25.422286 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:49:25.422797 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:49:25.489247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '55d70574-bc5c-4f05-91a7-044ec6cf4805', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c8879f40>]}
[0m09:49:25.671953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '55d70574-bc5c-4f05-91a7-044ec6cf4805', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c889b8b0>]}
[0m09:49:25.672655 [info ] [MainThread]: Found 15 models, 3 seeds, 1 operation, 480 macros
[0m09:49:25.673159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '55d70574-bc5c-4f05-91a7-044ec6cf4805', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c8841a00>]}
[0m09:49:25.674917 [info ] [MainThread]: 
[0m09:49:25.675684 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:49:25.676732 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:49:25.677283 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:49:29.494554 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:49:29.496109 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:49:30.129148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '55d70574-bc5c-4f05-91a7-044ec6cf4805', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c3a37e20>]}
[0m09:49:30.130064 [info ] [MainThread]: 
[0m09:49:30.130676 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:49:30.152014 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:49:30.226697 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:49:30.227525 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:49:30.228265 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:49:30.946942 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b9f85ad8-d40a-491f-bf8c-fc154e8db899&page=queryresults
[0m09:49:32.088452 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 1.86s]
[0m09:49:32.089229 [info ] [MainThread]: 
[0m09:49:32.090097 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:49:32.090707 [info ] [MainThread]: 
[0m09:49:32.095657 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m09:49:32.096540 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m09:49:32.097269 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m09:49:32.097880 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m09:49:32.104019 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m09:49:32.106098 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m09:49:32.129377 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:49:32.828905 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m09:49:32.830346 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            paid_total < unlock_price AND amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN paid_total >= unlock_price THEN Null
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
    paid_total_excl_dp / unlock_price_excl_dp as perc_paid,
  FROM join_wo_statuses
),

usage_rates as (
    SELECT 
        *,
        AVG(
            IF(reporting_date_status in ('ENABLED', 'UNLOCKED'), 1, 0)
        ) OVER(
            PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN 180 PRECEDING AND CURRENT ROW
        ) as usage_rate_last_180d,
    FROM final_kpis
),

segmentations as (
    SELECT 
        *,
        CASE 
            WHEN usage_rate_last_180d >= 0.95 THEN 'A'
            WHEN usage_rate_last_180d >= 0.90 THEN 'B'
            WHEN usage_rate_last_180d >= 0.60 THEN 'C'
            WHEN usage_rate_last_180d < 0.60  THEN 'D'
        END as account_segmentation,
    FROM usage_rates
)

SELECT * FROM segmentations
    );
  
[0m09:49:33.625749 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:d8cf2ecc-4a5b-4120-bf34-ddaddc8ad218&page=queryresults
[0m09:49:49.560423 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55d70574-bc5c-4f05-91a7-044ec6cf4805', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c7cda6d0>]}
[0m09:49:49.561358 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 511.5 MiB processed)[0m in 17.46s]
[0m09:49:49.562260 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m09:49:49.563772 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:49:49.564221 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m09:49:49.564682 [info ] [MainThread]: 
[0m09:49:49.565173 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 23.89 seconds (23.89s).
[0m09:49:49.566105 [debug] [MainThread]: Command end result
[0m09:49:49.615016 [info ] [MainThread]: 
[0m09:49:49.615790 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:49:49.616332 [info ] [MainThread]: 
[0m09:49:49.616971 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:49:49.617829 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 28.71773, "process_user_time": 5.315807, "process_kernel_time": 0.966532, "process_mem_max_rss": "227840000", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:49:49.618699 [debug] [MainThread]: Command `dbt run` succeeded at 09:49:49.618523 after 28.72 seconds
[0m09:49:49.619272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c1b60550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c84b5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7c1e70d90>]}
[0m09:49:49.619806 [debug] [MainThread]: Flushing usage events
[0m09:58:16.602452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e67b644f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e6a2b0d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e6a2b0100>]}


============================== 09:58:16.607214 | cf9f7b94-cd0f-4dc6-9de7-8d34ed8ea789 ==============================
[0m09:58:16.607214 [info ] [MainThread]: Running with dbt=1.8.8
[0m09:58:16.608192 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'target_path': 'None', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'invocation_command': 'dbt run --select history_disablements', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'introspect': 'True', 'write_json': 'True', 'warn_error': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'static_parser': 'True', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'version_check': 'True', 'empty': 'False', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/david/.dbt'}
[0m09:58:19.915447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cf9f7b94-cd0f-4dc6-9de7-8d34ed8ea789', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e6dda3520>]}
[0m09:58:19.971584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cf9f7b94-cd0f-4dc6-9de7-8d34ed8ea789', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e6e4558b0>]}
[0m09:58:19.972290 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:58:19.996575 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m09:58:20.283280 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:58:20.283785 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:58:20.345289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cf9f7b94-cd0f-4dc6-9de7-8d34ed8ea789', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e6e87a130>]}
[0m09:58:20.504644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cf9f7b94-cd0f-4dc6-9de7-8d34ed8ea789', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e6e89f490>]}
[0m09:58:20.505436 [info ] [MainThread]: Found 16 models, 3 seeds, 1 operation, 480 macros
[0m09:58:20.505991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf9f7b94-cd0f-4dc6-9de7-8d34ed8ea789', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e6e463940>]}
[0m09:58:20.507848 [info ] [MainThread]: 
[0m09:58:20.508686 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:58:20.510096 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m09:58:20.510712 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:58:25.909180 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m09:58:25.910592 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:58:27.689740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf9f7b94-cd0f-4dc6-9de7-8d34ed8ea789', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e6e491dc0>]}
[0m09:58:27.690673 [info ] [MainThread]: 
[0m09:58:27.691300 [info ] [MainThread]: Running 1 on-run-start hook
[0m09:58:27.709463 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m09:58:27.716686 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m09:58:27.717474 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:58:27.718201 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m09:58:29.430799 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:f535d7de-21d0-45f6-8aa3-e8fce2c24e18&page=queryresults
[0m09:58:31.389837 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.67s]
[0m09:58:31.390606 [info ] [MainThread]: 
[0m09:58:31.391456 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:58:31.392055 [info ] [MainThread]: 
[0m09:58:31.395978 [debug] [Thread-1  ]: Began running node model.creditrisk.history_disablements
[0m09:58:31.397127 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.history_disablements .................. [RUN]
[0m09:58:31.397895 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.history_disablements)
[0m09:58:31.398512 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_disablements
[0m09:58:31.403396 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_disablements"
[0m09:58:31.404961 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_disablements
[0m09:58:31.449367 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_disablements"
[0m09:58:31.450535 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:58:31.451243 [debug] [Thread-1  ]: On model.creditrisk.history_disablements: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_disablements"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_disablements`
  OPTIONS()
  as WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

get_disablement_periods as (
    SELECT 
        account_id,
        reporting_day,
        reporting_date,
        reporting_date_status,
        LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day) as last_disablement,
        days_disabled,
    FROM accounts_history
),

aggregated_disablement_periods as (
    SELECT 
        account_id,
        reporting_date,
        days_disabled,
    FROM get_disablement_periods
    QUALIFY days_disabled = MAX(days_disabled) OVER(PARTITION BY account_id, last_disablement)
)


SELECT 
    *,
    IF(reporting_date = MAX(reporting_date) OVER(), 1, 0) as censored,
FROM aggregated_disablement_periods;


[0m09:58:33.301462 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:a22bd337-48d3-4803-9077-07c0d23f628d&page=queryresults
[0m09:58:34.669106 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf9f7b94-cd0f-4dc6-9de7-8d34ed8ea789', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e6efba490>]}
[0m09:58:34.670122 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.history_disablements ............. [[32mCREATE VIEW (0 processed)[0m in 3.27s]
[0m09:58:34.671147 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_disablements
[0m09:58:34.672797 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:58:34.673270 [debug] [MainThread]: Connection 'model.creditrisk.history_disablements' was properly closed.
[0m09:58:34.673772 [info ] [MainThread]: 
[0m09:58:34.674465 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 14.17 seconds (14.17s).
[0m09:58:34.675495 [debug] [MainThread]: Command end result
[0m09:58:34.724770 [info ] [MainThread]: 
[0m09:58:34.725518 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:58:34.725994 [info ] [MainThread]: 
[0m09:58:34.726689 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:58:34.727478 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 18.211576, "process_user_time": 5.257613, "process_kernel_time": 0.905651, "process_mem_max_rss": "227213312", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:58:34.728316 [debug] [MainThread]: Command `dbt run` succeeded at 09:58:34.728166 after 18.21 seconds
[0m09:58:34.728901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e67b644f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e69a663d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e67e65220>]}
[0m09:58:34.729443 [debug] [MainThread]: Flushing usage events
[0m10:00:48.469045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba7a5d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbaa37e280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbaa37ec40>]}


============================== 10:00:48.473298 | cdaaed6e-ffb6-491c-9996-67a4244ca08c ==============================
[0m10:00:48.473298 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:00:48.474194 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'quiet': 'False', 'profiles_dir': '/Users/david/.dbt', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'version_check': 'True', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'write_json': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select history_disablements', 'empty': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'log_format': 'default', 'partial_parse': 'True', 'introspect': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False'}
[0m10:00:51.695961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cdaaed6e-ffb6-491c-9996-67a4244ca08c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbae4a6730>]}
[0m10:00:51.754558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cdaaed6e-ffb6-491c-9996-67a4244ca08c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbae41f400>]}
[0m10:00:51.755345 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:00:51.781490 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:00:52.205741 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:00:52.206296 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:00:52.283648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cdaaed6e-ffb6-491c-9996-67a4244ca08c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbae77b130>]}
[0m10:00:52.460516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cdaaed6e-ffb6-491c-9996-67a4244ca08c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbae781730>]}
[0m10:00:52.461361 [info ] [MainThread]: Found 16 models, 3 seeds, 1 operation, 480 macros
[0m10:00:52.461934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cdaaed6e-ffb6-491c-9996-67a4244ca08c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba7dc3250>]}
[0m10:00:52.463758 [info ] [MainThread]: 
[0m10:00:52.464791 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:00:52.466291 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m10:00:52.467194 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:00:55.626414 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m10:00:55.627402 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:00:57.055862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cdaaed6e-ffb6-491c-9996-67a4244ca08c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbae4b5910>]}
[0m10:00:57.056791 [info ] [MainThread]: 
[0m10:00:57.057457 [info ] [MainThread]: Running 1 on-run-start hook
[0m10:00:57.075563 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m10:00:57.082877 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m10:00:57.083934 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:00:57.084672 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m10:00:58.483495 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:a6b0c45c-d838-4d7b-931e-93b16466763d&page=queryresults
[0m10:01:00.175996 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.09s]
[0m10:01:00.176796 [info ] [MainThread]: 
[0m10:01:00.177757 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:01:00.178366 [info ] [MainThread]: 
[0m10:01:00.181250 [debug] [Thread-1  ]: Began running node model.creditrisk.history_disablements
[0m10:01:00.182098 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.history_disablements .................. [RUN]
[0m10:01:00.183080 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.history_disablements)
[0m10:01:00.183727 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_disablements
[0m10:01:00.188680 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_disablements"
[0m10:01:00.189890 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_disablements
[0m10:01:00.233574 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_disablements"
[0m10:01:00.234610 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:01:00.235321 [debug] [Thread-1  ]: On model.creditrisk.history_disablements: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_disablements"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_disablements`
  OPTIONS()
  as /*
    This transformation prepares a dataset in the right format for a survival analysis.
    The target dataset contains one line per disablement period. 
    Duration represents the duration of the period. Event represents the fact that there was a payment interrupting the period. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

get_disablement_periods as (
    SELECT 
        account_id,
        reporting_date,
        perc_paid,
        LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day) as last_disablement,
        days_disabled,
    FROM accounts_history
),

aggregated_disablement_periods as (
    SELECT 
        account_id,
        reporting_date,
        perc_paid,
        days_disabled as duration,
    FROM get_disablement_periods
    QUALIFY days_disabled = MAX(days_disabled) OVER(PARTITION BY account_id, last_disablement)
)


SELECT 
    *,
    IF(reporting_date = MAX(reporting_date) OVER(), 0, 1) as event,
FROM aggregated_disablement_periods;


[0m10:01:01.745341 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:6c4bd9ae-3612-4015-97f4-c7a8289484f9&page=queryresults
[0m10:01:02.893247 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdaaed6e-ffb6-491c-9996-67a4244ca08c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbadcd6760>]}
[0m10:01:02.894291 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.history_disablements ............. [[32mCREATE VIEW (0 processed)[0m in 2.71s]
[0m10:01:02.895420 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_disablements
[0m10:01:02.897099 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:01:02.897624 [debug] [MainThread]: Connection 'model.creditrisk.history_disablements' was properly closed.
[0m10:01:02.898155 [info ] [MainThread]: 
[0m10:01:02.898679 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 10.43 seconds (10.43s).
[0m10:01:02.899826 [debug] [MainThread]: Command end result
[0m10:01:02.948882 [info ] [MainThread]: 
[0m10:01:02.949629 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:01:02.950147 [info ] [MainThread]: 
[0m10:01:02.950897 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:01:02.951706 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 14.566256, "process_user_time": 5.181001, "process_kernel_time": 0.796086, "process_mem_max_rss": "226942976", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:01:02.952615 [debug] [MainThread]: Command `dbt run` succeeded at 10:01:02.952448 after 14.57 seconds
[0m10:01:02.953211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba7a5d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbae744760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdbae41f400>]}
[0m10:01:02.953777 [debug] [MainThread]: Flushing usage events
[0m10:01:18.381189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb65ca5d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb65ea72d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb65ea723d0>]}


============================== 10:01:18.384961 | 0c1d0839-ad1e-4dde-816f-48b6d370255e ==============================
[0m10:01:18.384961 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:01:18.385761 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'partial_parse': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'static_parser': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'no_print': 'None', 'debug': 'False', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'empty': 'False', 'profiles_dir': '/Users/david/.dbt', 'fail_fast': 'False', 'invocation_command': 'dbt run --select probability of repaying'}
[0m10:01:21.782285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0c1d0839-ad1e-4dde-816f-48b6d370255e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb65a4e5df0>]}
[0m10:01:21.844090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0c1d0839-ad1e-4dde-816f-48b6d370255e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb65e907b50>]}
[0m10:01:21.845018 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:01:21.872045 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:01:22.184013 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:01:22.184567 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:01:22.268819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0c1d0839-ad1e-4dde-816f-48b6d370255e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb66387b130>]}
[0m10:01:22.439331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0c1d0839-ad1e-4dde-816f-48b6d370255e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb663864880>]}
[0m10:01:22.440064 [info ] [MainThread]: Found 16 models, 3 seeds, 1 operation, 480 macros
[0m10:01:22.440562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0c1d0839-ad1e-4dde-816f-48b6d370255e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb662e1f310>]}
[0m10:01:22.441444 [warn ] [MainThread]: The selection criterion 'probability' does not match any enabled nodes
[0m10:01:22.442063 [warn ] [MainThread]: The selection criterion 'of' does not match any enabled nodes
[0m10:01:22.442737 [warn ] [MainThread]: The selection criterion 'repaying' does not match any enabled nodes
[0m10:01:22.443907 [info ] [MainThread]: 
[0m10:01:22.444416 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:01:22.446713 [debug] [MainThread]: Command end result
[0m10:01:22.485939 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.180314, "process_user_time": 4.870859, "process_kernel_time": 0.748952, "process_mem_max_rss": "219574272", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:01:22.486713 [debug] [MainThread]: Command `dbt run` succeeded at 10:01:22.486588 after 4.18 seconds
[0m10:01:22.487376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb65ca5d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb662d0b250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb65e907b50>]}
[0m10:01:22.487862 [debug] [MainThread]: Flushing usage events
[0m10:02:45.852316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad1b60550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad3b7d280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad3b7dc10>]}


============================== 10:02:45.857306 | 04852d89-59a3-4137-9412-95d2282a8bc3 ==============================
[0m10:02:45.857306 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:02:45.858356 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run --select probability_of_repaying', 'target_path': 'None', 'use_colors': 'True', 'empty': 'False', 'version_check': 'True', 'static_parser': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'quiet': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'debug': 'False', 'printer_width': '80', 'introspect': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'partial_parse': 'True', 'no_print': 'None', 'profiles_dir': '/Users/david/.dbt', 'log_format': 'default', 'cache_selected_only': 'False'}
[0m10:02:49.563001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04852d89-59a3-4137-9412-95d2282a8bc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad7d8e880>]}
[0m10:02:49.618148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04852d89-59a3-4137-9412-95d2282a8bc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad84bf070>]}
[0m10:02:49.618881 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:02:49.644876 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:02:49.938806 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:02:49.939243 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:02:50.000716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04852d89-59a3-4137-9412-95d2282a8bc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad887b130>]}
[0m10:02:50.153434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04852d89-59a3-4137-9412-95d2282a8bc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad889e5e0>]}
[0m10:02:50.154346 [info ] [MainThread]: Found 16 models, 3 seeds, 1 operation, 480 macros
[0m10:02:50.154898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04852d89-59a3-4137-9412-95d2282a8bc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad88a50a0>]}
[0m10:02:50.156988 [info ] [MainThread]: 
[0m10:02:50.157905 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:02:50.159028 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m10:02:50.159626 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:02:53.904123 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m10:02:53.906116 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:02:55.488330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04852d89-59a3-4137-9412-95d2282a8bc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad3b3ee20>]}
[0m10:02:55.489229 [info ] [MainThread]: 
[0m10:02:55.489839 [info ] [MainThread]: Running 1 on-run-start hook
[0m10:02:55.510758 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m10:02:55.518491 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m10:02:55.519611 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:02:55.520437 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m10:02:57.116222 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:5c1249c3-bcee-4555-ab8c-69a18255620b&page=queryresults
[0m10:02:59.078615 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.56s]
[0m10:02:59.079290 [info ] [MainThread]: 
[0m10:02:59.080108 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:02:59.080660 [info ] [MainThread]: 
[0m10:02:59.084699 [debug] [Thread-1  ]: Began running node model.creditrisk.probability_of_repaying
[0m10:02:59.085910 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.probability_of_repaying ............... [RUN]
[0m10:02:59.086811 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.probability_of_repaying)
[0m10:02:59.087465 [debug] [Thread-1  ]: Began compiling node model.creditrisk.probability_of_repaying
[0m10:02:59.092791 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.probability_of_repaying"
[0m10:02:59.093869 [debug] [Thread-1  ]: Began executing node model.creditrisk.probability_of_repaying
[0m10:02:59.146046 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.probability_of_repaying"
[0m10:02:59.147499 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:02:59.148556 [debug] [Thread-1  ]: On model.creditrisk.probability_of_repaying: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.probability_of_repaying"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`probability_of_repaying`
  OPTIONS()
  as WITH reactivation_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_disablements`
),

-- Split by perc paid bucket and take only last 3 years events observed
reactivation_history_filtered as (
    SELECT 
        *, 
        CASE 
            WHEN perc_paid <= 0.1 THEN '0'
            WHEN perc_paid <= 0.5 THEN '0.1'
            WHEN perc_paid <= 1 THEN '0.5'
            ELSE '0.5'
        END as perc_paid_bucket_start,
            CASE 
            WHEN perc_paid <= 0.1 THEN '0.1'
            WHEN perc_paid <= 0.5 THEN '0.5'
            WHEN perc_paid <= 1 THEN '1'
            ELSE '1'
        END as perc_paid_bucket_end
    FROM reactivation_history
),

cnt_subjects as (
  SELECT 
    perc_paid_bucket_start, 
    perc_paid_bucket_end, 
    COUNT(*) as num_subjects 
  FROM reactivation_history_filtered
  GROUP BY ALL 
),

daily as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end,
    duration,
    COUNT(*) as num_obs,
    SUM(event) as num_events
  FROM reactivation_history_filtered
  GROUP BY ALL ORDER BY 1, 2, 3
),

at_risk_table as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end,
    duration, 
    num_obs,
    num_events,
    num_subjects - COALESCE(SUM(num_obs) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end
      ORDER BY duration ASC ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING), 0)
     as at_risk
  FROM daily
  LEFT JOIN cnt_subjects USING(perc_paid_bucket_start, perc_paid_bucket_end)
),

survival_proba_table as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end, 
    duration, 
    at_risk,
    num_obs,
    num_events,
    at_risk - num_events - COALESCE(LEAD(at_risk, 1) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC), 0) as censored,
    EXP(SUM(SAFE.LN(1 - num_events / at_risk)) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC ROWS BETWEEN UNBOUNDED PRECEDING AND current ROW)) as survival_proba
  FROM at_risk_table
),

get_density_proba as (
  SELECT  
    survival_proba_table.*,
    1 - survival_proba as prob_cum,
    (1 - survival_proba) - COALESCE(1 - LAG(survival_proba) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC), 0) as prob_dens,
    ROW_NUMBER() OVER (PARTITION BY perc_paid_bucket_end ORDER BY duration ASC) as row_num
  FROM survival_proba_table
)

SELECT 
    * EXCEPT(duration, perc_paid_bucket_start, perc_paid_bucket_end),
    CAST(perc_paid_bucket_start AS FLOAT64) as perc_paid_bucket_start,
    CAST(perc_paid_bucket_end AS FLOAT64) as perc_paid_bucket_end,
    duration as days_since_cutoff 
FROM get_density_proba
ORDER BY perc_paid_bucket_start, duration;


[0m10:03:01.160497 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:d6b37c89-a599-49e3-8400-46fffa72ad50&page=queryresults
[0m10:03:02.564902 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04852d89-59a3-4137-9412-95d2282a8bc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad7ce16d0>]}
[0m10:03:02.565865 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.probability_of_repaying .......... [[32mCREATE VIEW (0 processed)[0m in 3.48s]
[0m10:03:02.566835 [debug] [Thread-1  ]: Finished running node model.creditrisk.probability_of_repaying
[0m10:03:02.568504 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:03:02.568970 [debug] [MainThread]: Connection 'model.creditrisk.probability_of_repaying' was properly closed.
[0m10:03:02.569526 [info ] [MainThread]: 
[0m10:03:02.570067 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 12.41 seconds (12.41s).
[0m10:03:02.571062 [debug] [MainThread]: Command end result
[0m10:03:02.620981 [info ] [MainThread]: 
[0m10:03:02.621784 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:03:02.622329 [info ] [MainThread]: 
[0m10:03:02.623327 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:03:02.624308 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 16.857765, "process_user_time": 4.962745, "process_kernel_time": 0.917115, "process_mem_max_rss": "227647488", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:03:02.625333 [debug] [MainThread]: Command `dbt run` succeeded at 10:03:02.625163 after 16.86 seconds
[0m10:03:02.625979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad1b60550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad1e35550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ad3340910>]}
[0m10:03:02.626549 [debug] [MainThread]: Flushing usage events
[0m10:13:02.205804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd632b2f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6363b0d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6363b03d0>]}


============================== 10:13:02.210532 | 1506d223-4080-4dc9-b86f-1a9f2afe2d41 ==============================
[0m10:13:02.210532 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:13:02.211583 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/Users/david/.dbt', 'fail_fast': 'False', 'empty': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'introspect': 'True', 'partial_parse': 'True', 'quiet': 'False', 'log_format': 'default', 'indirect_selection': 'eager', 'warn_error': 'None', 'target_path': 'None', 'static_parser': 'True', 'use_colors': 'True', 'debug': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt run --select probability_calculation_survival'}
[0m10:13:05.879526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1506d223-4080-4dc9-b86f-1a9f2afe2d41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd639dbeeb0>]}
[0m10:13:05.969426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1506d223-4080-4dc9-b86f-1a9f2afe2d41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd63a3f69a0>]}
[0m10:13:05.970467 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:13:06.005701 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:13:06.357889 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:13:06.358497 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:13:06.449910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1506d223-4080-4dc9-b86f-1a9f2afe2d41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd63b17e130>]}
[0m10:13:06.671705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1506d223-4080-4dc9-b86f-1a9f2afe2d41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd63b19d8e0>]}
[0m10:13:06.672539 [info ] [MainThread]: Found 17 models, 3 seeds, 1 operation, 480 macros
[0m10:13:06.673147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1506d223-4080-4dc9-b86f-1a9f2afe2d41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd63b14fb50>]}
[0m10:13:06.675195 [info ] [MainThread]: 
[0m10:13:06.676180 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:13:06.677554 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m10:13:06.678225 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:13:10.775619 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m10:13:10.776691 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:13:11.407541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1506d223-4080-4dc9-b86f-1a9f2afe2d41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd632abfbe0>]}
[0m10:13:11.408512 [info ] [MainThread]: 
[0m10:13:11.409155 [info ] [MainThread]: Running 1 on-run-start hook
[0m10:13:11.429109 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m10:13:11.439217 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m10:13:11.440171 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:13:11.440996 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m10:13:12.076034 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:577c2424-b576-4bb3-a4bb-44d9c9ee70d9&page=queryresults
[0m10:13:13.650700 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.21s]
[0m10:13:13.651482 [info ] [MainThread]: 
[0m10:13:13.652328 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:13:13.652896 [info ] [MainThread]: 
[0m10:13:13.658019 [debug] [Thread-1  ]: Began running node model.creditrisk.probability_calculation_survival
[0m10:13:13.659065 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.probability_calculation_survival ...... [RUN]
[0m10:13:13.659903 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.probability_calculation_survival)
[0m10:13:13.660589 [debug] [Thread-1  ]: Began compiling node model.creditrisk.probability_calculation_survival
[0m10:13:13.666895 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.probability_calculation_survival"
[0m10:13:13.668089 [debug] [Thread-1  ]: Began executing node model.creditrisk.probability_calculation_survival
[0m10:13:13.721870 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.probability_calculation_survival"
[0m10:13:13.723115 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:13:13.724090 [debug] [Thread-1  ]: On model.creditrisk.probability_calculation_survival: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.probability_calculation_survival"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`
  OPTIONS()
  as /*
    This is a SQL implementation of the Kaplan Meier Survival Analysis.
    The output is a survival function. 
*/

WITH reactivation_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_disablements`
),

-- Split by perc paid bucket and take only last 3 years events observed
reactivation_history_filtered as (
    SELECT 
        *, 
        CASE 
            WHEN perc_paid <= 0.1 THEN '0'
            WHEN perc_paid <= 0.5 THEN '0.1'
            WHEN perc_paid <= 1 THEN '0.5'
            ELSE '0.5'
        END as perc_paid_bucket_start,
            CASE 
            WHEN perc_paid <= 0.1 THEN '0.1'
            WHEN perc_paid <= 0.5 THEN '0.5'
            WHEN perc_paid <= 1 THEN '1'
            ELSE '1'
        END as perc_paid_bucket_end
    FROM reactivation_history
),

cnt_subjects as (
  SELECT 
    perc_paid_bucket_start, 
    perc_paid_bucket_end, 
    COUNT(*) as num_subjects 
  FROM reactivation_history_filtered
  GROUP BY ALL 
),

daily as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end,
    duration,
    COUNT(*) as num_obs,
    SUM(event) as num_events
  FROM reactivation_history_filtered
  GROUP BY ALL ORDER BY 1, 2, 3
),

at_risk_table as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end,
    duration, 
    num_obs,
    num_events,
    num_subjects - COALESCE(SUM(num_obs) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end
      ORDER BY duration ASC ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING), 0)
     as at_risk
  FROM daily
  LEFT JOIN cnt_subjects USING(perc_paid_bucket_start, perc_paid_bucket_end)
),

survival_proba_table as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end, 
    duration, 
    at_risk,
    num_obs,
    num_events,
    at_risk - num_events - COALESCE(LEAD(at_risk, 1) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC), 0) as censored,
    EXP(SUM(SAFE.LN(1 - num_events / at_risk)) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC ROWS BETWEEN UNBOUNDED PRECEDING AND current ROW)) as survival_proba
  FROM at_risk_table
),

get_density_proba as (
  SELECT  
    survival_proba_table.*,
    1 - survival_proba as prob_cum,
    (1 - survival_proba) - COALESCE(1 - LAG(survival_proba) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC), 0) as prob_dens,
    ROW_NUMBER() OVER (PARTITION BY perc_paid_bucket_end ORDER BY duration ASC) as row_num
  FROM survival_proba_table
)

SELECT 
    * EXCEPT(duration, perc_paid_bucket_start, perc_paid_bucket_end),
    CAST(perc_paid_bucket_start AS FLOAT64) as perc_paid_bucket_start,
    CAST(perc_paid_bucket_end AS FLOAT64) as perc_paid_bucket_end,
    duration as days_since_cutoff 
FROM get_density_proba
ORDER BY perc_paid_bucket_start, duration;


[0m10:13:14.709171 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:4624bc09-6566-4032-890c-368c7b0fd48f&page=queryresults
[0m10:13:15.414497 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1506d223-4080-4dc9-b86f-1a9f2afe2d41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd639dcc730>]}
[0m10:13:15.415688 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.probability_calculation_survival . [[32mCREATE VIEW (0 processed)[0m in 1.75s]
[0m10:13:15.416901 [debug] [Thread-1  ]: Finished running node model.creditrisk.probability_calculation_survival
[0m10:13:15.418811 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:13:15.419370 [debug] [MainThread]: Connection 'model.creditrisk.probability_calculation_survival' was properly closed.
[0m10:13:15.419945 [info ] [MainThread]: 
[0m10:13:15.420564 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 8.74 seconds (8.74s).
[0m10:13:15.421742 [debug] [MainThread]: Command end result
[0m10:13:15.483222 [info ] [MainThread]: 
[0m10:13:15.484067 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:13:15.484701 [info ] [MainThread]: 
[0m10:13:15.485397 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:13:15.486351 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 13.390934, "process_user_time": 5.759792, "process_kernel_time": 0.906543, "process_mem_max_rss": "226766848", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:13:15.487373 [debug] [MainThread]: Command `dbt run` succeeded at 10:13:15.487200 after 13.39 seconds
[0m10:13:15.488072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd632b2f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd63b95c9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd63a3f69a0>]}
[0m10:13:15.488719 [debug] [MainThread]: Flushing usage events
[0m10:13:51.586606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb40eb32550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb410971b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb410971280>]}


============================== 10:13:51.595777 | c9d22a43-7f34-4bea-90f8-3dd4b96e3eff ==============================
[0m10:13:51.595777 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:13:51.598091 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'empty': 'False', 'fail_fast': 'False', 'introspect': 'True', 'log_format': 'default', 'indirect_selection': 'eager', 'quiet': 'False', 'static_parser': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'use_colors': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'profiles_dir': '/Users/david/.dbt', 'warn_error': 'None', 'partial_parse': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select probability_of_defaulting', 'log_cache_events': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:13:59.560253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c9d22a43-7f34-4bea-90f8-3dd4b96e3eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb415583520>]}
[0m10:13:59.721975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c9d22a43-7f34-4bea-90f8-3dd4b96e3eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb41559c1c0>]}
[0m10:13:59.723728 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:13:59.780899 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:14:00.384228 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:14:00.385464 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:14:00.558008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c9d22a43-7f34-4bea-90f8-3dd4b96e3eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb41587e130>]}
[0m10:14:00.960129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c9d22a43-7f34-4bea-90f8-3dd4b96e3eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb41589d790>]}
[0m10:14:00.961644 [info ] [MainThread]: Found 17 models, 3 seeds, 1 operation, 480 macros
[0m10:14:00.962806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c9d22a43-7f34-4bea-90f8-3dd4b96e3eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb41584fdc0>]}
[0m10:14:00.967460 [info ] [MainThread]: 
[0m10:14:00.969923 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:14:00.972505 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m10:14:00.973807 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:14:05.371591 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m10:14:05.373645 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:14:06.138280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c9d22a43-7f34-4bea-90f8-3dd4b96e3eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb40eac0be0>]}
[0m10:14:06.140116 [info ] [MainThread]: 
[0m10:14:06.141400 [info ] [MainThread]: Running 1 on-run-start hook
[0m10:14:06.182316 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m10:14:06.197832 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m10:14:06.199704 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:14:06.202612 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m10:14:06.883767 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:dd06dc69-de66-4fe3-bb3f-b924b9a7e9d8&page=queryresults
[0m10:14:08.627341 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.43s]
[0m10:14:08.628671 [info ] [MainThread]: 
[0m10:14:08.630211 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:14:08.631295 [info ] [MainThread]: 
[0m10:14:08.637959 [debug] [Thread-1  ]: Began running node model.creditrisk.probability_of_defaulting
[0m10:14:08.640300 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.probability_of_defaulting ............. [RUN]
[0m10:14:08.641902 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.probability_of_defaulting)
[0m10:14:08.643251 [debug] [Thread-1  ]: Began compiling node model.creditrisk.probability_of_defaulting
[0m10:14:08.655325 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.probability_of_defaulting"
[0m10:14:08.657671 [debug] [Thread-1  ]: Began executing node model.creditrisk.probability_of_defaulting
[0m10:14:08.767559 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.probability_of_defaulting"
[0m10:14:08.769878 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:14:08.771548 [debug] [Thread-1  ]: On model.creditrisk.probability_of_defaulting: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.probability_of_defaulting"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`probability_of_defaulting`
  OPTIONS()
  as WITH proba_reactivation as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`
),

repayment as (
  SELECT 
    *,
    1 - prob_cum as survival_func, -- opposite of probability of reactivation
    IF(days_since_cutoff = 360, 1 - prob_cum, null) as survival_func_at_PAR360 -- opposite of probability of reactivation at PAR360
  FROM proba_reactivation
),

get_survival_limit as (
  SELECT 
    scope,
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    MAX(survival_func_at_PAR360)  as survival_limit_at_PAR360,
    MIN(survival_func)            as survival_limit
  FROM repayment
  GROUP BY 1, 2, 3
),

immediate_churn_and_repo_act as (
  SELECT 
    scope,
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    days_since_cutoff,
    survival_limit_at_PAR360,
    survival_limit,
    survival_func,
    -- probability of non-reactivation before PAR360 knowing there is non-reactivation event at time t
    SAFE_DIVIDE(IF(survival_limit_at_PAR360 is null, survival_limit, survival_limit_at_PAR360), survival_func) as immediate_prob_churn,
  FROM repayment
  LEFT JOIN get_survival_limit
    USING(scope, perc_paid_bucket_start, perc_paid_bucket_end) 
),

immediate_churn as (
  SELECT 
    * EXCEPT(immediate_prob_churn),
    IF(days_since_cutoff > 360, 1, immediate_prob_churn) as immediate_prob_churn
  FROM immediate_churn_and_repo_act
)

SELECT * FROM immediate_churn;


[0m10:14:09.766352 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:3475b88e-451b-4ccd-a678-dcb5ed194238&page=queryresults
[0m10:14:10.070925 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: scope at [20:5]; reason: invalidQuery, location: query, message: Unrecognized name: scope at [20:5]')
[0m10:14:11.367494 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:764f9a03-692a-4989-acdc-ee1db065a8d3&page=queryresults
[0m10:14:11.695736 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:764f9a03-692a-4989-acdc-ee1db065a8d3&page=queryresults
[0m10:14:11.727615 [debug] [Thread-1  ]: Database Error in model probability_of_defaulting (models/4_baobabplus_methodology/4_2_late_loans_ecl_model/probability_of_defaulting.sql)
  Unrecognized name: scope at [20:5]
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_2_late_loans_ecl_model/probability_of_defaulting.sql
[0m10:14:11.732813 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c9d22a43-7f34-4bea-90f8-3dd4b96e3eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb40fac2ac0>]}
[0m10:14:11.736786 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.probability_of_defaulting .... [[31mERROR[0m in 3.09s]
[0m10:14:11.743429 [debug] [Thread-1  ]: Finished running node model.creditrisk.probability_of_defaulting
[0m10:14:11.747719 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:14:11.748962 [debug] [MainThread]: Connection 'model.creditrisk.probability_of_defaulting' was properly closed.
[0m10:14:11.750672 [info ] [MainThread]: 
[0m10:14:11.752722 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 10.78 seconds (10.78s).
[0m10:14:11.755998 [debug] [MainThread]: Command end result
[0m10:14:11.903371 [info ] [MainThread]: 
[0m10:14:11.905014 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:14:11.906786 [info ] [MainThread]: 
[0m10:14:11.908785 [error] [MainThread]:   Database Error in model probability_of_defaulting (models/4_baobabplus_methodology/4_2_late_loans_ecl_model/probability_of_defaulting.sql)
  Unrecognized name: scope at [20:5]
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_2_late_loans_ecl_model/probability_of_defaulting.sql
[0m10:14:11.910047 [info ] [MainThread]: 
[0m10:14:11.911822 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:14:11.959187 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 20.565687, "process_user_time": 11.23031, "process_kernel_time": 2.080706, "process_mem_max_rss": "228139008", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:14:12.004071 [debug] [MainThread]: Command `dbt run` failed at 10:14:12.003582 after 20.61 seconds
[0m10:14:12.005814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb40eb32550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4155834f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb410110910>]}
[0m10:14:12.008225 [debug] [MainThread]: Flushing usage events
[0m10:14:39.266717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4c9361520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4cb271d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4cb2710a0>]}


============================== 10:14:39.279348 | d0890fff-1520-4e85-adcf-6bcbebedbe1e ==============================
[0m10:14:39.279348 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:14:39.282622 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'debug': 'False', 'invocation_command': 'dbt run --select probability_of_defaulting', 'no_print': 'None', 'static_parser': 'True', 'warn_error': 'None', 'fail_fast': 'False', 'partial_parse': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'indirect_selection': 'eager', 'empty': 'False', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/david/.dbt', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False', 'use_colors': 'True', 'printer_width': '80', 'target_path': 'None', 'version_check': 'True'}
[0m10:14:52.001334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd0890fff-1520-4e85-adcf-6bcbebedbe1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4c9d73820>]}
[0m10:14:52.285588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd0890fff-1520-4e85-adcf-6bcbebedbe1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4cfd0d1c0>]}
[0m10:14:52.288661 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:14:52.406766 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:14:53.976840 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:14:53.978665 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:14:54.280584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd0890fff-1520-4e85-adcf-6bcbebedbe1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4d007e130>]}
[0m10:14:54.911797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd0890fff-1520-4e85-adcf-6bcbebedbe1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4d009d880>]}
[0m10:14:54.914142 [info ] [MainThread]: Found 17 models, 3 seeds, 1 operation, 480 macros
[0m10:14:54.919026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0890fff-1520-4e85-adcf-6bcbebedbe1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4d0048e50>]}
[0m10:14:54.932408 [info ] [MainThread]: 
[0m10:14:54.935123 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:14:54.941449 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m10:14:54.943866 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:15:01.019878 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m10:15:01.023031 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:15:01.715277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0890fff-1520-4e85-adcf-6bcbebedbe1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4c92efbb0>]}
[0m10:15:01.717990 [info ] [MainThread]: 
[0m10:15:01.719954 [info ] [MainThread]: Running 1 on-run-start hook
[0m10:15:01.839375 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m10:15:02.013058 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m10:15:02.017047 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:15:02.020581 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m10:15:02.733905 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:8d70ce7f-6f72-4236-b775-df9653391c4f&page=queryresults
[0m10:15:04.219726 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.20s]
[0m10:15:04.225909 [info ] [MainThread]: 
[0m10:15:04.228569 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:15:04.230159 [info ] [MainThread]: 
[0m10:15:04.238079 [debug] [Thread-1  ]: Began running node model.creditrisk.probability_of_defaulting
[0m10:15:04.241059 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.probability_of_defaulting ............. [RUN]
[0m10:15:04.243323 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.probability_of_defaulting)
[0m10:15:04.246502 [debug] [Thread-1  ]: Began compiling node model.creditrisk.probability_of_defaulting
[0m10:15:04.267038 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.probability_of_defaulting"
[0m10:15:04.276506 [debug] [Thread-1  ]: Began executing node model.creditrisk.probability_of_defaulting
[0m10:15:04.456542 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.probability_of_defaulting"
[0m10:15:04.459630 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:15:04.466132 [debug] [Thread-1  ]: On model.creditrisk.probability_of_defaulting: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.probability_of_defaulting"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`probability_of_defaulting`
  OPTIONS()
  as WITH proba_reactivation as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`
),

repayment as (
  SELECT 
    *,
    1 - prob_cum as survival_func, -- opposite of probability of reactivation
    IF(days_since_cutoff = 360, 1 - prob_cum, null) as survival_func_at_PAR360 -- opposite of probability of reactivation at PAR360
  FROM proba_reactivation
),

get_survival_limit as (
  SELECT 
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    MAX(survival_func_at_PAR360)  as survival_limit_at_PAR360,
    MIN(survival_func)            as survival_limit
  FROM repayment
  GROUP BY 1, 2, 3
),

immediate_churn_and_repo_act as (
  SELECT 
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    days_since_cutoff,
    survival_limit_at_PAR360,
    survival_limit,
    survival_func,
    -- probability of non-reactivation before PAR360 knowing there is non-reactivation event at time t
    SAFE_DIVIDE(IF(survival_limit_at_PAR360 is null, survival_limit, survival_limit_at_PAR360), survival_func) as immediate_prob_churn,
  FROM repayment
  LEFT JOIN get_survival_limit
    USING(perc_paid_bucket_start, perc_paid_bucket_end) 
),

immediate_churn as (
  SELECT 
    * EXCEPT(immediate_prob_churn),
    IF(days_since_cutoff > 360, 1, immediate_prob_churn) as immediate_prob_churn
  FROM immediate_churn_and_repo_act
)

SELECT * FROM immediate_churn;


[0m10:15:05.536454 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:c45a3ab4-1c12-40eb-9b31-6aa51dc90ccf&page=queryresults
[0m10:15:05.842593 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Column 3 contains an aggregation function, which is not allowed in GROUP BY at [25:18]; reason: invalidQuery, location: query, message: Column 3 contains an aggregation function, which is not allowed in GROUP BY at [25:18]')
[0m10:15:07.057701 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:f97a36a2-cb35-43d9-9a8f-0d7237f99f3a&page=queryresults
[0m10:15:07.344461 [error] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:f97a36a2-cb35-43d9-9a8f-0d7237f99f3a&page=queryresults
[0m10:15:07.364403 [debug] [Thread-1  ]: Database Error in model probability_of_defaulting (models/4_baobabplus_methodology/4_2_late_loans_ecl_model/probability_of_defaulting.sql)
  Column 3 contains an aggregation function, which is not allowed in GROUP BY at [25:18]
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_2_late_loans_ecl_model/probability_of_defaulting.sql
[0m10:15:07.371250 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0890fff-1520-4e85-adcf-6bcbebedbe1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4d089c5e0>]}
[0m10:15:07.374015 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model oscreditrisk.probability_of_defaulting .... [[31mERROR[0m in 3.12s]
[0m10:15:07.383733 [debug] [Thread-1  ]: Finished running node model.creditrisk.probability_of_defaulting
[0m10:15:07.391924 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:15:07.394033 [debug] [MainThread]: Connection 'model.creditrisk.probability_of_defaulting' was properly closed.
[0m10:15:07.395671 [info ] [MainThread]: 
[0m10:15:07.397338 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 12.46 seconds (12.46s).
[0m10:15:07.400551 [debug] [MainThread]: Command end result
[0m10:15:07.626015 [info ] [MainThread]: 
[0m10:15:07.629030 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:15:07.630603 [info ] [MainThread]: 
[0m10:15:07.633313 [error] [MainThread]:   Database Error in model probability_of_defaulting (models/4_baobabplus_methodology/4_2_late_loans_ecl_model/probability_of_defaulting.sql)
  Column 3 contains an aggregation function, which is not allowed in GROUP BY at [25:18]
  compiled code at target/run/creditrisk/models/4_baobabplus_methodology/4_2_late_loans_ecl_model/probability_of_defaulting.sql
[0m10:15:07.636772 [info ] [MainThread]: 
[0m10:15:07.639666 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:15:07.642491 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 28.637573, "process_user_time": 17.171543, "process_kernel_time": 3.26645, "process_mem_max_rss": "226906112", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:15:07.645093 [debug] [MainThread]: Command `dbt run` failed at 10:15:07.644631 after 28.64 seconds
[0m10:15:07.651568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4c9361520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4cfd84ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4cfd54520>]}
[0m10:15:07.653308 [debug] [MainThread]: Flushing usage events
[0m10:15:47.392325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0522354c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff054071b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0540712b0>]}


============================== 10:15:47.438114 | d9a405dc-d52d-4788-8624-7cb5bb5826fe ==============================
[0m10:15:47.438114 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:15:47.442093 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'write_json': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'fail_fast': 'False', 'use_colors': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'log_cache_events': 'False', 'profiles_dir': '/Users/david/.dbt', 'log_format': 'default', 'invocation_command': 'dbt run --select probability_of_defaulting', 'version_check': 'True', 'printer_width': '80', 'static_parser': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'partial_parse': 'True', 'target_path': 'None', 'warn_error': 'None'}
[0m10:16:08.473871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9a405dc-d52d-4788-8624-7cb5bb5826fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05831fe80>]}
[0m10:16:08.645623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd9a405dc-d52d-4788-8624-7cb5bb5826fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff057ab67c0>]}
[0m10:16:08.647660 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:16:08.716154 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:16:09.504837 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:16:09.508914 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:16:09.691009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd9a405dc-d52d-4788-8624-7cb5bb5826fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05867f130>]}
[0m10:16:10.093596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd9a405dc-d52d-4788-8624-7cb5bb5826fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05869cd60>]}
[0m10:16:10.095110 [info ] [MainThread]: Found 17 models, 3 seeds, 1 operation, 480 macros
[0m10:16:10.097335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9a405dc-d52d-4788-8624-7cb5bb5826fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff058648bb0>]}
[0m10:16:10.102728 [info ] [MainThread]: 
[0m10:16:10.105658 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:16:10.108996 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m10:16:10.110730 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:16:14.896037 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m10:16:14.899574 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:16:15.568873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9a405dc-d52d-4788-8624-7cb5bb5826fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff058687fa0>]}
[0m10:16:15.570328 [info ] [MainThread]: 
[0m10:16:15.571322 [info ] [MainThread]: Running 1 on-run-start hook
[0m10:16:15.605268 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m10:16:15.620341 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m10:16:15.621974 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:16:15.623301 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m10:16:16.338645 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:458dddf9-715f-43d5-88a6-2401ac060575&page=queryresults
[0m10:16:17.575429 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 1.95s]
[0m10:16:17.576637 [info ] [MainThread]: 
[0m10:16:17.577897 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:16:17.578852 [info ] [MainThread]: 
[0m10:16:17.585387 [debug] [Thread-1  ]: Began running node model.creditrisk.probability_of_defaulting
[0m10:16:17.587053 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.probability_of_defaulting ............. [RUN]
[0m10:16:17.588343 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.probability_of_defaulting)
[0m10:16:17.589380 [debug] [Thread-1  ]: Began compiling node model.creditrisk.probability_of_defaulting
[0m10:16:17.599049 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.probability_of_defaulting"
[0m10:16:17.601556 [debug] [Thread-1  ]: Began executing node model.creditrisk.probability_of_defaulting
[0m10:16:17.687435 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.probability_of_defaulting"
[0m10:16:17.689221 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:16:17.690487 [debug] [Thread-1  ]: On model.creditrisk.probability_of_defaulting: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.probability_of_defaulting"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`probability_of_defaulting`
  OPTIONS()
  as WITH proba_reactivation as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`
),

repayment as (
  SELECT 
    *,
    1 - prob_cum as survival_func, -- opposite of probability of reactivation
    IF(days_since_cutoff = 360, 1 - prob_cum, null) as survival_func_at_PAR360 -- opposite of probability of reactivation at PAR360
  FROM proba_reactivation
),

get_survival_limit as (
  SELECT 
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    MAX(survival_func_at_PAR360)  as survival_limit_at_PAR360,
    MIN(survival_func)            as survival_limit
  FROM repayment
  GROUP BY ALL
),

immediate_churn_and_repo_act as (
  SELECT 
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    days_since_cutoff,
    survival_limit_at_PAR360,
    survival_limit,
    survival_func,
    -- probability of non-reactivation before PAR360 knowing there is non-reactivation event at time t
    SAFE_DIVIDE(IF(survival_limit_at_PAR360 is null, survival_limit, survival_limit_at_PAR360), survival_func) as immediate_prob_churn,
  FROM repayment
  LEFT JOIN get_survival_limit
    USING(perc_paid_bucket_start, perc_paid_bucket_end) 
),

immediate_churn as (
  SELECT 
    * EXCEPT(immediate_prob_churn),
    IF(days_since_cutoff > 360, 1, immediate_prob_churn) as immediate_prob_churn
  FROM immediate_churn_and_repo_act
)

SELECT * FROM immediate_churn;


[0m10:16:18.691423 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:042fa053-ac04-4962-894c-c393eed40b52&page=queryresults
[0m10:16:19.457813 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9a405dc-d52d-4788-8624-7cb5bb5826fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff057ac2640>]}
[0m10:16:19.460059 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.probability_of_defaulting ........ [[32mCREATE VIEW (0 processed)[0m in 1.87s]
[0m10:16:19.461697 [debug] [Thread-1  ]: Finished running node model.creditrisk.probability_of_defaulting
[0m10:16:19.464357 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:16:19.465227 [debug] [MainThread]: Connection 'model.creditrisk.probability_of_defaulting' was properly closed.
[0m10:16:19.466201 [info ] [MainThread]: 
[0m10:16:19.467579 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 9.36 seconds (9.36s).
[0m10:16:19.469612 [debug] [MainThread]: Command end result
[0m10:16:19.573269 [info ] [MainThread]: 
[0m10:16:19.574436 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:16:19.575336 [info ] [MainThread]: 
[0m10:16:19.576416 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:16:19.578212 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 33.026623, "process_user_time": 18.362589, "process_kernel_time": 4.109977, "process_mem_max_rss": "223379456", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:16:19.581852 [debug] [MainThread]: Command `dbt run` succeeded at 10:16:19.579724 after 33.03 seconds
[0m10:16:19.583662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0522354c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05256a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff054040e50>]}
[0m10:16:19.586100 [debug] [MainThread]: Flushing usage events
[0m10:18:50.187521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90f8c9d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90fc2b1c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90fc2b1130>]}


============================== 10:18:50.193172 | bf3a41d9-dac2-42d0-994d-93260c84c063 ==============================
[0m10:18:50.193172 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:18:50.194116 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'profiles_dir': '/Users/david/.dbt', 'static_parser': 'True', 'introspect': 'True', 'cache_selected_only': 'False', 'use_colors': 'True', 'invocation_command': 'dbt run --select probability_of_defaulting', 'fail_fast': 'False', 'write_json': 'True', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'indirect_selection': 'eager', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'version_check': 'True', 'log_format': 'default', 'log_cache_events': 'False', 'empty': 'False', 'partial_parse': 'True', 'printer_width': '80'}
[0m10:18:54.545368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bf3a41d9-dac2-42d0-994d-93260c84c063', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f910150c130>]}
[0m10:18:54.616929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bf3a41d9-dac2-42d0-994d-93260c84c063', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9101562a90>]}
[0m10:18:54.617772 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:18:54.649459 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:18:55.025976 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:18:55.027071 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:18:55.115464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bf3a41d9-dac2-42d0-994d-93260c84c063', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f910197e130>]}
[0m10:18:55.318283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf3a41d9-dac2-42d0-994d-93260c84c063', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f910199dca0>]}
[0m10:18:55.319058 [info ] [MainThread]: Found 17 models, 3 seeds, 1 operation, 480 macros
[0m10:18:55.319612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bf3a41d9-dac2-42d0-994d-93260c84c063', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f910194ff10>]}
[0m10:18:55.321472 [info ] [MainThread]: 
[0m10:18:55.322307 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:18:55.323466 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m10:18:55.323990 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:18:59.681768 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m10:18:59.682859 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:19:01.254911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bf3a41d9-dac2-42d0-994d-93260c84c063', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9100e17790>]}
[0m10:19:01.255989 [info ] [MainThread]: 
[0m10:19:01.256992 [info ] [MainThread]: Running 1 on-run-start hook
[0m10:19:01.276197 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m10:19:01.283838 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m10:19:01.284623 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:19:01.285345 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m10:19:02.847610 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:40a48bfc-8c20-4b81-a3f0-cf29d83ffccb&page=queryresults
[0m10:19:04.792567 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.51s]
[0m10:19:04.793343 [info ] [MainThread]: 
[0m10:19:04.794205 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:19:04.794805 [info ] [MainThread]: 
[0m10:19:04.799357 [debug] [Thread-1  ]: Began running node model.creditrisk.probability_of_defaulting
[0m10:19:04.800296 [info ] [Thread-1  ]: 1 of 1 START sql view model oscreditrisk.probability_of_defaulting ............. [RUN]
[0m10:19:04.801055 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.probability_of_defaulting)
[0m10:19:04.801692 [debug] [Thread-1  ]: Began compiling node model.creditrisk.probability_of_defaulting
[0m10:19:04.806753 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.probability_of_defaulting"
[0m10:19:04.807886 [debug] [Thread-1  ]: Began executing node model.creditrisk.probability_of_defaulting
[0m10:19:04.857979 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.probability_of_defaulting"
[0m10:19:04.859102 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:19:04.859869 [debug] [Thread-1  ]: On model.creditrisk.probability_of_defaulting: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.probability_of_defaulting"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`probability_of_defaulting`
  OPTIONS()
  as WITH proba_reactivation as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`
),

repayment as (
  SELECT 
    *,
    1 - prob_cum as survival_func, -- opposite of probability of reactivation
    IF(days_since_cutoff = 270, 1 - prob_cum, null) as survival_func_at_PAR270 -- opposite of probability of reactivation at PAR270
  FROM proba_reactivation
),

get_survival_limit as (
  SELECT 
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    MAX(survival_func_at_PAR270)  as survival_limit_at_PAR270,
    MIN(survival_func)            as survival_limit
  FROM repayment
  GROUP BY ALL
),

immediate_churn_and_repo_act as (
  SELECT 
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    days_since_cutoff,
    survival_limit_at_PAR270,
    survival_limit,
    survival_func,
    -- probability of non-reactivation before PAR270 knowing there is non-reactivation event at time t
    SAFE_DIVIDE(IF(survival_limit_at_PAR270 is null, survival_limit, survival_limit_at_PAR270), survival_func) as immediate_prob_churn,
  FROM repayment
  LEFT JOIN get_survival_limit
    USING(perc_paid_bucket_start, perc_paid_bucket_end) 
),

immediate_churn as (
  SELECT 
    * EXCEPT(immediate_prob_churn),
    IF(days_since_cutoff > 270, 1, immediate_prob_churn) as immediate_prob_churn
  FROM immediate_churn_and_repo_act
)

SELECT * FROM immediate_churn;


[0m10:19:06.855423 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:4dc7a0fe-1cdc-444e-b169-1c76e570faa6&page=queryresults
[0m10:19:08.144272 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf3a41d9-dac2-42d0-994d-93260c84c063', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9100dd6730>]}
[0m10:19:08.145213 [info ] [Thread-1  ]: 1 of 1 OK created sql view model oscreditrisk.probability_of_defaulting ........ [[32mCREATE VIEW (0 processed)[0m in 3.34s]
[0m10:19:08.146179 [debug] [Thread-1  ]: Finished running node model.creditrisk.probability_of_defaulting
[0m10:19:08.147740 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:19:08.148185 [debug] [MainThread]: Connection 'model.creditrisk.probability_of_defaulting' was properly closed.
[0m10:19:08.148649 [info ] [MainThread]: 
[0m10:19:08.149141 [info ] [MainThread]: Finished running 1 view model, 1 project hook in 0 hours 0 minutes and 12.83 seconds (12.83s).
[0m10:19:08.150073 [debug] [MainThread]: Command end result
[0m10:19:08.201716 [info ] [MainThread]: 
[0m10:19:08.202597 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:19:08.203236 [info ] [MainThread]: 
[0m10:19:08.203852 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:19:08.204718 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 18.112453, "process_user_time": 5.669064, "process_kernel_time": 1.1205, "process_mem_max_rss": "226201600", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:19:08.205696 [debug] [MainThread]: Command `dbt run` succeeded at 10:19:08.205504 after 18.11 seconds
[0m10:19:08.206572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90f8c9d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91019b4580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9101562a90>]}
[0m10:19:08.207509 [debug] [MainThread]: Flushing usage events
[0m10:26:24.692082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9564361580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9566268be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9566268190>]}


============================== 10:26:24.698318 | 8d229468-1abe-49e9-9279-cae621271ebe ==============================
[0m10:26:24.698318 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:26:24.699366 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'write_json': 'True', 'introspect': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'profiles_dir': '/Users/david/.dbt', 'quiet': 'False', 'printer_width': '80', 'use_colors': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False', 'debug': 'False', 'log_format': 'default', 'no_print': 'None', 'fail_fast': 'False', 'static_parser': 'True', 'invocation_command': 'dbt run --select 4_baobabplus_methodology', 'target_path': 'None', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False'}
[0m10:26:29.132360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956a587f70>]}
[0m10:26:29.191988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956ac9c280>]}
[0m10:26:29.192700 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:26:29.224654 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:26:29.601209 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m10:26:29.601938 [debug] [MainThread]: Partial parsing: added file: creditrisk://models/4_baobabplus_methodology/4_4_predict_ecls/predict_ecls.sql
[0m10:26:29.897195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b309e20>]}
[0m10:26:30.080097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b331880>]}
[0m10:26:30.080889 [info ] [MainThread]: Found 19 models, 3 seeds, 1 operation, 480 macros
[0m10:26:30.081441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b309d90>]}
[0m10:26:30.083560 [info ] [MainThread]: 
[0m10:26:30.084354 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:26:30.091839 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m10:26:30.092545 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:26:34.468946 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m10:26:34.470555 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:26:35.152817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956462d6a0>]}
[0m10:26:35.153717 [info ] [MainThread]: 
[0m10:26:35.154267 [info ] [MainThread]: Running 1 on-run-start hook
[0m10:26:35.171846 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m10:26:35.181246 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m10:26:35.182108 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:26:35.182862 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m10:26:35.910888 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:fc405474-6993-4f0b-b6c6-1b21f124778e&page=queryresults
[0m10:26:37.328632 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.15s]
[0m10:26:37.329418 [info ] [MainThread]: 
[0m10:26:37.330249 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:26:37.330821 [info ] [MainThread]: 
[0m10:26:37.335956 [debug] [Thread-1  ]: Began running node model.creditrisk.history_defaults
[0m10:26:37.336915 [info ] [Thread-1  ]: 1 of 9 START sql view model oscreditrisk.history_defaults ...................... [RUN]
[0m10:26:37.337693 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.history_defaults)
[0m10:26:37.338616 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_defaults
[0m10:26:37.344292 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_defaults"
[0m10:26:37.346988 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_defaults
[0m10:26:37.394961 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_defaults"
[0m10:26:37.397268 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:26:37.398083 [debug] [Thread-1  ]: On model.creditrisk.history_defaults: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_defaults"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
  OPTIONS()
  as /*
    This transformations creates a dataset containing one line per account and contains the information if the account has defaulted or not. 
*/

WITH history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

detect_defaults as (
    SELECT 
        account_id,
        registration_date,
        perc_paid,
        CASE 
            WHEN reporting_date_status in ('UNLOCKED') THEN 0
            WHEN reporting_date_status in ('DETACHED', 'WRITTEN_OFF') THEN 1
            WHEN days_disabled >= 180 THEN 1
            ELSE 0
        END as has_defaulted,
    FROM history
)

SELECT * FROM detect_defaults;


[0m10:26:38.142844 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:2bffaf6b-8b58-41cd-915b-c887fccadcab&page=queryresults
[0m10:26:38.788539 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b970dc0>]}
[0m10:26:38.789643 [info ] [Thread-1  ]: 1 of 9 OK created sql view model oscreditrisk.history_defaults ................. [[32mCREATE VIEW (0 processed)[0m in 1.45s]
[0m10:26:38.790640 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_defaults
[0m10:26:38.791341 [debug] [Thread-1  ]: Began running node model.creditrisk.history_disablements
[0m10:26:38.792053 [info ] [Thread-1  ]: 2 of 9 START sql view model oscreditrisk.history_disablements .................. [RUN]
[0m10:26:38.792952 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_defaults, now model.creditrisk.history_disablements)
[0m10:26:38.793556 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_disablements
[0m10:26:38.802706 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_disablements"
[0m10:26:38.805632 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_disablements
[0m10:26:38.811255 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_disablements"
[0m10:26:38.812588 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:26:38.813672 [debug] [Thread-1  ]: On model.creditrisk.history_disablements: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_disablements"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_disablements`
  OPTIONS()
  as /*
    This transformation prepares a dataset in the right format for a survival analysis.
    The target dataset contains one line per disablement period. 
    Duration represents the duration of the period. Event represents the fact that there was a payment interrupting the period. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

get_disablement_periods as (
    SELECT 
        account_id,
        reporting_date,
        perc_paid,
        LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day) as last_disablement,
        days_disabled,
    FROM accounts_history
),

aggregated_disablement_periods as (
    SELECT 
        account_id,
        reporting_date,
        perc_paid,
        days_disabled as duration,
    FROM get_disablement_periods
    QUALIFY days_disabled = MAX(days_disabled) OVER(PARTITION BY account_id, last_disablement)
)


SELECT 
    *,
    IF(reporting_date = MAX(reporting_date) OVER(), 0, 1) as event,
FROM aggregated_disablement_periods;


[0m10:26:39.560895 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:630d8aeb-7d7d-4120-8f2e-b873a3f332de&page=queryresults
[0m10:26:40.208326 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b970b80>]}
[0m10:26:40.209755 [info ] [Thread-1  ]: 2 of 9 OK created sql view model oscreditrisk.history_disablements ............. [[32mCREATE VIEW (0 processed)[0m in 1.42s]
[0m10:26:40.211538 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_disablements
[0m10:26:40.212441 [debug] [Thread-1  ]: Began running node model.creditrisk.history_segmentations
[0m10:26:40.214354 [info ] [Thread-1  ]: 3 of 9 START sql view model oscreditrisk.history_segmentations ................. [RUN]
[0m10:26:40.215166 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_disablements, now model.creditrisk.history_segmentations)
[0m10:26:40.215805 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_segmentations
[0m10:26:40.222132 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_segmentations"
[0m10:26:40.223982 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_segmentations
[0m10:26:40.230349 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_segmentations"
[0m10:26:40.231638 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:26:40.232744 [debug] [Thread-1  ]: On model.creditrisk.history_segmentations: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_segmentations"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_segmentations`
  OPTIONS()
  as /*
    This transformations generates a table representing the segmentation A, B, C and D
    for each account depending on the progress on repayment. 
    It will be used to train the model to pick up these segmentations.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

segmentation_at_0 as (
  SELECT 
    account_id,
    0 as perc_paid_current,
    '0. At registration' as account_segmentation,
  FROM accounts_history
  WHERE reporting_day = 1
),

segmentation_at_10 as (
  SELECT 
    account_id,
    0.1 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.1
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_20 as (
  SELECT 
    account_id,
    0.2 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.2
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_30 as (
  SELECT 
    account_id,
    0.3 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.3
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_40 as (
  SELECT 
    account_id,
    0.4 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.4
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_50 as (
  SELECT 
    account_id,
    0.5 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.5
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_60 as (
  SELECT 
    account_id,
    0.6 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.6
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_70 as (
  SELECT 
    account_id,
    0.7 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.7
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_80 as (
  SELECT 
    account_id,
    0.8 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.8
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_90 as (
  SELECT 
    account_id,
    0.9 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.9
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
)

SELECT * FROM segmentation_at_0
UNION ALL
SELECT * FROM segmentation_at_10
UNION ALL
SELECT * FROM segmentation_at_20
UNION ALL
SELECT * FROM segmentation_at_30
UNION ALL
SELECT * FROM segmentation_at_40
UNION ALL
SELECT * FROM segmentation_at_50
UNION ALL
SELECT * FROM segmentation_at_60
UNION ALL
SELECT * FROM segmentation_at_70
UNION ALL
SELECT * FROM segmentation_at_80
UNION ALL
SELECT * FROM segmentation_at_90;


[0m10:26:40.947656 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:6a96be71-578b-4db4-a2e4-a65a5f710777&page=queryresults
[0m10:26:41.554145 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b9781c0>]}
[0m10:26:41.555264 [info ] [Thread-1  ]: 3 of 9 OK created sql view model oscreditrisk.history_segmentations ............ [[32mCREATE VIEW (0 processed)[0m in 1.34s]
[0m10:26:41.556515 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_segmentations
[0m10:26:41.557385 [debug] [Thread-1  ]: Began running node model.creditrisk.repossession_valuation_parameters
[0m10:26:41.558468 [info ] [Thread-1  ]: 4 of 9 START sql view model oscreditrisk.repossession_valuation_parameters ..... [RUN]
[0m10:26:41.559614 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_segmentations, now model.creditrisk.repossession_valuation_parameters)
[0m10:26:41.560480 [debug] [Thread-1  ]: Began compiling node model.creditrisk.repossession_valuation_parameters
[0m10:26:41.566834 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.repossession_valuation_parameters"
[0m10:26:41.568093 [debug] [Thread-1  ]: Began executing node model.creditrisk.repossession_valuation_parameters
[0m10:26:41.572705 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.repossession_valuation_parameters"
[0m10:26:41.573905 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:26:41.574652 [debug] [Thread-1  ]: On model.creditrisk.repossession_valuation_parameters: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.repossession_valuation_parameters"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`repossession_valuation_parameters`
  OPTIONS()
  as /*
    This part is drastically simplified here. 
    Analyses should be performed to determine the right value of KPIs. 
    Here we are using these values as placeholders to show how they fit in the global model recombination.
*/

SELECT 
    0.6 as probability_of_repossession,
    0.2 as repossession_value, -- expressed here as a percentage of initial unlock price.;


[0m10:26:42.293405 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:102c3a1a-8ddd-4e3f-9526-e0717a9f8583&page=queryresults
[0m10:26:42.932646 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b9842e0>]}
[0m10:26:42.933652 [info ] [Thread-1  ]: 4 of 9 OK created sql view model oscreditrisk.repossession_valuation_parameters  [[32mCREATE VIEW (0 processed)[0m in 1.37s]
[0m10:26:42.934662 [debug] [Thread-1  ]: Finished running node model.creditrisk.repossession_valuation_parameters
[0m10:26:42.935482 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_date_samples
[0m10:26:42.936391 [info ] [Thread-1  ]: 5 of 9 START sql view model oscreditrisk.prepare_date_samples .................. [RUN]
[0m10:26:42.937398 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.repossession_valuation_parameters, now model.creditrisk.prepare_date_samples)
[0m10:26:42.938035 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_date_samples
[0m10:26:42.947699 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_date_samples"
[0m10:26:42.951100 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_date_samples
[0m10:26:42.956877 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_date_samples"
[0m10:26:42.958250 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:26:42.959594 [debug] [Thread-1  ]: On model.creditrisk.prepare_date_samples: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_date_samples"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`prepare_date_samples`
  OPTIONS()
  as /*
    This transformation is quite essential to produce an unbiaised model
    For every chunk of repayment [0-10%], [10-20%], etc... it estimates what is the sample of accounts we can use for estimating probabilities of default.
    For example, if for 40 - 50% the sample end date is 2020-12-03, it means that we must use only accounts registered prior to this date.
    Otherwise, we are going to produce biaised (selection bias) estimates, as too many accounts will not have finished paying or will not have defaulted.
*/

WITH default_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
),

date_spine as (
    SELECT reporting_date as sample_end_date FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

-- Generates a table containing 10 rows, representing the different chunks of repayment : 0 to 10%, 10 to 20%, etc...
split_chunks as (
    SELECT 
        *,
        index_chunk / 10 as perc_paid_chunk_start,
        COALESCE(
            LEAD(index_chunk / 10) OVER(ORDER BY index_chunk),
            1
        ) as perc_paid_chunk_end,
    FROM UNNEST(GENERATE_ARRAY(0, 9)) as index_chunk
),

crossjoint as (
    SELECT 
        *,
        IF(perc_paid < perc_paid_chunk_end AND has_defaulted = 0, 1, 0) as is_censored,
    FROM default_history
    CROSS JOIN split_chunks
),

grouped as (
    SELECT 
        index_chunk,
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        sample_end_date,
        AVG(is_censored) as censored_percent,
    FROM crossjoint
    LEFT JOIN date_spine
    ON date_spine.sample_end_date >= crossjoint.registration_date
    GROUP BY ALL
    HAVING censored_percent <= 0.05 -- Here the tolerance to censoring is 5%.
),

get_chunck_dates as (
    SELECT 
        index_chunk,
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        MAX(sample_end_date) as sample_end_date,
    FROM grouped 
    GROUP BY ALL
)

SELECT * FROM get_chunck_dates;


[0m10:26:43.996596 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:f0ae0347-e764-4670-8fe5-f7d5232d3748&page=queryresults
[0m10:26:44.606992 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956bd79700>]}
[0m10:26:44.608147 [info ] [Thread-1  ]: 5 of 9 OK created sql view model oscreditrisk.prepare_date_samples ............. [[32mCREATE VIEW (0 processed)[0m in 1.67s]
[0m10:26:44.609181 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_date_samples
[0m10:26:44.609920 [debug] [Thread-1  ]: Began running node model.creditrisk.probability_calculation_survival
[0m10:26:44.610686 [info ] [Thread-1  ]: 6 of 9 START sql view model oscreditrisk.probability_calculation_survival ...... [RUN]
[0m10:26:44.611721 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.prepare_date_samples, now model.creditrisk.probability_calculation_survival)
[0m10:26:44.612352 [debug] [Thread-1  ]: Began compiling node model.creditrisk.probability_calculation_survival
[0m10:26:44.621703 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.probability_calculation_survival"
[0m10:26:44.624103 [debug] [Thread-1  ]: Began executing node model.creditrisk.probability_calculation_survival
[0m10:26:44.630387 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.probability_calculation_survival"
[0m10:26:44.632277 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:26:44.633875 [debug] [Thread-1  ]: On model.creditrisk.probability_calculation_survival: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.probability_calculation_survival"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`
  OPTIONS()
  as /*
    This is a SQL implementation of the Kaplan Meier Survival Analysis.
    The output is a survival function. 
*/

WITH reactivation_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_disablements`
),

-- Split by perc paid bucket and take only last 3 years events observed
reactivation_history_filtered as (
    SELECT 
        *, 
        CASE 
            WHEN perc_paid <= 0.1 THEN '0'
            WHEN perc_paid <= 0.5 THEN '0.1'
            WHEN perc_paid <= 1 THEN '0.5'
            ELSE '0.5'
        END as perc_paid_bucket_start,
            CASE 
            WHEN perc_paid <= 0.1 THEN '0.1'
            WHEN perc_paid <= 0.5 THEN '0.5'
            WHEN perc_paid <= 1 THEN '1'
            ELSE '1'
        END as perc_paid_bucket_end
    FROM reactivation_history
),

cnt_subjects as (
  SELECT 
    perc_paid_bucket_start, 
    perc_paid_bucket_end, 
    COUNT(*) as num_subjects 
  FROM reactivation_history_filtered
  GROUP BY ALL 
),

daily as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end,
    duration,
    COUNT(*) as num_obs,
    SUM(event) as num_events
  FROM reactivation_history_filtered
  GROUP BY ALL ORDER BY 1, 2, 3
),

at_risk_table as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end,
    duration, 
    num_obs,
    num_events,
    num_subjects - COALESCE(SUM(num_obs) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end
      ORDER BY duration ASC ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING), 0)
     as at_risk
  FROM daily
  LEFT JOIN cnt_subjects USING(perc_paid_bucket_start, perc_paid_bucket_end)
),

survival_proba_table as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end, 
    duration, 
    at_risk,
    num_obs,
    num_events,
    at_risk - num_events - COALESCE(LEAD(at_risk, 1) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC), 0) as censored,
    EXP(SUM(SAFE.LN(1 - num_events / at_risk)) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC ROWS BETWEEN UNBOUNDED PRECEDING AND current ROW)) as survival_proba
  FROM at_risk_table
),

get_density_proba as (
  SELECT  
    survival_proba_table.*,
    1 - survival_proba as prob_cum,
    (1 - survival_proba) - COALESCE(1 - LAG(survival_proba) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC), 0) as prob_dens,
    ROW_NUMBER() OVER (PARTITION BY perc_paid_bucket_end ORDER BY duration ASC) as row_num
  FROM survival_proba_table
)

SELECT 
    * EXCEPT(duration, perc_paid_bucket_start, perc_paid_bucket_end),
    CAST(perc_paid_bucket_start AS FLOAT64) as perc_paid_bucket_start,
    CAST(perc_paid_bucket_end AS FLOAT64) as perc_paid_bucket_end,
    duration as days_since_cutoff 
FROM get_density_proba
ORDER BY perc_paid_bucket_start, duration;


[0m10:26:45.565294 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:2f1592d2-48ed-4f2a-8d68-719eaec7db3d&page=queryresults
[0m10:26:46.151344 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b9760a0>]}
[0m10:26:46.152598 [info ] [Thread-1  ]: 6 of 9 OK created sql view model oscreditrisk.probability_calculation_survival . [[32mCREATE VIEW (0 processed)[0m in 1.54s]
[0m10:26:46.153696 [debug] [Thread-1  ]: Finished running node model.creditrisk.probability_calculation_survival
[0m10:26:46.154512 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_inputs
[0m10:26:46.155916 [info ] [Thread-1  ]: 7 of 9 START sql view model oscreditrisk.prepare_model_inputs .................. [RUN]
[0m10:26:46.157018 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.probability_calculation_survival, now model.creditrisk.prepare_model_inputs)
[0m10:26:46.157703 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_inputs
[0m10:26:46.167425 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_inputs"
[0m10:26:46.168596 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_inputs
[0m10:26:46.174529 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_inputs"
[0m10:26:46.176217 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:26:46.177044 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_inputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_inputs"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
  OPTIONS()
  as /*
    Simple preparation step joining the various inputs.
*/

WITH accs as (
  SELECT 
    *,
  FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
  LEFT JOIN `steam-outlet-209412`.`oscreditrisk`.`history_segmentations` USING(account_id)
),

samples as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_date_samples`
),

joint as (
  SELECT 
    accs.*,
    samples.*,
    RAND() as rnd,
  FROM accs
  INNER JOIN samples
  ON 
    accs.registration_date < CAST(samples.sample_end_date AS TIMESTAMP)
)

SELECT * FROM joint;


[0m10:26:47.075692 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:23de3f86-9244-449c-9696-859c9fba831d&page=queryresults
[0m10:26:47.674184 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956bd74f40>]}
[0m10:26:47.675422 [info ] [Thread-1  ]: 7 of 9 OK created sql view model oscreditrisk.prepare_model_inputs ............. [[32mCREATE VIEW (0 processed)[0m in 1.52s]
[0m10:26:47.676603 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_inputs
[0m10:26:47.677313 [debug] [Thread-1  ]: Began running node model.creditrisk.probability_of_defaulting
[0m10:26:47.678057 [info ] [Thread-1  ]: 8 of 9 START sql view model oscreditrisk.probability_of_defaulting ............. [RUN]
[0m10:26:47.678840 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.prepare_model_inputs, now model.creditrisk.probability_of_defaulting)
[0m10:26:47.679571 [debug] [Thread-1  ]: Began compiling node model.creditrisk.probability_of_defaulting
[0m10:26:47.687381 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.probability_of_defaulting"
[0m10:26:47.689137 [debug] [Thread-1  ]: Began executing node model.creditrisk.probability_of_defaulting
[0m10:26:47.694521 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.probability_of_defaulting"
[0m10:26:47.695710 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:26:47.696522 [debug] [Thread-1  ]: On model.creditrisk.probability_of_defaulting: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.probability_of_defaulting"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`probability_of_defaulting`
  OPTIONS()
  as /*
    This transformation uses the output of the survival function to determine the immediate probability of defaulting of a late account
*/

WITH proba_reactivation as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`
),

repayment as (
  SELECT 
    *,
    1 - prob_cum as survival_func, -- opposite of probability of reactivation
    IF(days_since_cutoff = 270, 1 - prob_cum, null) as survival_func_at_PAR270 -- opposite of probability of reactivation at PAR270
  FROM proba_reactivation
),

get_survival_limit as (
  SELECT 
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    MAX(survival_func_at_PAR270)  as survival_limit_at_PAR270,
    MIN(survival_func)            as survival_limit
  FROM repayment
  GROUP BY ALL
),

immediate_churn_and_repo_act as (
  SELECT 
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    days_since_cutoff,
    survival_limit_at_PAR270,
    survival_limit,
    survival_func,
    -- probability of non-reactivation before PAR270 knowing there is non-reactivation event at time t
    SAFE_DIVIDE(IF(survival_limit_at_PAR270 is null, survival_limit, survival_limit_at_PAR270), survival_func) as immediate_prob_churn,
  FROM repayment
  LEFT JOIN get_survival_limit
    USING(perc_paid_bucket_start, perc_paid_bucket_end) 
),

immediate_churn as (
  SELECT 
    * EXCEPT(immediate_prob_churn),
    IF(days_since_cutoff > 270, 1, immediate_prob_churn) as immediate_prob_churn
  FROM immediate_churn_and_repo_act
)

SELECT * FROM immediate_churn;


[0m10:26:48.662942 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:6ee76526-b224-41b2-bcf0-3964d13d57ca&page=queryresults
[0m10:26:49.275081 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b970790>]}
[0m10:26:49.276321 [info ] [Thread-1  ]: 8 of 9 OK created sql view model oscreditrisk.probability_of_defaulting ........ [[32mCREATE VIEW (0 processed)[0m in 1.60s]
[0m10:26:49.277487 [debug] [Thread-1  ]: Finished running node model.creditrisk.probability_of_defaulting
[0m10:26:49.278509 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_outputs
[0m10:26:49.279469 [info ] [Thread-1  ]: 9 of 9 START sql table model oscreditrisk.prepare_model_outputs ................ [RUN]
[0m10:26:49.280336 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.probability_of_defaulting, now model.creditrisk.prepare_model_outputs)
[0m10:26:49.283050 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_outputs
[0m10:26:49.288618 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_outputs"
[0m10:26:49.289929 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_outputs
[0m10:26:49.306842 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:26:50.142710 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_outputs"
[0m10:26:50.143995 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_outputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_outputs"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`
      
    
    

    OPTIONS()
    as (
      /*
    This is where the main calculation happens.
    Calculation of the PDs & PDs * EADs.
*/



WITH input as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
),

calculated as (
  SELECT 
    perc_paid_current,
    account_segmentation,
    sample_end_date, 
    perc_paid_chunk_start,
    perc_paid_chunk_end,
    COUNT(*) as number_of_accounts,
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1
        WHEN 
            has_defaulted = 0 
            AND perc_paid < perc_paid_chunk_start AND 
            -- This formula takes an assumption for future default rates of censored accounts.
            -- Here we consider the account will have 40% chances of defaulting in the remaining repayment
            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10) 
        THEN 1
        ELSE 0
      END
    ) as p_churn_incr, -- p_churn represents the probability of default
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1 - perc_paid
        WHEN 
            has_defaulted = 0 AND 
            perc_paid < perc_paid_chunk_end AND 
            -- This formula takes an assumption for future default rates of censored accounts.
            -- Here we consider the account will have 40% chances of defaulting in the remaining repayment
            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10)
        THEN 1 - perc_paid_chunk_start
        ELSE 0
      END
    ) as r_churn_incr, -- r_churn represents the expected loss in receivable PD * EAD.
  FROM input
  GROUP BY ALL
)

SELECT 
    *,

    SUM(p_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as p_churn,

    SUM(r_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as r_churn, 

FROM calculated
    );
  
[0m10:26:50.915600 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:8c9dfaf2-a8f7-407b-b170-2d17069c8f93&page=queryresults
[0m10:26:57.583008 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d229468-1abe-49e9-9279-cae621271ebe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b976bb0>]}
[0m10:26:57.584237 [info ] [Thread-1  ]: 9 of 9 OK created sql table model oscreditrisk.prepare_model_outputs ........... [[32mCREATE TABLE (369.0 rows, 174.7 MiB processed)[0m in 8.30s]
[0m10:26:57.585258 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_outputs
[0m10:26:57.587422 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:26:57.588234 [debug] [MainThread]: Connection 'model.creditrisk.prepare_model_outputs' was properly closed.
[0m10:26:57.588995 [info ] [MainThread]: 
[0m10:26:57.590408 [info ] [MainThread]: Finished running 8 view models, 1 table model, 1 project hook in 0 hours 0 minutes and 27.50 seconds (27.50s).
[0m10:26:57.593720 [debug] [MainThread]: Command end result
[0m10:26:57.654518 [info ] [MainThread]: 
[0m10:26:57.655335 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:26:57.656476 [info ] [MainThread]: 
[0m10:26:57.657227 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m10:26:57.658216 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 33.079773, "process_user_time": 6.133898, "process_kernel_time": 1.205901, "process_mem_max_rss": "232943616", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:26:57.659555 [debug] [MainThread]: Command `dbt run` succeeded at 10:26:57.659258 after 33.08 seconds
[0m10:26:57.660605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9564361580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956b309100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956ac9c280>]}
[0m10:26:57.661785 [debug] [MainThread]: Flushing usage events
[0m10:39:52.785449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc803a60520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8073b0a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8073b0340>]}


============================== 10:39:52.789751 | 73524e60-5bc3-4691-a122-98ac7376483d ==============================
[0m10:39:52.789751 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:39:52.790940 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'static_parser': 'True', 'debug': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'no_print': 'None', 'target_path': 'None', 'cache_selected_only': 'False', 'partial_parse': 'True', 'version_check': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run --select accounts_history_advanced', 'quiet': 'False', 'fail_fast': 'False', 'introspect': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'profiles_dir': '/Users/david/.dbt', 'empty': 'False', 'write_json': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False'}
[0m10:39:56.286744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '73524e60-5bc3-4691-a122-98ac7376483d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80b68db20>]}
[0m10:39:56.342621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '73524e60-5bc3-4691-a122-98ac7376483d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8073700d0>]}
[0m10:39:56.343395 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:39:56.370273 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:39:56.722461 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:39:56.723010 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:39:56.790298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '73524e60-5bc3-4691-a122-98ac7376483d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80c089130>]}
[0m10:39:56.948746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73524e60-5bc3-4691-a122-98ac7376483d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80c077f10>]}
[0m10:39:56.949518 [info ] [MainThread]: Found 19 models, 3 seeds, 1 operation, 480 macros
[0m10:39:56.950080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73524e60-5bc3-4691-a122-98ac7376483d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80bddf340>]}
[0m10:39:56.952317 [info ] [MainThread]: 
[0m10:39:56.953201 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:39:56.954371 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m10:39:56.954913 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:40:01.849488 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m10:40:01.851401 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:40:03.503791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73524e60-5bc3-4691-a122-98ac7376483d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8038c0bb0>]}
[0m10:40:03.504670 [info ] [MainThread]: 
[0m10:40:03.505234 [info ] [MainThread]: Running 1 on-run-start hook
[0m10:40:03.523932 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m10:40:03.530850 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m10:40:03.531640 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:40:03.532336 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m10:40:05.209415 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:03f56b55-06cf-4d5a-8b32-b58e8051675d&page=queryresults
[0m10:40:07.172061 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.64s]
[0m10:40:07.172900 [info ] [MainThread]: 
[0m10:40:07.173765 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:40:07.174372 [info ] [MainThread]: 
[0m10:40:07.179269 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m10:40:07.180350 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m10:40:07.181256 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m10:40:07.181896 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m10:40:07.188242 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m10:40:07.191705 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m10:40:07.222238 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:40:08.817431 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m10:40:08.820948 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            paid_total < unlock_price AND amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN paid_total >= unlock_price THEN Null
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
    paid_total_excl_dp / unlock_price_excl_dp as perc_paid,
  FROM join_wo_statuses
),

usage_rates as (
    SELECT 
        *,
        AVG(
            IF(reporting_date_status in ('ENABLED', 'UNLOCKED'), 1, 0)
        ) OVER(
            PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN 180 PRECEDING AND CURRENT ROW
        ) as usage_rate_last_180d,
    FROM final_kpis
),

segmentations as (
    SELECT 
        *,
        CASE 
            WHEN usage_rate_last_180d >= 0.95 THEN 'A'
            WHEN usage_rate_last_180d >= 0.90 THEN 'B'
            WHEN usage_rate_last_180d >= 0.60 THEN 'C'
            WHEN usage_rate_last_180d < 0.60  THEN 'D'
        END as account_segmentation,
    FROM usage_rates
)

SELECT * FROM segmentations
    );
  
[0m10:40:09.841933 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:08e9a83b-f46d-4238-8c5f-ddffdcce1860&page=queryresults
[0m10:40:38.151824 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73524e60-5bc3-4691-a122-98ac7376483d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80b5da6a0>]}
[0m10:40:38.153937 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 511.5 MiB processed)[0m in 30.97s]
[0m10:40:38.155055 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m10:40:38.156747 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:40:38.157233 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m10:40:38.157727 [info ] [MainThread]: 
[0m10:40:38.158355 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 41.20 seconds (41.20s).
[0m10:40:38.159469 [debug] [MainThread]: Command end result
[0m10:40:38.214186 [info ] [MainThread]: 
[0m10:40:38.214918 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:40:38.215407 [info ] [MainThread]: 
[0m10:40:38.216035 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:40:38.216867 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 45.514275, "process_user_time": 5.046035, "process_kernel_time": 0.919359, "process_mem_max_rss": "226574336", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:40:38.217723 [debug] [MainThread]: Command `dbt run` succeeded at 10:40:38.217579 after 45.52 seconds
[0m10:40:38.218281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc803a60520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8069388e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8073700d0>]}
[0m10:40:38.218805 [debug] [MainThread]: Flushing usage events
[0m10:41:43.565246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f912d49d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9131af1c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9131af1130>]}


============================== 10:41:43.570358 | 6d6c0a65-9c11-43b6-9ed7-08e8c9652560 ==============================
[0m10:41:43.570358 [info ] [MainThread]: Running with dbt=1.8.8
[0m10:41:43.571461 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'write_json': 'True', 'warn_error': 'None', 'fail_fast': 'False', 'partial_parse': 'True', 'printer_width': '80', 'target_path': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'profiles_dir': '/Users/david/.dbt', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'no_print': 'None', 'static_parser': 'True', 'introspect': 'True', 'quiet': 'False', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run --select accounts_history_advanced', 'empty': 'False', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True'}
[0m10:41:47.323088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6d6c0a65-9c11-43b6-9ed7-08e8c9652560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9135e5bfa0>]}
[0m10:41:47.383318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6d6c0a65-9c11-43b6-9ed7-08e8c9652560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9136569280>]}
[0m10:41:47.384018 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:41:47.414217 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m10:41:47.701665 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:41:47.702121 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:41:47.764966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6d6c0a65-9c11-43b6-9ed7-08e8c9652560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f913718a130>]}
[0m10:41:47.916980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6d6c0a65-9c11-43b6-9ed7-08e8c9652560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91371a9520>]}
[0m10:41:47.917796 [info ] [MainThread]: Found 19 models, 3 seeds, 1 operation, 480 macros
[0m10:41:47.918301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6d6c0a65-9c11-43b6-9ed7-08e8c9652560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91371a28b0>]}
[0m10:41:47.919958 [info ] [MainThread]: 
[0m10:41:47.920677 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:41:47.921695 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m10:41:47.922169 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:41:52.749058 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m10:41:52.750100 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:41:54.380763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6d6c0a65-9c11-43b6-9ed7-08e8c9652560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f913655f5b0>]}
[0m10:41:54.381423 [info ] [MainThread]: 
[0m10:41:54.381846 [info ] [MainThread]: Running 1 on-run-start hook
[0m10:41:54.397459 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m10:41:54.402765 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m10:41:54.403591 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:41:54.404274 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m10:41:56.037867 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:72d8e4e8-2b48-49c5-b7c6-cd7576e71ab3&page=queryresults
[0m10:41:57.857996 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.45s]
[0m10:41:57.858770 [info ] [MainThread]: 
[0m10:41:57.859627 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:41:57.860291 [info ] [MainThread]: 
[0m10:41:57.864781 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m10:41:57.865720 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.accounts_history_advanced ............ [RUN]
[0m10:41:57.866584 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.accounts_history_advanced)
[0m10:41:57.867269 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m10:41:57.873685 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m10:41:57.875037 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m10:41:57.903766 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:41:59.418934 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m10:41:59.420492 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            paid_total < unlock_price AND amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN paid_total >= unlock_price THEN Null
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
    paid_total_excl_dp / unlock_price_excl_dp as perc_paid,
  FROM join_wo_statuses
),

usage_rates as (
    SELECT 
        *,
        AVG(
            IF(reporting_date_status in ('ENABLED', 'UNLOCKED'), 1, 0)
        ) OVER(
            PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN 180 PRECEDING AND CURRENT ROW
        ) as usage_rate_last_180d,
    FROM final_kpis
),

segmentations as (
    SELECT 
        *,
        CASE 
            WHEN usage_rate_last_180d >= 0.95 THEN 'A'
            WHEN usage_rate_last_180d >= 0.90 THEN 'B'
            WHEN usage_rate_last_180d >= 0.60 THEN 'C'
            WHEN usage_rate_last_180d < 0.60  THEN 'D'
        END as account_segmentation,
        
        reporting_date_status in ('ENABLED', 'DISABLED') as portfolio_scope,
        
    FROM usage_rates
)

SELECT * FROM segmentations
    );
  
[0m10:42:00.461246 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:512d33c5-ffa4-461e-a2e9-9c56f0e8c092&page=queryresults
[0m10:42:24.566595 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d6c0a65-9c11-43b6-9ed7-08e8c9652560', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9135dda730>]}
[0m10:42:24.568512 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.accounts_history_advanced ....... [[32mCREATE TABLE (3.4m rows, 511.5 MiB processed)[0m in 26.70s]
[0m10:42:24.569446 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m10:42:24.570930 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:42:24.571364 [debug] [MainThread]: Connection 'model.creditrisk.accounts_history_advanced' was properly closed.
[0m10:42:24.571819 [info ] [MainThread]: 
[0m10:42:24.572297 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 36.65 seconds (36.65s).
[0m10:42:24.573221 [debug] [MainThread]: Command end result
[0m10:42:24.621426 [info ] [MainThread]: 
[0m10:42:24.622164 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:42:24.622640 [info ] [MainThread]: 
[0m10:42:24.623143 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:42:24.623887 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 41.13749, "process_user_time": 4.952174, "process_kernel_time": 0.950905, "process_mem_max_rss": "227229696", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:42:24.624679 [debug] [MainThread]: Command `dbt run` succeeded at 10:42:24.624541 after 41.14 seconds
[0m10:42:24.625216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f912d49d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f913715bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f912d799700>]}
[0m10:42:24.625723 [debug] [MainThread]: Flushing usage events
[0m11:04:53.018169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dc2960550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dc6271d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dc6271400>]}


============================== 11:04:53.022449 | 6f95b234-9e78-4cc9-af2a-9f2491f2b2cf ==============================
[0m11:04:53.022449 [info ] [MainThread]: Running with dbt=1.8.8
[0m11:04:53.023316 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'printer_width': '80', 'empty': 'False', 'write_json': 'True', 'static_parser': 'True', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/Users/david/.dbt', 'invocation_command': 'dbt run --select predict_ecls', 'target_path': 'None', 'warn_error': 'None', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'fail_fast': 'False', 'no_print': 'None', 'introspect': 'True', 'version_check': 'True', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'partial_parse': 'True', 'cache_selected_only': 'False', 'quiet': 'False', 'log_cache_events': 'False'}
[0m11:04:56.564503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f95b234-9e78-4cc9-af2a-9f2491f2b2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dc9ccca90>]}
[0m11:04:56.622889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6f95b234-9e78-4cc9-af2a-9f2491f2b2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dca49d250>]}
[0m11:04:56.623594 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:04:56.648564 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m11:04:56.960347 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:04:56.960787 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:04:57.021455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6f95b234-9e78-4cc9-af2a-9f2491f2b2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dca88a130>]}
[0m11:04:57.176827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6f95b234-9e78-4cc9-af2a-9f2491f2b2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dca865be0>]}
[0m11:04:57.178033 [info ] [MainThread]: Found 19 models, 3 seeds, 1 operation, 480 macros
[0m11:04:57.178812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f95b234-9e78-4cc9-af2a-9f2491f2b2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dca5f78e0>]}
[0m11:04:57.181310 [info ] [MainThread]: 
[0m11:04:57.182411 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:04:57.183756 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m11:04:57.184423 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:05:01.216481 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m11:05:01.218077 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:05:01.848777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f95b234-9e78-4cc9-af2a-9f2491f2b2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dca483490>]}
[0m11:05:01.850332 [info ] [MainThread]: 
[0m11:05:01.851326 [info ] [MainThread]: Running 1 on-run-start hook
[0m11:05:01.874395 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m11:05:01.883455 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m11:05:01.884609 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:05:01.886104 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m11:05:02.552589 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:c85fae13-368d-4d3f-b2ad-b205323b820d&page=queryresults
[0m11:05:04.051291 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 2.17s]
[0m11:05:04.052039 [info ] [MainThread]: 
[0m11:05:04.052782 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:05:04.053273 [info ] [MainThread]: 
[0m11:05:04.056991 [debug] [Thread-1  ]: Began running node model.creditrisk.predict_ecls
[0m11:05:04.057964 [info ] [Thread-1  ]: 1 of 1 START sql table model oscreditrisk.predict_ecls ......................... [RUN]
[0m11:05:04.058684 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.predict_ecls)
[0m11:05:04.059306 [debug] [Thread-1  ]: Began compiling node model.creditrisk.predict_ecls
[0m11:05:04.066368 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.predict_ecls"
[0m11:05:04.067588 [debug] [Thread-1  ]: Began executing node model.creditrisk.predict_ecls
[0m11:05:04.152739 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.predict_ecls"
[0m11:05:04.154045 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:05:04.154977 [debug] [Thread-1  ]: On model.creditrisk.predict_ecls: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.predict_ecls"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`predict_ecls`
      
    partition by timestamp_trunc(reporting_date, day)
    cluster by account_id

    OPTIONS()
    as (
      

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

repo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`repossession_valuation_parameters`
),

proba_churn_repayment as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`
),

proba_churn_immediate as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`probability_of_defaulting`
),

batch_to_compute as (
    SELECT
        account_id, 
        reporting_date,
        reporting_day,
        portfolio_scope,
        days_disabled,
        perc_paid,
        IF(perc_paid < 0.1, '0. At registration', account_segmentation) as account_segmentation, 
    FROM accounts_history
    WHERE portfolio_scope
),

join_with_churn_model as (
    SELECT     
        account_id,
        reporting_date,
        SUM(proba_churn_repayment.p_churn_incr)        as p_churn,
        SUM(proba_churn_repayment.r_churn_incr)        as r_churn,
    FROM batch_to_compute
    LEFT JOIN proba_churn_repayment
    ON 
        batch_to_compute.account_segmentation = proba_churn_repayment.account_segmentation AND
        batch_to_compute.perc_paid < proba_churn_repayment.perc_paid_chunk_end
    GROUP BY ALL
),

join_with_immediate_churn_model as (
    SELECT 
        account_id, 
        reporting_date,
        COALESCE(proba_churn_immediate.immediate_prob_churn, 0) as immediate_prob_churn,
        COALESCE(proba_churn_immediate.immediate_prob_churn, 0) * (1 - perc_paid) as immediate_loss,
    FROM batch_to_compute
    LEFT JOIN proba_churn_immediate
    ON  
        batch_to_compute.perc_paid >= proba_churn_immediate.perc_paid_bucket_start AND 
        batch_to_compute.perc_paid < proba_churn_immediate.perc_paid_bucket_end AND 
        batch_to_compute.days_disabled = proba_churn_immediate.days_since_cutoff
),

joint_together as (
    SELECT * FROM batch_to_compute
    LEFT JOIN join_with_churn_model USING(account_id, reporting_date)
    LEFT JOIN join_with_immediate_churn_model USING(account_id, reporting_date)
    CROSS JOIN repo
),

combine_outputs_1 as (
    SELECT 
        account_id,
        reporting_date,
        reporting_day, 
        days_disabled,
        perc_paid,
        account_segmentation,

        p_churn as repayment_prob_churn,
        r_churn as repayment_loss,
        p_churn * probability_of_repossession * repossession_value as repayment_recoveries,
        
        immediate_prob_churn,
        immediate_loss,
        immediate_prob_churn * probability_of_repossession * repossession_value as immediate_recoveries,

    FROM joint_together
),

combine_outputs_2 as (
    SELECT 
        *,
        IF(immediate_loss - immediate_recoveries < 0, 0, immediate_loss - immediate_recoveries) as immediate_ecl,
        IF(repayment_loss - repayment_recoveries < 0, 0, repayment_loss - repayment_recoveries) as repayment_ecl,
    FROM combine_outputs_1
),

combine_outputs_3 as (
    SELECT 
        *,
        immediate_loss + (1 - immediate_prob_churn) * repayment_loss as total_loss,
        immediate_prob_churn + (1 - immediate_prob_churn) * repayment_prob_churn as total_pchurn,
        immediate_ecl + (1 - immediate_prob_churn) * repayment_ecl as total_ecl,
    FROM combine_outputs_2
)

SELECT * FROM combine_outputs_3
    );
  
[0m11:05:05.278619 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:9e2ab2e9-edec-4d8d-ac92-415cacdcf389&page=queryresults
[0m11:05:44.517301 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f95b234-9e78-4cc9-af2a-9f2491f2b2cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dc9cda6d0>]}
[0m11:05:44.518370 [info ] [Thread-1  ]: 1 of 1 OK created sql table model oscreditrisk.predict_ecls .................... [[32mCREATE TABLE (2.4m rows, 122.1 MiB processed)[0m in 40.46s]
[0m11:05:44.519377 [debug] [Thread-1  ]: Finished running node model.creditrisk.predict_ecls
[0m11:05:44.521026 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:05:44.521495 [debug] [MainThread]: Connection 'model.creditrisk.predict_ecls' was properly closed.
[0m11:05:44.521982 [info ] [MainThread]: 
[0m11:05:44.522507 [info ] [MainThread]: Finished running 1 table model, 1 project hook in 0 hours 0 minutes and 47.34 seconds (47.34s).
[0m11:05:44.523505 [debug] [MainThread]: Command end result
[0m11:05:44.575196 [info ] [MainThread]: 
[0m11:05:44.575956 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:05:44.576460 [info ] [MainThread]: 
[0m11:05:44.576999 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:05:44.577779 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 51.638817, "process_user_time": 5.233774, "process_kernel_time": 0.808759, "process_mem_max_rss": "226701312", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m11:05:44.578652 [debug] [MainThread]: Command `dbt run` succeeded at 11:05:44.578507 after 51.64 seconds
[0m11:05:44.579234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dc2960550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dc61fa8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dca8c0430>]}
[0m11:05:44.579784 [debug] [MainThread]: Flushing usage events
[0m11:06:17.179978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa06d332580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0709afbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0709af1f0>]}


============================== 11:06:17.183884 | 874f6deb-455e-41a6-9dd9-d22bc709be55 ==============================
[0m11:06:17.183884 [info ] [MainThread]: Running with dbt=1.8.8
[0m11:06:17.184804 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/david/.dbt', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'fail_fast': 'False', 'empty': 'False', 'use_colors': 'True', 'introspect': 'True', 'write_json': 'True', 'log_format': 'default', 'static_parser': 'True', 'printer_width': '80', 'version_check': 'True', 'partial_parse': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run', 'log_path': '/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs', 'no_print': 'None', 'warn_error': 'None', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:06:20.727037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa06f506970>]}
[0m11:06:20.823603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa074c53d00>]}
[0m11:06:20.824822 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:06:20.859143 [debug] [MainThread]: checksum: ec53e341a936509427e16df1c646386a84befec52c1957e3f4359fbc36fc93f5, vars: {}, profile: , target: , version: 1.8.8
[0m11:06:21.265102 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:06:21.265742 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:06:21.362071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa075889130>]}
[0m11:06:21.590462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07589ffd0>]}
[0m11:06:21.593065 [info ] [MainThread]: Found 19 models, 3 seeds, 1 operation, 480 macros
[0m11:06:21.594148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa06d632d00>]}
[0m11:06:21.598151 [info ] [MainThread]: 
[0m11:06:21.599536 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:06:21.609426 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_steam-outlet-209412'
[0m11:06:21.610242 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:06:26.184561 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_steam-outlet-209412, now list_steam-outlet-209412_oscreditrisk)
[0m11:06:26.185564 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:06:27.600325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa06d2c0be0>]}
[0m11:06:27.601302 [info ] [MainThread]: 
[0m11:06:27.601927 [info ] [MainThread]: Running 1 on-run-start hook
[0m11:06:27.623015 [debug] [MainThread]: Writing injected SQL for node "operation.creditrisk.creditrisk-on-run-start-0"
[0m11:06:27.633884 [info ] [MainThread]: 1 of 1 START hook: creditrisk.on-run-start.0 ................................... [RUN]
[0m11:06:27.634930 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:06:27.635760 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "connection_name": "master"} */


CREATE SCHEMA IF NOT EXISTS oscreditrisk;

CREATE OR REPLACE FUNCTION oscreditrisk.payment_linearization(
  payment_amounts ARRAY<FLOAT64>,
  daily_rate ARRAY<FLOAT64>,
  reporting_dates ARRAY<STRING>
)

RETURNS ARRAY<FLOAT64>
LANGUAGE js AS """
    let result = [];
    let balance = 0.0;

    for (let i = 0; i < payment_amounts.length; i++) {
        if (payment_amounts[i] > 0) {
            // Add payment to balance
            balance += payment_amounts[i];
        }

        if (balance >= daily_rate[i]) {
            result.push(daily_rate[i]);
            balance = balance - daily_rate[i];
        }
        else if (balance > 0.0) {
            result.push(balance);
            balance = 0.0
        } 
        else {
            // Push zero for days with no payment distribution
            result.push(0.0);
            balance = 0.0
        }
    }
    return result;
""";
  

[0m11:06:28.988825 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:6f32f7ec-edcc-49bc-91f4-8f825c54532f&page=queryresults
[0m11:06:30.891365 [info ] [MainThread]: 1 of 1 OK hook: creditrisk.on-run-start.0 ...................................... [[32mSCRIPT (0 processed)[0m in 3.26s]
[0m11:06:30.892234 [info ] [MainThread]: 
[0m11:06:30.893097 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:06:30.893709 [info ] [MainThread]: 
[0m11:06:30.900277 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_accounts
[0m11:06:30.901245 [info ] [Thread-1  ]: 1 of 19 START sql view model oscreditrisk.cleaned_accounts ..................... [RUN]
[0m11:06:30.902007 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_steam-outlet-209412_oscreditrisk, now model.creditrisk.cleaned_accounts)
[0m11:06:30.902620 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_accounts
[0m11:06:30.907311 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_accounts"
[0m11:06:30.961418 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_accounts
[0m11:06:31.031301 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_accounts"
[0m11:06:31.034590 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:06:31.035747 [debug] [Thread-1  ]: On model.creditrisk.cleaned_accounts: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_accounts"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH accounts as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`
)

SELECT 
  account_id, 
  CAST(registration_date            AS TIMESTAMP)     as registration_date, 
  CAST(unlock_price                 AS FLOAT64)       as unlock_price, 
  CAST(down_payment                 AS FLOAT64)       as down_payment, 
  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, 
  CAST(daily_rate                   AS FLOAT64)       as daily_rate, 
FROM accounts;


[0m11:06:32.552317 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:476df677-b4a4-4d11-913c-2b8d697b5075&page=queryresults
[0m11:06:33.720687 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0744d46a0>]}
[0m11:06:33.721886 [info ] [Thread-1  ]: 1 of 19 OK created sql view model oscreditrisk.cleaned_accounts ................ [[32mCREATE VIEW (0 processed)[0m in 2.82s]
[0m11:06:33.723075 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_accounts
[0m11:06:33.723852 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_payments
[0m11:06:33.724840 [info ] [Thread-1  ]: 2 of 19 START sql view model oscreditrisk.cleaned_payments ..................... [RUN]
[0m11:06:33.725934 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_accounts, now model.creditrisk.cleaned_payments)
[0m11:06:33.726943 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_payments
[0m11:06:33.731855 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_payments"
[0m11:06:33.733315 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_payments
[0m11:06:33.737541 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_payments"
[0m11:06:33.738572 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:06:33.739321 [debug] [Thread-1  ]: On model.creditrisk.cleaned_payments: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_payments"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
  OPTIONS()
  as /*
    This transformations is just casting fields in the right format. 
    In practice, you may add here filtering steps to reduce your data to relevant records.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`
)

SELECT 
  account_id,
  CAST(down_payment             AS BOOLEAN)         as down_payment,
  CAST(payment_effective_date   AS TIMESTAMP)       as payment_effective_date,
  CAST(amount                   AS FLOAT64)         as amount,
FROM payments;


[0m11:06:35.284085 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:32bb655c-a164-4e74-bc7e-7c2521858cfc&page=queryresults
[0m11:06:36.532045 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa076263490>]}
[0m11:06:36.532964 [info ] [Thread-1  ]: 2 of 19 OK created sql view model oscreditrisk.cleaned_payments ................ [[32mCREATE VIEW (0 processed)[0m in 2.81s]
[0m11:06:36.534379 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_payments
[0m11:06:36.535121 [debug] [Thread-1  ]: Began running node model.creditrisk.cleaned_write_offs
[0m11:06:36.535823 [info ] [Thread-1  ]: 3 of 19 START sql view model oscreditrisk.cleaned_write_offs ................... [RUN]
[0m11:06:36.536665 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_payments, now model.creditrisk.cleaned_write_offs)
[0m11:06:36.539733 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cleaned_write_offs
[0m11:06:36.545699 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cleaned_write_offs"
[0m11:06:36.547454 [debug] [Thread-1  ]: Began executing node model.creditrisk.cleaned_write_offs
[0m11:06:36.552279 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cleaned_write_offs"
[0m11:06:36.553431 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:06:36.554219 [debug] [Thread-1  ]: On model.creditrisk.cleaned_write_offs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cleaned_write_offs"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
  OPTIONS()
  as WITH wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_write_offs`
)

-- Deduplication step in case there are several write offs or repossessions on the same account
SELECT 
    account_id,
    write_off_status,
    MIN(CAST(changed_date AS TIMESTAMP)) as changed_date, 
FROM wo
GROUP BY ALL;


[0m11:06:38.040820 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:cfc33fc5-4dbc-4110-88bf-ba3de3c7ee93&page=queryresults
[0m11:06:39.278632 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07640c6d0>]}
[0m11:06:39.279942 [info ] [Thread-1  ]: 3 of 19 OK created sql view model oscreditrisk.cleaned_write_offs .............. [[32mCREATE VIEW (0 processed)[0m in 2.74s]
[0m11:06:39.281405 [debug] [Thread-1  ]: Finished running node model.creditrisk.cleaned_write_offs
[0m11:06:39.282575 [debug] [Thread-1  ]: Began running node model.creditrisk.repossession_valuation_parameters
[0m11:06:39.283726 [info ] [Thread-1  ]: 4 of 19 START sql view model oscreditrisk.repossession_valuation_parameters .... [RUN]
[0m11:06:39.284511 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cleaned_write_offs, now model.creditrisk.repossession_valuation_parameters)
[0m11:06:39.285097 [debug] [Thread-1  ]: Began compiling node model.creditrisk.repossession_valuation_parameters
[0m11:06:39.288495 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.repossession_valuation_parameters"
[0m11:06:39.291392 [debug] [Thread-1  ]: Began executing node model.creditrisk.repossession_valuation_parameters
[0m11:06:39.297457 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.repossession_valuation_parameters"
[0m11:06:39.299045 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:06:39.300128 [debug] [Thread-1  ]: On model.creditrisk.repossession_valuation_parameters: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.repossession_valuation_parameters"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`repossession_valuation_parameters`
  OPTIONS()
  as /*
    This part is drastically simplified here. 
    Analyses should be performed to determine the right value of KPIs. 
    Here we are using these values as placeholders to show how they fit in the global model recombination.
*/

SELECT 
    0.6 as probability_of_repossession,
    0.2 as repossession_value, -- expressed here as a percentage of initial unlock price.;


[0m11:06:40.786690 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:bfdd6fc2-92b2-44c1-a488-9ba7ecccabeb&page=queryresults
[0m11:06:41.925135 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa076409670>]}
[0m11:06:41.925969 [info ] [Thread-1  ]: 4 of 19 OK created sql view model oscreditrisk.repossession_valuation_parameters  [[32mCREATE VIEW (0 processed)[0m in 2.64s]
[0m11:06:41.926824 [debug] [Thread-1  ]: Finished running node model.creditrisk.repossession_valuation_parameters
[0m11:06:41.927451 [debug] [Thread-1  ]: Began running node model.creditrisk.date_spine
[0m11:06:41.928199 [info ] [Thread-1  ]: 5 of 19 START sql table model oscreditrisk.date_spine .......................... [RUN]
[0m11:06:41.928826 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.repossession_valuation_parameters, now model.creditrisk.date_spine)
[0m11:06:41.929333 [debug] [Thread-1  ]: Began compiling node model.creditrisk.date_spine
[0m11:06:41.933226 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.date_spine"
[0m11:06:41.935026 [debug] [Thread-1  ]: Began executing node model.creditrisk.date_spine
[0m11:06:41.952648 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:06:43.508042 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.date_spine"
[0m11:06:43.509079 [debug] [Thread-1  ]: On model.creditrisk.date_spine: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.date_spine"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`date_spine`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating a dataset containing one row for each day betwee : 
    - The first day you opened an account
    - Today. With artificial data here we consider today being the day after we received the last payment.
*/

WITH payments as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

min_max_dates as (
    SELECT 
        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,
        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,
    FROM payments
)

SELECT
    CAST(
        TIMESTAMP_ADD(
            (SELECT min_date FROM min_max_dates), 
            INTERVAL n DAY
        ) AS TIMESTAMP
    ) AS reporting_date,
FROM 
  UNNEST(
    GENERATE_ARRAY(
        0, 
        DATE_DIFF(
            (SELECT max_date FROM min_max_dates),
            (SELECT min_date FROM min_max_dates),
            DAY
        )
    )
) AS n
    );
  
[0m11:06:44.492728 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b58d1a64-de98-469a-96e6-cc6a2142a27a&page=queryresults
[0m11:06:48.094885 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0762b3fa0>]}
[0m11:06:48.096022 [info ] [Thread-1  ]: 5 of 19 OK created sql table model oscreditrisk.date_spine ..................... [[32mCREATE TABLE (1.1k rows, 3.4 MiB processed)[0m in 6.17s]
[0m11:06:48.097166 [debug] [Thread-1  ]: Finished running node model.creditrisk.date_spine
[0m11:06:48.098467 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_beginner
[0m11:06:48.099424 [info ] [Thread-1  ]: 6 of 19 START sql table model oscreditrisk.accounts_history_beginner ........... [RUN]
[0m11:06:48.100259 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.date_spine, now model.creditrisk.accounts_history_beginner)
[0m11:06:48.100945 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_beginner
[0m11:06:48.107207 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_beginner"
[0m11:06:48.108814 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_beginner
[0m11:06:48.120282 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:06:50.129926 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_beginner"
[0m11:06:50.131949 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_beginner"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the first version of the core dataset (beginner version). 
    It is essentially : 
    - Joining the accounts dataset with a date spine for the target granuarity
    - Grouping the payment by day, and joining them to the accounts history
    - Calculating cumulated sums to describe the cumulated amount paid, and a few other useful fields
*/

WITH accounts as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`
),

payments as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`
),

date_spine as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

accounts_with_spine as (
  SELECT 
    *,
    TIMESTAMP_DIFF(reporting_date, registration_date, DAY) + 1 as reporting_day,
  FROM accounts
  LEFT JOIN date_spine
  ON accounts.registration_date <= date_spine.reporting_date
),

payments_grouped_by_day as (
  SELECT 
    account_id,
    
    DATE_ADD(
      DATE_TRUNC(payment_effective_date, DAY), 
      INTERVAL 1 DAY
    ) as reporting_date,

    SUM(amount) as amount,
    SUM(
      IF(not down_payment, amount, 0)
    ) as amount_excl_dp,

  FROM payments
  GROUP BY ALL
),

joint as (
  SELECT 
    * EXCEPT(amount, amount_excl_dp),
    COALESCE(amount,          0) as amount,
    COALESCE(amount_excl_dp,  0) as amount_excl_dp,
  FROM accounts_with_spine 
  LEFT JOIN payments_grouped_by_day 
  USING(account_id, reporting_date)
),

calc_paid_total as (
  SELECT 
    *,
    SUM(amount)         OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total,
    SUM(amount_excl_dp) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_excl_dp,
    
    unlock_price - down_payment as unlock_price_excl_dp,

    SAFE_DIVIDE(unlock_price - down_payment, daily_rate) + down_payment_days_included as nominal_term,
    SAFE_DIVIDE(unlock_price - down_payment, daily_rate)                              as nominal_term_excl_dp,

    MAX(reporting_day) OVER(PARTITION BY account_id) as account_age_in_days,
    GREATEST(
            0,
            MAX(reporting_day - down_payment_days_included) OVER(PARTITION BY account_id)
    ) as account_age_excl_dp_in_days,

    DATE_TRUNC(registration_date, MONTH) as cohort_month,
    DATE_TRUNC(registration_date, QUARTER) as cohort_quarter,
    DATE_TRUNC(registration_date, YEAR) as cohort_year,

  FROM joint
)

SELECT * FROM calc_paid_total
    );
  
[0m11:06:51.235884 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:47dd1bac-8cdc-49be-8fa0-53d9b123f815&page=queryresults
[0m11:07:00.332592 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07645e0d0>]}
[0m11:07:00.333675 [info ] [Thread-1  ]: 6 of 19 OK created sql table model oscreditrisk.accounts_history_beginner ...... [[32mCREATE TABLE (3.4m rows, 6.2 MiB processed)[0m in 12.23s]
[0m11:07:00.334669 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_beginner
[0m11:07:00.335772 [debug] [Thread-1  ]: Began running node model.creditrisk.accounts_history_advanced
[0m11:07:00.336611 [info ] [Thread-1  ]: 7 of 19 START sql table model oscreditrisk.accounts_history_advanced ........... [RUN]
[0m11:07:00.337530 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_beginner, now model.creditrisk.accounts_history_advanced)
[0m11:07:00.338136 [debug] [Thread-1  ]: Began compiling node model.creditrisk.accounts_history_advanced
[0m11:07:00.344088 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.accounts_history_advanced"
[0m11:07:00.345265 [debug] [Thread-1  ]: Began executing node model.creditrisk.accounts_history_advanced
[0m11:07:00.349273 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:01.932442 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.accounts_history_advanced"
[0m11:07:01.934115 [debug] [Thread-1  ]: On model.creditrisk.accounts_history_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.accounts_history_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is generating the second version of the core dataset (advanced version)
    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. 
    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

wo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`
),

additional_kpis as (
    SELECT 
        *,
        
        CASE 
            WHEN reporting_day <= down_payment_days_included THEN Null
            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total
            ELSE amount_excl_dp
        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.

        CASE  
            WHEN reporting_day < down_payment_days_included THEN Null
            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included
        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses

    FROM accounts_history
),

-- Preparing the data for the UDF (consuming arrays)
prepared_for_udf as (
    SELECT
        account_id,
        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,
        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,
        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,
    FROM additional_kpis
    GROUP BY ALL
),

-- applying the UDF on prepared data format
apply_udf AS (
    SELECT 
        *,
        oscreditrisk.payment_linearization(
        prepared_for_udf.payment_amounts, 
        prepared_for_udf.daily_rates, 
        prepared_for_udf.casted_reporting_dates
        ) as payment_amount_lin_excl_dp
    FROM prepared_for_udf
),

-- Expanding the results before joining them back
expand_udf_result AS (
    SELECT
        account_id,
        CAST(reporting_date AS TIMESTAMP) as reporting_date,
        amount_lin
    FROM
        apply_udf,
        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos
    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos
    ON pos = val_pos
),

join_back_on_dataset as (
    SELECT 
        *,
        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,
        IF(
            paid_total < unlock_price AND amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,
            reporting_date,
            Null
        ) as last_disablement,
    FROM additional_kpis 
    LEFT JOIN expand_udf_result USING(account_id, reporting_date)
),

join_wo_statuses as (
    SELECT 
        join_back_on_dataset.*,
        wo.write_off_status,
    FROM join_back_on_dataset
    LEFT JOIN wo 
    ON 
        wo.account_id = join_back_on_dataset.account_id AND 
        wo.changed_date <= join_back_on_dataset.reporting_date
),

-- As a last step, use this information to calculate useful fields: status and number of days disabled.
final_kpis as (
  SELECT 
    * EXCEPT(write_off_status),
    CASE 
        WHEN write_off_status IS NOT NULL THEN write_off_status
        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'
        WHEN paid_total >= unlock_price THEN 'UNLOCKED'
        WHEN amount_lin > 0   THEN 'ENABLED'
        WHEN amount_lin <= 0  THEN 'DISABLED'
    END as reporting_date_status,
    CASE 
        WHEN paid_total >= unlock_price THEN Null
        WHEN amount_lin = 0 
        THEN DATE_DIFF(
            reporting_date, 
            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),
            DAY
        ) 
    END as days_disabled,
    paid_total_excl_dp / unlock_price_excl_dp as perc_paid,
  FROM join_wo_statuses
),

usage_rates as (
    SELECT 
        *,
        AVG(
            IF(reporting_date_status in ('ENABLED', 'UNLOCKED'), 1, 0)
        ) OVER(
            PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN 180 PRECEDING AND CURRENT ROW
        ) as usage_rate_last_180d,
    FROM final_kpis
),

segmentations as (
    SELECT 
        *,
        CASE 
            WHEN usage_rate_last_180d >= 0.95 THEN 'A'
            WHEN usage_rate_last_180d >= 0.90 THEN 'B'
            WHEN usage_rate_last_180d >= 0.60 THEN 'C'
            WHEN usage_rate_last_180d < 0.60  THEN 'D'
        END as account_segmentation,
        
        reporting_date_status in ('ENABLED', 'DISABLED') as portfolio_scope,
        
    FROM usage_rates
)

SELECT * FROM segmentations
    );
  
[0m11:07:03.011227 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:9d7534b9-cb93-4680-a88e-43bee5408d7f&page=queryresults
[0m11:07:22.870945 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa076454ac0>]}
[0m11:07:22.872205 [info ] [Thread-1  ]: 7 of 19 OK created sql table model oscreditrisk.accounts_history_advanced ...... [[32mCREATE TABLE (3.4m rows, 511.5 MiB processed)[0m in 22.53s]
[0m11:07:22.873351 [debug] [Thread-1  ]: Finished running node model.creditrisk.accounts_history_advanced
[0m11:07:22.874197 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_beginner
[0m11:07:22.875190 [info ] [Thread-1  ]: 8 of 19 START sql table model oscreditrisk.cohorts_beginner .................... [RUN]
[0m11:07:22.876057 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.accounts_history_advanced, now model.creditrisk.cohorts_beginner)
[0m11:07:22.876699 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_beginner
[0m11:07:22.881299 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_beginner"
[0m11:07:22.882474 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_beginner
[0m11:07:22.886724 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:24.381058 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_beginner"
[0m11:07:24.382457 [debug] [Thread-1  ]: On model.creditrisk.cohorts_beginner: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_beginner"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`cohorts_beginner`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the beginner core dataset. 
    Produces information on raw payments only.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`
),

filtered as (
    SELECT 
        * 
    FROM accounts_history
    -- optional : downsampling results to 1 point every 30 days. Often sufficient.
    WHERE  MOD(reporting_day, 30) = 1 
    -- optional : removing the end of cohorts where calculation is not representative of the whole cohort
    QUALIFY reporting_day <= MIN(account_age_in_days) OVER(PARTITION BY cohort_month) 
)

-- Aggregating results on a cohort level
SELECT 
    cohort_month,
    reporting_day,
    SUM(paid_total) / SUM(unlock_price) as amount_paid_percent,
FROM filtered
GROUP BY ALL
    );
  
[0m11:07:25.246109 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:8df746d8-eae2-4ba9-a0f7-9b93165d9cc0&page=queryresults
[0m11:07:28.978354 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa06fab3400>]}
[0m11:07:28.979337 [info ] [Thread-1  ]: 8 of 19 OK created sql table model oscreditrisk.cohorts_beginner ............... [[32mCREATE TABLE (666.0 rows, 127.9 MiB processed)[0m in 6.10s]
[0m11:07:28.980546 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_beginner
[0m11:07:28.982622 [debug] [Thread-1  ]: Began running node model.creditrisk.cohorts_advanced
[0m11:07:28.983582 [info ] [Thread-1  ]: 9 of 19 START sql table model oscreditrisk.cohorts_advanced .................... [RUN]
[0m11:07:28.984493 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cohorts_beginner, now model.creditrisk.cohorts_advanced)
[0m11:07:28.985316 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohorts_advanced
[0m11:07:28.996096 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohorts_advanced"
[0m11:07:28.998447 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohorts_advanced
[0m11:07:29.002704 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:30.497461 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohorts_advanced"
[0m11:07:30.498924 [debug] [Thread-1  ]: On model.creditrisk.cohorts_advanced: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohorts_advanced"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`cohorts_advanced`
      
    
    

    OPTIONS()
    as (
      /*
    This transformations is aggregating on a cohort level for visualisation.
    It uses the advanced core dataset.
    Produces information on linearized payments and with a term elapsed in % excluding downpayment.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

perc_elapsed as (
    SELECT 
        *,
        SAFE_DIVIDE(reporting_day_excl_dp, nominal_term_excl_dp) as perc_term_elapsed,
    FROM accounts_history
),

approximating as (
    SELECT
        *,
        -- Flooring the perc paid to the next 5% (we could choose another grain)
        FLOOR(perc_term_elapsed * 20) * 5 as perc_term_elapsed_approx,
    FROM perc_elapsed
),

downsampling as (
    SELECT 
        * 
    FROM approximating
    -- Optional : limit the time horizon to 200% of contractual term. Often sufficient.
    WHERE perc_term_elapsed_approx <= 200
    -- Ensure the dataset ends up with only one row per grain on % of contractual term
    QUALIFY ROW_NUMBER() OVER(PARTITION BY account_id, CAST(perc_term_elapsed_approx AS STRING) ORDER BY reporting_day_excl_dp) = 1
),

counting_accounts as (
  SELECT 
    *,
    COUNT(account_id) OVER (PARTITION BY cohort_month, CAST(perc_term_elapsed_approx AS INT64)) as cnt_accounts,
  FROM downsampling
),

filtering as (
    SELECT 
        *,
    FROM counting_accounts
    -- optional - removes the end of cohorts where calculation is not representative of the whole cohort. 
    -- We take 98% and not 100% as otherwise only a few outliers might prevent us from showing the cohort.
    QUALIFY cnt_accounts >= 0.98 * MAX(cnt_accounts) OVER(PARTITION BY cohort_month) 
),

aggregating as (
    SELECT 
        cohort_month,
        perc_term_elapsed_approx,
        SUM(paid_total_lin) / SUM(unlock_price_excl_dp) as amount_paid_percent,
    FROM filtering
    GROUP BY ALL 
)

SELECT * FROM aggregating
    );
  
[0m11:07:31.327371 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:3695bbce-9fd9-4582-a9ff-34b1b4afc188&page=queryresults
[0m11:07:36.010643 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa06fab3400>]}
[0m11:07:36.012157 [info ] [Thread-1  ]: 9 of 19 OK created sql table model oscreditrisk.cohorts_advanced ............... [[32mCREATE TABLE (693.0 rows, 153.2 MiB processed)[0m in 7.03s]
[0m11:07:36.013649 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohorts_advanced
[0m11:07:36.014735 [debug] [Thread-1  ]: Began running node model.creditrisk.history_defaults
[0m11:07:36.015751 [info ] [Thread-1  ]: 10 of 19 START sql view model oscreditrisk.history_defaults .................... [RUN]
[0m11:07:36.016667 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cohorts_advanced, now model.creditrisk.history_defaults)
[0m11:07:36.017380 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_defaults
[0m11:07:36.028698 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_defaults"
[0m11:07:36.033693 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_defaults
[0m11:07:36.041271 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_defaults"
[0m11:07:36.043560 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:36.044427 [debug] [Thread-1  ]: On model.creditrisk.history_defaults: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_defaults"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
  OPTIONS()
  as /*
    This transformations creates a dataset containing one line per account and contains the information if the account has defaulted or not. 
*/

WITH history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
    QUALIFY reporting_date = MAX(reporting_date) OVER()
),

detect_defaults as (
    SELECT 
        account_id,
        registration_date,
        perc_paid,
        CASE 
            WHEN reporting_date_status in ('UNLOCKED') THEN 0
            WHEN reporting_date_status in ('DETACHED', 'WRITTEN_OFF') THEN 1
            WHEN days_disabled >= 180 THEN 1
            ELSE 0
        END as has_defaulted,
    FROM history
)

SELECT * FROM detect_defaults;


[0m11:07:37.618815 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:1191e939-9d18-47a9-a7f6-8e1149e0ef55&page=queryresults
[0m11:07:38.876950 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07640ca90>]}
[0m11:07:38.877956 [info ] [Thread-1  ]: 10 of 19 OK created sql view model oscreditrisk.history_defaults ............... [[32mCREATE VIEW (0 processed)[0m in 2.86s]
[0m11:07:38.879128 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_defaults
[0m11:07:38.879795 [debug] [Thread-1  ]: Began running node model.creditrisk.history_disablements
[0m11:07:38.880493 [info ] [Thread-1  ]: 11 of 19 START sql view model oscreditrisk.history_disablements ................ [RUN]
[0m11:07:38.881332 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_defaults, now model.creditrisk.history_disablements)
[0m11:07:38.881907 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_disablements
[0m11:07:38.886836 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_disablements"
[0m11:07:38.888049 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_disablements
[0m11:07:38.894553 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_disablements"
[0m11:07:38.896262 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:38.897569 [debug] [Thread-1  ]: On model.creditrisk.history_disablements: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_disablements"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_disablements`
  OPTIONS()
  as /*
    This transformation prepares a dataset in the right format for a survival analysis.
    The target dataset contains one line per disablement period. 
    Duration represents the duration of the period. Event represents the fact that there was a payment interrupting the period. 
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

get_disablement_periods as (
    SELECT 
        account_id,
        reporting_date,
        reporting_date_status,
        perc_paid,
        LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day) as last_disablement,
        days_disabled,
    FROM accounts_history
),

aggregated_disablement_periods as (
    SELECT 
        account_id,
        reporting_date,
        reporting_date_status,
        perc_paid,
        days_disabled as duration,
    FROM get_disablement_periods
    QUALIFY days_disabled = MAX(days_disabled) OVER(PARTITION BY account_id, last_disablement)
)


SELECT
    *,
    IF(reporting_date = MAX(reporting_date) OVER(), 0, 1) as event,
FROM aggregated_disablement_periods;


[0m11:07:40.451974 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:af5a7a88-d789-4f53-acd4-97b27e9166b2&page=queryresults
[0m11:07:41.650453 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0762bd3a0>]}
[0m11:07:41.651406 [info ] [Thread-1  ]: 11 of 19 OK created sql view model oscreditrisk.history_disablements ........... [[32mCREATE VIEW (0 processed)[0m in 2.77s]
[0m11:07:41.652355 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_disablements
[0m11:07:41.653057 [debug] [Thread-1  ]: Began running node model.creditrisk.history_segmentations
[0m11:07:41.654158 [info ] [Thread-1  ]: 12 of 19 START sql view model oscreditrisk.history_segmentations ............... [RUN]
[0m11:07:41.655091 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_disablements, now model.creditrisk.history_segmentations)
[0m11:07:41.655704 [debug] [Thread-1  ]: Began compiling node model.creditrisk.history_segmentations
[0m11:07:41.669550 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.history_segmentations"
[0m11:07:41.671359 [debug] [Thread-1  ]: Began executing node model.creditrisk.history_segmentations
[0m11:07:41.677896 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.history_segmentations"
[0m11:07:41.679506 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:41.680494 [debug] [Thread-1  ]: On model.creditrisk.history_segmentations: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.history_segmentations"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`history_segmentations`
  OPTIONS()
  as /*
    This transformations generates a table representing the segmentation A, B, C and D
    for each account depending on the progress on repayment. 
    It will be used to train the model to pick up these segmentations.
*/

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

segmentation_at_0 as (
  SELECT 
    account_id,
    0 as perc_paid_current,
    '0. At registration' as account_segmentation,
  FROM accounts_history
  WHERE reporting_day = 1
),

segmentation_at_10 as (
  SELECT 
    account_id,
    0.1 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.1
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_20 as (
  SELECT 
    account_id,
    0.2 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.2
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_30 as (
  SELECT 
    account_id,
    0.3 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.3
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_40 as (
  SELECT 
    account_id,
    0.4 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.4
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_50 as (
  SELECT 
    account_id,
    0.5 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.5
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_60 as (
  SELECT 
    account_id,
    0.6 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.6
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_70 as (
  SELECT 
    account_id,
    0.7 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.7
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_80 as (
  SELECT 
    account_id,
    0.8 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.8
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
),

segmentation_at_90 as (
  SELECT 
    account_id,
    0.9 as perc_paid_current,
    account_segmentation,
  FROM accounts_history
  WHERE perc_paid >= 0.9
  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1
)

SELECT * FROM segmentation_at_0
UNION ALL
SELECT * FROM segmentation_at_10
UNION ALL
SELECT * FROM segmentation_at_20
UNION ALL
SELECT * FROM segmentation_at_30
UNION ALL
SELECT * FROM segmentation_at_40
UNION ALL
SELECT * FROM segmentation_at_50
UNION ALL
SELECT * FROM segmentation_at_60
UNION ALL
SELECT * FROM segmentation_at_70
UNION ALL
SELECT * FROM segmentation_at_80
UNION ALL
SELECT * FROM segmentation_at_90;


[0m11:07:43.213723 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b6563e40-7f8f-4f22-bc5a-92d5b15cd8d1&page=queryresults
[0m11:07:44.374325 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa076421250>]}
[0m11:07:44.375095 [info ] [Thread-1  ]: 12 of 19 OK created sql view model oscreditrisk.history_segmentations .......... [[32mCREATE VIEW (0 processed)[0m in 2.72s]
[0m11:07:44.375905 [debug] [Thread-1  ]: Finished running node model.creditrisk.history_segmentations
[0m11:07:44.376532 [debug] [Thread-1  ]: Began running node model.creditrisk.cohort_projection_model
[0m11:07:44.377422 [info ] [Thread-1  ]: 13 of 19 START sql view model oscreditrisk.cohort_projection_model ............. [RUN]
[0m11:07:44.378107 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.history_segmentations, now model.creditrisk.cohort_projection_model)
[0m11:07:44.378591 [debug] [Thread-1  ]: Began compiling node model.creditrisk.cohort_projection_model
[0m11:07:44.412045 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.cohort_projection_model"
[0m11:07:44.417945 [debug] [Thread-1  ]: Began executing node model.creditrisk.cohort_projection_model
[0m11:07:44.434320 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.cohort_projection_model"
[0m11:07:44.435280 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:44.435969 [debug] [Thread-1  ]: On model.creditrisk.cohort_projection_model: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.cohort_projection_model"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`cohort_projection_model`
  OPTIONS()
  as WITH cohorts as (
    SELECT 
        *, 
        (reporting_day - 1) / 30 as reporting_month, 
        CASE
            WHEN reporting_day = 1 THEN amount_paid_percent
            ELSE amount_paid_percent - LAG(amount_paid_percent) OVER(PARTITION BY cohort_month ORDER BY reporting_day)
        END as amount_paid_percent_incr, 
    FROM `steam-outlet-209412`.`oscreditrisk`.`cohorts_beginner`
),

-- Step 1 : Building a reference dataset : containing for each month, the reference point for the last 6 available cohorts
last_6_reference as (
    SELECT 
        *,
    FROM cohorts
    QUALIFY ROW_NUMBER() OVER(PARTITION BY CAST(reporting_month AS INT64) ORDER BY cohort_month DESC) <= 6
),

last_6_aggregated as (
    SELECT 
        reporting_month,
        AVG(amount_paid_percent_incr)                           as projected_paid_percent_incr,
        AVG(amount_paid_percent - amount_paid_percent_incr)     as reference_paid_percent, -- this field will serve to apply the scale factor
    FROM last_6_reference
    GROUP BY ALL
),

-- Step 2 : Let's build the full dataset of cohorts including future months
cohort_months as (
    SELECT DISTINCT cohort_month FROM cohorts
),

reporting_months as (
    SELECT DISTINCT reporting_month FROM cohorts
),

full_cohort_spine as (
    SELECT * FROM cohort_months
    CROSS JOIN reporting_months
),

-- Step 3 : Joining the data back in this target dataset
joint as (
    SELECT 
        full_cohort_spine.*,
        cohorts.amount_paid_percent,
        cohorts.amount_paid_percent_incr,
    FROM full_cohort_spine 
    LEFT JOIN cohorts USING(cohort_month, reporting_month)
),

joint_with_projections as (
    SELECT 
        joint.*,
        last_6_aggregated.projected_paid_percent_incr,
        last_6_aggregated.reference_paid_percent,
        MAX(joint.amount_paid_percent) OVER(PARTITION BY cohort_month) / MIN(last_6_aggregated.reference_paid_percent) OVER(PARTITION BY cohort_month) as scale_factor,
    FROM joint 
    LEFT JOIN last_6_aggregated
    ON 
        joint.amount_paid_percent IS NULL AND 
        joint.reporting_month = last_6_aggregated.reporting_month
),

-- Step 4 : combine actuals and predictions, and calculate cumulative values
projected_and_actuals as (
    SELECT 
    *,
    COALESCE(amount_paid_percent_incr, projected_paid_percent_incr)                 as projected_and_actual_amount_paid_percent_incr,
    COALESCE(amount_paid_percent_incr, projected_paid_percent_incr * scale_factor)  as projected_and_actual_amount_paid_percent_incr_with_scale_factor,
    FROM joint_with_projections 
    GROUP BY ALL
)

SELECT 
    *,
    SUM(projected_and_actual_amount_paid_percent_incr) OVER(
        PARTITION BY cohort_month ORDER BY reporting_month ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
    ) as projected_and_actual_amount_paid_percent,
    SUM(projected_and_actual_amount_paid_percent_incr_with_scale_factor) OVER(
        PARTITION BY cohort_month ORDER BY reporting_month ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
    ) as projected_and_actual_amount_paid_percent_with_scale_factor,
FROM projected_and_actuals
ORDER BY 1, 2;


[0m11:07:45.855337 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:406bb600-9e5b-42b3-9583-4496fd6f99f8&page=queryresults
[0m11:07:47.002935 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa076410b20>]}
[0m11:07:47.003889 [info ] [Thread-1  ]: 13 of 19 OK created sql view model oscreditrisk.cohort_projection_model ........ [[32mCREATE VIEW (0 processed)[0m in 2.62s]
[0m11:07:47.004933 [debug] [Thread-1  ]: Finished running node model.creditrisk.cohort_projection_model
[0m11:07:47.005688 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_date_samples
[0m11:07:47.006599 [info ] [Thread-1  ]: 14 of 19 START sql view model oscreditrisk.prepare_date_samples ................ [RUN]
[0m11:07:47.007881 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.cohort_projection_model, now model.creditrisk.prepare_date_samples)
[0m11:07:47.008713 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_date_samples
[0m11:07:47.014936 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_date_samples"
[0m11:07:47.017237 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_date_samples
[0m11:07:47.022878 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_date_samples"
[0m11:07:47.024817 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:47.026599 [debug] [Thread-1  ]: On model.creditrisk.prepare_date_samples: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_date_samples"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`prepare_date_samples`
  OPTIONS()
  as /*
    This transformation is quite essential to produce an unbiaised model
    For every chunk of repayment [0-10%], [10-20%], etc... it estimates what is the sample of accounts we can use for estimating probabilities of default.
    For example, if for 40 - 50% the sample end date is 2020-12-03, it means that we must use only accounts registered prior to this date.
    Otherwise, we are going to produce biaised (selection bias) estimates, as too many accounts will not have finished paying or will not have defaulted.
*/

WITH default_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
),

date_spine as (
    SELECT reporting_date as sample_end_date FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`
),

-- Generates a table containing 10 rows, representing the different chunks of repayment : 0 to 10%, 10 to 20%, etc...
split_chunks as (
    SELECT 
        *,
        index_chunk / 10 as perc_paid_chunk_start,
        COALESCE(
            LEAD(index_chunk / 10) OVER(ORDER BY index_chunk),
            1
        ) as perc_paid_chunk_end,
    FROM UNNEST(GENERATE_ARRAY(0, 9)) as index_chunk
),

crossjoint as (
    SELECT 
        *,
        IF(perc_paid < perc_paid_chunk_end AND has_defaulted = 0, 1, 0) as is_censored,
    FROM default_history
    CROSS JOIN split_chunks
),

grouped as (
    SELECT 
        index_chunk,
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        sample_end_date,
        AVG(is_censored) as censored_percent,
    FROM crossjoint
    LEFT JOIN date_spine
    ON date_spine.sample_end_date >= crossjoint.registration_date
    GROUP BY ALL
    HAVING censored_percent <= 0.05 -- Here the tolerance to censoring is 5%.
),

get_chunck_dates as (
    SELECT 
        index_chunk,
        perc_paid_chunk_start,
        perc_paid_chunk_end,
        MAX(sample_end_date) as sample_end_date,
    FROM grouped 
    GROUP BY ALL
)

SELECT * FROM get_chunck_dates;


[0m11:07:48.714327 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:8924e326-3dd2-4dd0-83ba-ba17336622d3&page=queryresults
[0m11:07:49.815270 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa076483520>]}
[0m11:07:49.816411 [info ] [Thread-1  ]: 14 of 19 OK created sql view model oscreditrisk.prepare_date_samples ........... [[32mCREATE VIEW (0 processed)[0m in 2.81s]
[0m11:07:49.817571 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_date_samples
[0m11:07:49.818280 [debug] [Thread-1  ]: Began running node model.creditrisk.probability_calculation_survival
[0m11:07:49.819029 [info ] [Thread-1  ]: 15 of 19 START sql view model oscreditrisk.probability_calculation_survival .... [RUN]
[0m11:07:49.819901 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.prepare_date_samples, now model.creditrisk.probability_calculation_survival)
[0m11:07:49.820501 [debug] [Thread-1  ]: Began compiling node model.creditrisk.probability_calculation_survival
[0m11:07:49.831704 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.probability_calculation_survival"
[0m11:07:49.834203 [debug] [Thread-1  ]: Began executing node model.creditrisk.probability_calculation_survival
[0m11:07:49.838506 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.probability_calculation_survival"
[0m11:07:49.839482 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:49.840294 [debug] [Thread-1  ]: On model.creditrisk.probability_calculation_survival: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.probability_calculation_survival"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`
  OPTIONS()
  as /*
    This is a SQL implementation of the Kaplan Meier Survival Analysis.
    The output is a survival function. 
*/

WITH reactivation_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_disablements`
),

-- Split by perc paid bucket and take only last 3 years events observed
reactivation_history_filtered as (
    SELECT 
        *, 
        CASE 
            WHEN perc_paid <= 0.1 THEN '0'
            WHEN perc_paid <= 0.5 THEN '0.1'
            WHEN perc_paid <= 1 THEN '0.5'
            ELSE '0.5'
        END as perc_paid_bucket_start,
            CASE 
            WHEN perc_paid <= 0.1 THEN '0.1'
            WHEN perc_paid <= 0.5 THEN '0.5'
            WHEN perc_paid <= 1 THEN '1'
            ELSE '1'
        END as perc_paid_bucket_end
    FROM reactivation_history
),

cnt_subjects as (
  SELECT 
    perc_paid_bucket_start, 
    perc_paid_bucket_end, 
    COUNT(*) as num_subjects 
  FROM reactivation_history_filtered
  GROUP BY ALL 
),

daily as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end,
    duration,
    COUNT(*) as num_obs,
    SUM(event) as num_events
  FROM reactivation_history_filtered
  GROUP BY ALL ORDER BY 1, 2, 3
),

at_risk_table as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end,
    duration, 
    num_obs,
    num_events,
    num_subjects - COALESCE(SUM(num_obs) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end
      ORDER BY duration ASC ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING), 0)
     as at_risk
  FROM daily
  LEFT JOIN cnt_subjects USING(perc_paid_bucket_start, perc_paid_bucket_end)
),

survival_proba_table as (
  SELECT
    perc_paid_bucket_start, 
    perc_paid_bucket_end, 
    duration, 
    at_risk,
    num_obs,
    num_events,
    at_risk - num_events - COALESCE(LEAD(at_risk, 1) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC), 0) as censored,
    EXP(SUM(SAFE.LN(1 - num_events / at_risk)) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC ROWS BETWEEN UNBOUNDED PRECEDING AND current ROW)) as survival_proba
  FROM at_risk_table
),

get_density_proba as (
  SELECT  
    survival_proba_table.*,
    1 - survival_proba as prob_cum,
    (1 - survival_proba) - COALESCE(1 - LAG(survival_proba) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC), 0) as prob_dens,
    ROW_NUMBER() OVER (PARTITION BY perc_paid_bucket_end ORDER BY duration ASC) as row_num
  FROM survival_proba_table
)

SELECT 
    * EXCEPT(duration, perc_paid_bucket_start, perc_paid_bucket_end),
    CAST(perc_paid_bucket_start AS FLOAT64) as perc_paid_bucket_start,
    CAST(perc_paid_bucket_end AS FLOAT64) as perc_paid_bucket_end,
    duration as days_since_cutoff 
FROM get_density_proba
ORDER BY perc_paid_bucket_start, duration;


[0m11:07:51.524961 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:244a01de-3731-46ad-9511-8a9c50eb3242&page=queryresults
[0m11:07:52.635862 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa076418d90>]}
[0m11:07:52.636989 [info ] [Thread-1  ]: 15 of 19 OK created sql view model oscreditrisk.probability_calculation_survival  [[32mCREATE VIEW (0 processed)[0m in 2.82s]
[0m11:07:52.638123 [debug] [Thread-1  ]: Finished running node model.creditrisk.probability_calculation_survival
[0m11:07:52.638947 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_inputs
[0m11:07:52.639663 [info ] [Thread-1  ]: 16 of 19 START sql view model oscreditrisk.prepare_model_inputs ................ [RUN]
[0m11:07:52.640428 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.probability_calculation_survival, now model.creditrisk.prepare_model_inputs)
[0m11:07:52.641117 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_inputs
[0m11:07:52.647813 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_inputs"
[0m11:07:52.649787 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_inputs
[0m11:07:52.654552 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_inputs"
[0m11:07:52.655677 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:52.656422 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_inputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_inputs"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
  OPTIONS()
  as /*
    Simple preparation step joining the various inputs.
*/

WITH accs as (
  SELECT 
    *,
  FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`
  LEFT JOIN `steam-outlet-209412`.`oscreditrisk`.`history_segmentations` USING(account_id)
),

samples as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_date_samples`
),

joint as (
  SELECT 
    accs.*,
    samples.*,
    RAND() as rnd,
  FROM accs
  INNER JOIN samples
  ON 
    accs.registration_date < CAST(samples.sample_end_date AS TIMESTAMP)
)

SELECT * FROM joint;


[0m11:07:54.318925 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:eb7aa98b-c705-43d0-8c54-76d3cae198d3&page=queryresults
[0m11:07:55.446110 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa076217c10>]}
[0m11:07:55.447076 [info ] [Thread-1  ]: 16 of 19 OK created sql view model oscreditrisk.prepare_model_inputs ........... [[32mCREATE VIEW (0 processed)[0m in 2.81s]
[0m11:07:55.448237 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_inputs
[0m11:07:55.448991 [debug] [Thread-1  ]: Began running node model.creditrisk.probability_of_defaulting
[0m11:07:55.449955 [info ] [Thread-1  ]: 17 of 19 START sql view model oscreditrisk.probability_of_defaulting ........... [RUN]
[0m11:07:55.450681 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.prepare_model_inputs, now model.creditrisk.probability_of_defaulting)
[0m11:07:55.451261 [debug] [Thread-1  ]: Began compiling node model.creditrisk.probability_of_defaulting
[0m11:07:55.458218 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.probability_of_defaulting"
[0m11:07:55.461363 [debug] [Thread-1  ]: Began executing node model.creditrisk.probability_of_defaulting
[0m11:07:55.466029 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.probability_of_defaulting"
[0m11:07:55.467319 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:55.468335 [debug] [Thread-1  ]: On model.creditrisk.probability_of_defaulting: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.probability_of_defaulting"} */


  create or replace view `steam-outlet-209412`.`oscreditrisk`.`probability_of_defaulting`
  OPTIONS()
  as /*
    This transformation uses the output of the survival function to determine the immediate probability of defaulting of a late account
*/

WITH proba_reactivation as (
  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`
),

repayment as (
  SELECT 
    *,
    1 - prob_cum as survival_func, -- opposite of probability of reactivation
    IF(days_since_cutoff = 270, 1 - prob_cum, null) as survival_func_at_PAR270 -- opposite of probability of reactivation at PAR270
  FROM proba_reactivation
),

get_survival_limit as (
  SELECT 
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    MAX(survival_func_at_PAR270)  as survival_limit_at_PAR270,
    MIN(survival_func)            as survival_limit
  FROM repayment
  GROUP BY ALL
),

immediate_churn_and_repo_act as (
  SELECT 
    perc_paid_bucket_start,
    perc_paid_bucket_end,
    days_since_cutoff,
    survival_limit_at_PAR270,
    survival_limit,
    survival_func,
    -- probability of non-reactivation before PAR270 knowing there is non-reactivation event at time t
    SAFE_DIVIDE(IF(survival_limit_at_PAR270 is null, survival_limit, survival_limit_at_PAR270), survival_func) as immediate_prob_churn,
  FROM repayment
  LEFT JOIN get_survival_limit
    USING(perc_paid_bucket_start, perc_paid_bucket_end) 
),

immediate_churn as (
  SELECT 
    * EXCEPT(immediate_prob_churn),
    IF(days_since_cutoff > 270, 1, immediate_prob_churn) as immediate_prob_churn
  FROM immediate_churn_and_repo_act
)

SELECT * FROM immediate_churn;


[0m11:07:57.225908 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:90de1841-c52d-4d0c-a0bf-7f4edf77ce6d&page=queryresults
[0m11:07:58.321696 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa076217c10>]}
[0m11:07:58.322867 [info ] [Thread-1  ]: 17 of 19 OK created sql view model oscreditrisk.probability_of_defaulting ...... [[32mCREATE VIEW (0 processed)[0m in 2.87s]
[0m11:07:58.325188 [debug] [Thread-1  ]: Finished running node model.creditrisk.probability_of_defaulting
[0m11:07:58.326869 [debug] [Thread-1  ]: Began running node model.creditrisk.prepare_model_outputs
[0m11:07:58.328586 [info ] [Thread-1  ]: 18 of 19 START sql table model oscreditrisk.prepare_model_outputs .............. [RUN]
[0m11:07:58.329833 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.probability_of_defaulting, now model.creditrisk.prepare_model_outputs)
[0m11:07:58.330765 [debug] [Thread-1  ]: Began compiling node model.creditrisk.prepare_model_outputs
[0m11:07:58.341140 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.prepare_model_outputs"
[0m11:07:58.344340 [debug] [Thread-1  ]: Began executing node model.creditrisk.prepare_model_outputs
[0m11:07:58.349550 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:59.763975 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.prepare_model_outputs"
[0m11:07:59.765593 [debug] [Thread-1  ]: On model.creditrisk.prepare_model_outputs: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.prepare_model_outputs"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`
      
    
    

    OPTIONS()
    as (
      /*
    This is where the main calculation happens.
    Calculation of the PDs & PDs * EADs.
*/



WITH input as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`
),

calculated as (
  SELECT 
    perc_paid_current,
    account_segmentation,
    sample_end_date, 
    perc_paid_chunk_start,
    perc_paid_chunk_end,
    COUNT(*) as number_of_accounts,
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1
        WHEN 
            has_defaulted = 0 
            AND perc_paid < perc_paid_chunk_start AND 
            -- This formula takes an assumption for future default rates of censored accounts.
            -- Here we consider the account will have 40% chances of defaulting in the remaining repayment
            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10) 
        THEN 1
        ELSE 0
      END
    ) as p_churn_incr, -- p_churn represents the probability of default
    AVG(
      CASE 
        WHEN 
            has_defaulted = 1 AND 
            perc_paid >= perc_paid_chunk_start AND 
            perc_paid < perc_paid_chunk_end 
        THEN 1 - perc_paid
        WHEN 
            has_defaulted = 0 AND 
            perc_paid < perc_paid_chunk_end AND 
            -- This formula takes an assumption for future default rates of censored accounts.
            -- Here we consider the account will have 40% chances of defaulting in the remaining repayment
            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10)
        THEN 1 - perc_paid_chunk_start
        ELSE 0
      END
    ) as r_churn_incr, -- r_churn represents the expected loss in receivable PD * EAD.
  FROM input
  GROUP BY ALL
)

SELECT 
    *,

    SUM(p_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as p_churn,

    SUM(r_churn_incr) OVER(
        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation 
        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
    ) as r_churn, 

FROM calculated
    );
  
[0m11:08:00.785924 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:b8b6bdd5-d72a-4e36-93c5-2ddc464f8080&page=queryresults
[0m11:08:09.289567 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa076420100>]}
[0m11:08:09.290567 [info ] [Thread-1  ]: 18 of 19 OK created sql table model oscreditrisk.prepare_model_outputs ......... [[32mCREATE TABLE (369.0 rows, 174.7 MiB processed)[0m in 10.96s]
[0m11:08:09.291660 [debug] [Thread-1  ]: Finished running node model.creditrisk.prepare_model_outputs
[0m11:08:09.292734 [debug] [Thread-1  ]: Began running node model.creditrisk.predict_ecls
[0m11:08:09.293493 [info ] [Thread-1  ]: 19 of 19 START sql table model oscreditrisk.predict_ecls ....................... [RUN]
[0m11:08:09.294262 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.creditrisk.prepare_model_outputs, now model.creditrisk.predict_ecls)
[0m11:08:09.294868 [debug] [Thread-1  ]: Began compiling node model.creditrisk.predict_ecls
[0m11:08:09.302067 [debug] [Thread-1  ]: Writing injected SQL for node "model.creditrisk.predict_ecls"
[0m11:08:09.303557 [debug] [Thread-1  ]: Began executing node model.creditrisk.predict_ecls
[0m11:08:09.318730 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:08:10.770618 [debug] [Thread-1  ]: Writing runtime sql for node "model.creditrisk.predict_ecls"
[0m11:08:10.772140 [debug] [Thread-1  ]: On model.creditrisk.predict_ecls: /* {"app": "dbt", "dbt_version": "1.8.8", "profile_name": "creditrisk", "target_name": "dev", "node_id": "model.creditrisk.predict_ecls"} */

  
    

    create or replace table `steam-outlet-209412`.`oscreditrisk`.`predict_ecls`
      
    partition by timestamp_trunc(reporting_date, day)
    cluster by account_id

    OPTIONS()
    as (
      

WITH accounts_history as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`
),

repo as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`repossession_valuation_parameters`
),

proba_churn_repayment as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`
),

proba_churn_immediate as (
    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`probability_of_defaulting`
),

batch_to_compute as (
    SELECT
        account_id, 
        reporting_date,
        reporting_day,
        portfolio_scope,
        days_disabled,
        perc_paid,
        IF(perc_paid < 0.1, '0. At registration', account_segmentation) as account_segmentation, 
    FROM accounts_history
    WHERE portfolio_scope
),

join_with_churn_model as (
    SELECT     
        account_id,
        reporting_date,
        SUM(proba_churn_repayment.p_churn_incr)        as p_churn,
        SUM(proba_churn_repayment.r_churn_incr)        as r_churn,
    FROM batch_to_compute
    LEFT JOIN proba_churn_repayment
    ON 
        batch_to_compute.account_segmentation = proba_churn_repayment.account_segmentation AND
        batch_to_compute.perc_paid < proba_churn_repayment.perc_paid_chunk_end
    GROUP BY ALL
),

join_with_immediate_churn_model as (
    SELECT 
        account_id, 
        reporting_date,
        COALESCE(proba_churn_immediate.immediate_prob_churn, 0) as immediate_prob_churn,
        COALESCE(proba_churn_immediate.immediate_prob_churn, 0) * (1 - perc_paid) as immediate_loss,
    FROM batch_to_compute
    LEFT JOIN proba_churn_immediate
    ON  
        batch_to_compute.perc_paid >= proba_churn_immediate.perc_paid_bucket_start AND 
        batch_to_compute.perc_paid < proba_churn_immediate.perc_paid_bucket_end AND 
        batch_to_compute.days_disabled = proba_churn_immediate.days_since_cutoff
),

joint_together as (
    SELECT * FROM batch_to_compute
    LEFT JOIN join_with_churn_model USING(account_id, reporting_date)
    LEFT JOIN join_with_immediate_churn_model USING(account_id, reporting_date)
    CROSS JOIN repo
),

combine_outputs_1 as (
    SELECT 
        account_id,
        reporting_date,
        reporting_day, 
        days_disabled,
        perc_paid,
        account_segmentation,

        p_churn as repayment_prob_churn,
        r_churn as repayment_loss,
        p_churn * probability_of_repossession * repossession_value as repayment_recoveries,
        
        immediate_prob_churn,
        immediate_loss,
        immediate_prob_churn * probability_of_repossession * repossession_value as immediate_recoveries,

    FROM joint_together
),

combine_outputs_2 as (
    SELECT 
        *,
        IF(immediate_loss - immediate_recoveries < 0, 0, immediate_loss - immediate_recoveries) as immediate_ecl,
        IF(repayment_loss - repayment_recoveries < 0, 0, repayment_loss - repayment_recoveries) as repayment_ecl,
    FROM combine_outputs_1
),

combine_outputs_3 as (
    SELECT 
        *,
        immediate_loss + (1 - immediate_prob_churn) * repayment_loss as total_loss,
        immediate_prob_churn + (1 - immediate_prob_churn) * repayment_prob_churn as total_pchurn,
        immediate_ecl + (1 - immediate_prob_churn) * repayment_ecl as total_ecl,
    FROM combine_outputs_2
)

SELECT * FROM combine_outputs_3
    );
  
[0m11:08:11.951874 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=steam-outlet-209412&j=bq:EU:44b78f5d-8f66-4c56-b92a-0818e28fe53a&page=queryresults
[0m11:08:54.974438 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874f6deb-455e-41a6-9dd9-d22bc709be55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa07624dc70>]}
[0m11:08:54.976336 [info ] [Thread-1  ]: 19 of 19 OK created sql table model oscreditrisk.predict_ecls .................. [[32mCREATE TABLE (2.4m rows, 122.1 MiB processed)[0m in 45.68s]
[0m11:08:54.977441 [debug] [Thread-1  ]: Finished running node model.creditrisk.predict_ecls
[0m11:08:54.979122 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:08:54.979596 [debug] [MainThread]: Connection 'model.creditrisk.predict_ecls' was properly closed.
[0m11:08:54.980286 [info ] [MainThread]: 
[0m11:08:54.980822 [info ] [MainThread]: Finished running 12 view models, 7 table models, 1 project hook in 0 hours 2 minutes and 33.38 seconds (153.38s).
[0m11:08:54.986228 [debug] [MainThread]: Command end result
[0m11:08:55.048720 [info ] [MainThread]: 
[0m11:08:55.049441 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:08:55.049975 [info ] [MainThread]: 
[0m11:08:55.050532 [info ] [MainThread]: Done. PASS=19 WARN=0 ERROR=0 SKIP=0 TOTAL=19
[0m11:08:55.051459 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 157.95305, "process_user_time": 6.607973, "process_kernel_time": 1.036471, "process_mem_max_rss": "229523456", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m11:08:55.052575 [debug] [MainThread]: Command `dbt run` succeeded at 11:08:55.052422 after 157.95 seconds
[0m11:08:55.053281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa06d332580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa074dec970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa074c53d00>]}
[0m11:08:55.053900 [debug] [MainThread]: Flushing usage events
