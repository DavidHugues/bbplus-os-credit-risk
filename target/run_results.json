{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.8.8", "generated_at": "2024-12-17T08:08:54.981275Z", "invocation_id": "874f6deb-455e-41a6-9dd9-d22bc709be55", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:06:30.903051Z", "completed_at": "2024-12-17T08:06:30.961094Z"}, {"name": "execute", "started_at": "2024-12-17T08:06:30.962003Z", "completed_at": "2024-12-17T08:06:33.718271Z"}], "thread_id": "Thread-1", "execution_time": 2.8167128562927246, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "476df677-b4a4-4d11-913c-2b8d697b5075", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.cleaned_accounts", "compiled": true, "compiled_code": "/*\n    This transformations is just casting fields in the right format. \n    In practice, you may add here filtering steps to reduce your data to relevant records.\n*/\n\nWITH accounts as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_accounts`\n)\n\nSELECT \n  account_id, \n  CAST(registration_date            AS TIMESTAMP)     as registration_date, \n  CAST(unlock_price                 AS FLOAT64)       as unlock_price, \n  CAST(down_payment                 AS FLOAT64)       as down_payment, \n  CAST(down_payment_days_included   AS FLOAT64)       as down_payment_days_included, \n  CAST(daily_rate                   AS FLOAT64)       as daily_rate, \nFROM accounts", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:06:33.727515Z", "completed_at": "2024-12-17T08:06:33.733125Z"}, {"name": "execute", "started_at": "2024-12-17T08:06:33.733745Z", "completed_at": "2024-12-17T08:06:36.531739Z"}], "thread_id": "Thread-1", "execution_time": 2.8063578605651855, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "32bb655c-a164-4e74-bc7e-7c2521858cfc", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.cleaned_payments", "compiled": true, "compiled_code": "/*\n    This transformations is just casting fields in the right format. \n    In practice, you may add here filtering steps to reduce your data to relevant records.\n*/\n\nWITH payments as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_payments`\n)\n\nSELECT \n  account_id,\n  CAST(down_payment             AS BOOLEAN)         as down_payment,\n  CAST(payment_effective_date   AS TIMESTAMP)       as payment_effective_date,\n  CAST(amount                   AS FLOAT64)         as amount,\nFROM payments", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:06:36.540211Z", "completed_at": "2024-12-17T08:06:36.547032Z"}, {"name": "execute", "started_at": "2024-12-17T08:06:36.548021Z", "completed_at": "2024-12-17T08:06:39.278255Z"}], "thread_id": "Thread-1", "execution_time": 2.742111921310425, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "cfc33fc5-4dbc-4110-88bf-ba3de3c7ee93", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.cleaned_write_offs", "compiled": true, "compiled_code": "WITH wo as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`raw_write_offs`\n)\n\n-- Deduplication step in case there are several write offs or repossessions on the same account\nSELECT \n    account_id,\n    write_off_status,\n    MIN(CAST(changed_date AS TIMESTAMP)) as changed_date, \nFROM wo\nGROUP BY ALL", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:06:39.285502Z", "completed_at": "2024-12-17T08:06:39.291046Z"}, {"name": "execute", "started_at": "2024-12-17T08:06:39.292044Z", "completed_at": "2024-12-17T08:06:41.924856Z"}], "thread_id": "Thread-1", "execution_time": 2.6407418251037598, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "bfdd6fc2-92b2-44c1-a488-9ba7ecccabeb", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.repossession_valuation_parameters", "compiled": true, "compiled_code": "/*\n    This part is drastically simplified here. \n    Analyses should be performed to determine the right value of KPIs. \n    Here we are using these values as placeholders to show how they fit in the global model recombination.\n*/\n\nSELECT \n    0.6 as probability_of_repossession,\n    0.2 as repossession_value, -- expressed here as a percentage of initial unlock price.", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`repossession_valuation_parameters`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:06:41.929694Z", "completed_at": "2024-12-17T08:06:41.934849Z"}, {"name": "execute", "started_at": "2024-12-17T08:06:41.935444Z", "completed_at": "2024-12-17T08:06:48.094504Z"}], "thread_id": "Thread-1", "execution_time": 6.166068077087402, "adapter_response": {"_message": "CREATE TABLE (1.1k rows, 3.4 MiB processed)", "code": "CREATE TABLE", "rows_affected": 1096, "bytes_processed": 3588144, "bytes_billed": 10485760, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "b58d1a64-de98-469a-96e6-cc6a2142a27a", "slot_ms": 6035}, "message": "CREATE TABLE (1.1k rows, 3.4 MiB processed)", "failures": null, "unique_id": "model.creditrisk.date_spine", "compiled": true, "compiled_code": "/*\n    This transformations is generating a dataset containing one row for each day betwee : \n    - The first day you opened an account\n    - Today. With artificial data here we consider today being the day after we received the last payment.\n*/\n\nWITH payments as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`\n),\n\nmin_max_dates as (\n    SELECT \n        CAST(MIN(payment_effective_date)            AS DATE)                    as min_date,\n        DATE_ADD(CAST(MAX(payment_effective_date)   AS DATE), INTERVAL 1 DAY)   as max_date,\n    FROM payments\n)\n\nSELECT\n    CAST(\n        TIMESTAMP_ADD(\n            (SELECT min_date FROM min_max_dates), \n            INTERVAL n DAY\n        ) AS TIMESTAMP\n    ) AS reporting_date,\nFROM \n  UNNEST(\n    GENERATE_ARRAY(\n        0, \n        DATE_DIFF(\n            (SELECT max_date FROM min_max_dates),\n            (SELECT min_date FROM min_max_dates),\n            DAY\n        )\n    )\n) AS n", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`date_spine`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:06:48.101416Z", "completed_at": "2024-12-17T08:06:48.108583Z"}, {"name": "execute", "started_at": "2024-12-17T08:06:48.109316Z", "completed_at": "2024-12-17T08:07:00.332248Z"}], "thread_id": "Thread-1", "execution_time": 12.232433319091797, "adapter_response": {"_message": "CREATE TABLE (3.4m rows, 6.2 MiB processed)", "code": "CREATE TABLE", "rows_affected": 3352042, "bytes_processed": 6535378, "bytes_billed": 31457280, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "47dd1bac-8cdc-49be-8fa0-53d9b123f815", "slot_ms": 379965}, "message": "CREATE TABLE (3.4m rows, 6.2 MiB processed)", "failures": null, "unique_id": "model.creditrisk.accounts_history_beginner", "compiled": true, "compiled_code": "/*\n    This transformations is generating the first version of the core dataset (beginner version). \n    It is essentially : \n    - Joining the accounts dataset with a date spine for the target granuarity\n    - Grouping the payment by day, and joining them to the accounts history\n    - Calculating cumulated sums to describe the cumulated amount paid, and a few other useful fields\n*/\n\nWITH accounts as (\n  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_accounts`\n),\n\npayments as (\n  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_payments`\n),\n\ndate_spine as (\n  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`\n),\n\naccounts_with_spine as (\n  SELECT \n    *,\n    TIMESTAMP_DIFF(reporting_date, registration_date, DAY) + 1 as reporting_day,\n  FROM accounts\n  LEFT JOIN date_spine\n  ON accounts.registration_date <= date_spine.reporting_date\n),\n\npayments_grouped_by_day as (\n  SELECT \n    account_id,\n    \n    DATE_ADD(\n      DATE_TRUNC(payment_effective_date, DAY), \n      INTERVAL 1 DAY\n    ) as reporting_date,\n\n    SUM(amount) as amount,\n    SUM(\n      IF(not down_payment, amount, 0)\n    ) as amount_excl_dp,\n\n  FROM payments\n  GROUP BY ALL\n),\n\njoint as (\n  SELECT \n    * EXCEPT(amount, amount_excl_dp),\n    COALESCE(amount,          0) as amount,\n    COALESCE(amount_excl_dp,  0) as amount_excl_dp,\n  FROM accounts_with_spine \n  LEFT JOIN payments_grouped_by_day \n  USING(account_id, reporting_date)\n),\n\ncalc_paid_total as (\n  SELECT \n    *,\n    SUM(amount)         OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total,\n    SUM(amount_excl_dp) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_excl_dp,\n    \n    unlock_price - down_payment as unlock_price_excl_dp,\n\n    SAFE_DIVIDE(unlock_price - down_payment, daily_rate) + down_payment_days_included as nominal_term,\n    SAFE_DIVIDE(unlock_price - down_payment, daily_rate)                              as nominal_term_excl_dp,\n\n    MAX(reporting_day) OVER(PARTITION BY account_id) as account_age_in_days,\n    GREATEST(\n            0,\n            MAX(reporting_day - down_payment_days_included) OVER(PARTITION BY account_id)\n    ) as account_age_excl_dp_in_days,\n\n    DATE_TRUNC(registration_date, MONTH) as cohort_month,\n    DATE_TRUNC(registration_date, QUARTER) as cohort_quarter,\n    DATE_TRUNC(registration_date, YEAR) as cohort_year,\n\n  FROM joint\n)\n\nSELECT * FROM calc_paid_total", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:00.338626Z", "completed_at": "2024-12-17T08:07:00.345080Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:00.345699Z", "completed_at": "2024-12-17T08:07:22.870467Z"}], "thread_id": "Thread-1", "execution_time": 22.533433198928833, "adapter_response": {"_message": "CREATE TABLE (3.4m rows, 511.5 MiB processed)", "code": "CREATE TABLE", "rows_affected": 3359045, "bytes_processed": 536393806, "bytes_billed": 536870912, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "9d7534b9-cb93-4680-a88e-43bee5408d7f", "slot_ms": 499257}, "message": "CREATE TABLE (3.4m rows, 511.5 MiB processed)", "failures": null, "unique_id": "model.creditrisk.accounts_history_advanced", "compiled": true, "compiled_code": "/*\n    This transformations is generating the second version of the core dataset (advanced version)\n    The main complexity lies in the fact that SQL is not sufficient to calculate the linearized payments. \n    We thus need to use a User Defined Function (here in Javascript) - but we could also use another programming language. \n*/\n\nWITH accounts_history as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`\n),\n\nwo as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`cleaned_write_offs`\n),\n\nadditional_kpis as (\n    SELECT \n        *,\n        \n        CASE \n            WHEN reporting_day <= down_payment_days_included THEN Null\n            WHEN reporting_day = down_payment_days_included + 1 THEN paid_total\n            ELSE amount_excl_dp\n        END as amount_excl_dp_period, -- This step is necessary to 'record' payments at the end of the downpayment period.\n\n        CASE  \n            WHEN reporting_day < down_payment_days_included THEN Null\n            WHEN reporting_day >= down_payment_days_included THEN reporting_day - down_payment_days_included\n        END as reporting_day_excl_dp, -- Necessary to remove the downpayment period from analyses\n\n    FROM accounts_history\n),\n\n-- Preparing the data for the UDF (consuming arrays)\nprepared_for_udf as (\n    SELECT\n        account_id,\n        ARRAY_AGG(COALESCE(amount_excl_dp_period, 0)     ORDER BY reporting_day) as payment_amounts,\n        ARRAY_AGG(daily_rate                             ORDER BY reporting_day) as daily_rates,\n        ARRAY_AGG(CAST(DATE(reporting_date) as STRING)   ORDER BY reporting_day) as casted_reporting_dates,\n    FROM additional_kpis\n    GROUP BY ALL\n),\n\n-- applying the UDF on prepared data format\napply_udf AS (\n    SELECT \n        *,\n        oscreditrisk.payment_linearization(\n        prepared_for_udf.payment_amounts, \n        prepared_for_udf.daily_rates, \n        prepared_for_udf.casted_reporting_dates\n        ) as payment_amount_lin_excl_dp\n    FROM prepared_for_udf\n),\n\n-- Expanding the results before joining them back\nexpand_udf_result AS (\n    SELECT\n        account_id,\n        CAST(reporting_date AS TIMESTAMP) as reporting_date,\n        amount_lin\n    FROM\n        apply_udf,\n        UNNEST(apply_udf.casted_reporting_dates)            AS reporting_date   WITH OFFSET AS pos\n    JOIN UNNEST(apply_udf.payment_amount_lin_excl_dp)     AS amount_lin       WITH OFFSET AS val_pos\n    ON pos = val_pos\n),\n\njoin_back_on_dataset as (\n    SELECT \n        *,\n        SUM(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as paid_total_lin,\n        IF(\n            paid_total < unlock_price AND amount_lin = 0 AND LAG(amount_lin) OVER(PARTITION BY account_id ORDER BY reporting_day) > 0,\n            reporting_date,\n            Null\n        ) as last_disablement,\n    FROM additional_kpis \n    LEFT JOIN expand_udf_result USING(account_id, reporting_date)\n),\n\njoin_wo_statuses as (\n    SELECT \n        join_back_on_dataset.*,\n        wo.write_off_status,\n    FROM join_back_on_dataset\n    LEFT JOIN wo \n    ON \n        wo.account_id = join_back_on_dataset.account_id AND \n        wo.changed_date <= join_back_on_dataset.reporting_date\n),\n\n-- As a last step, use this information to calculate useful fields: status and number of days disabled.\nfinal_kpis as (\n  SELECT \n    * EXCEPT(write_off_status),\n    CASE \n        WHEN write_off_status IS NOT NULL THEN write_off_status\n        WHEN reporting_day <= down_payment_days_included THEN 'ENABLED'\n        WHEN paid_total >= unlock_price THEN 'UNLOCKED'\n        WHEN amount_lin > 0   THEN 'ENABLED'\n        WHEN amount_lin <= 0  THEN 'DISABLED'\n    END as reporting_date_status,\n    CASE \n        WHEN paid_total >= unlock_price THEN Null\n        WHEN amount_lin = 0 \n        THEN DATE_DIFF(\n            reporting_date, \n            LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day),\n            DAY\n        ) \n    END as days_disabled,\n    paid_total_excl_dp / unlock_price_excl_dp as perc_paid,\n  FROM join_wo_statuses\n),\n\nusage_rates as (\n    SELECT \n        *,\n        AVG(\n            IF(reporting_date_status in ('ENABLED', 'UNLOCKED'), 1, 0)\n        ) OVER(\n            PARTITION BY account_id ORDER BY reporting_day ROWS BETWEEN 180 PRECEDING AND CURRENT ROW\n        ) as usage_rate_last_180d,\n    FROM final_kpis\n),\n\nsegmentations as (\n    SELECT \n        *,\n        CASE \n            WHEN usage_rate_last_180d >= 0.95 THEN 'A'\n            WHEN usage_rate_last_180d >= 0.90 THEN 'B'\n            WHEN usage_rate_last_180d >= 0.60 THEN 'C'\n            WHEN usage_rate_last_180d < 0.60  THEN 'D'\n        END as account_segmentation,\n        \n        reporting_date_status in ('ENABLED', 'DISABLED') as portfolio_scope,\n        \n    FROM usage_rates\n)\n\nSELECT * FROM segmentations", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:22.877141Z", "completed_at": "2024-12-17T08:07:22.882270Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:22.882934Z", "completed_at": "2024-12-17T08:07:28.976037Z"}], "thread_id": "Thread-1", "execution_time": 6.102252721786499, "adapter_response": {"_message": "CREATE TABLE (666.0 rows, 127.9 MiB processed)", "code": "CREATE TABLE", "rows_affected": 666, "bytes_processed": 134081680, "bytes_billed": 134217728, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "8df746d8-eae2-4ba9-a0f7-9b93165d9cc0", "slot_ms": 34596}, "message": "CREATE TABLE (666.0 rows, 127.9 MiB processed)", "failures": null, "unique_id": "model.creditrisk.cohorts_beginner", "compiled": true, "compiled_code": "/*\n    This transformations is aggregating on a cohort level for visualisation.\n    It uses the beginner core dataset. \n    Produces information on raw payments only.\n*/\n\nWITH accounts_history as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_beginner`\n),\n\nfiltered as (\n    SELECT \n        * \n    FROM accounts_history\n    -- optional : downsampling results to 1 point every 30 days. Often sufficient.\n    WHERE  MOD(reporting_day, 30) = 1 \n    -- optional : removing the end of cohorts where calculation is not representative of the whole cohort\n    QUALIFY reporting_day <= MIN(account_age_in_days) OVER(PARTITION BY cohort_month) \n)\n\n-- Aggregating results on a cohort level\nSELECT \n    cohort_month,\n    reporting_day,\n    SUM(paid_total) / SUM(unlock_price) as amount_paid_percent,\nFROM filtered\nGROUP BY ALL", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`cohorts_beginner`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:28.985720Z", "completed_at": "2024-12-17T08:07:28.997940Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:28.998977Z", "completed_at": "2024-12-17T08:07:36.010011Z"}], "thread_id": "Thread-1", "execution_time": 7.026328802108765, "adapter_response": {"_message": "CREATE TABLE (693.0 rows, 153.2 MiB processed)", "code": "CREATE TABLE", "rows_affected": 693, "bytes_processed": 160613848, "bytes_billed": 161480704, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "3695bbce-9fd9-4582-a9ff-34b1b4afc188", "slot_ms": 64806}, "message": "CREATE TABLE (693.0 rows, 153.2 MiB processed)", "failures": null, "unique_id": "model.creditrisk.cohorts_advanced", "compiled": true, "compiled_code": "/*\n    This transformations is aggregating on a cohort level for visualisation.\n    It uses the advanced core dataset.\n    Produces information on linearized payments and with a term elapsed in % excluding downpayment.\n*/\n\nWITH accounts_history as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`\n),\n\nperc_elapsed as (\n    SELECT \n        *,\n        SAFE_DIVIDE(reporting_day_excl_dp, nominal_term_excl_dp) as perc_term_elapsed,\n    FROM accounts_history\n),\n\napproximating as (\n    SELECT\n        *,\n        -- Flooring the perc paid to the next 5% (we could choose another grain)\n        FLOOR(perc_term_elapsed * 20) * 5 as perc_term_elapsed_approx,\n    FROM perc_elapsed\n),\n\ndownsampling as (\n    SELECT \n        * \n    FROM approximating\n    -- Optional : limit the time horizon to 200% of contractual term. Often sufficient.\n    WHERE perc_term_elapsed_approx <= 200\n    -- Ensure the dataset ends up with only one row per grain on % of contractual term\n    QUALIFY ROW_NUMBER() OVER(PARTITION BY account_id, CAST(perc_term_elapsed_approx AS STRING) ORDER BY reporting_day_excl_dp) = 1\n),\n\ncounting_accounts as (\n  SELECT \n    *,\n    COUNT(account_id) OVER (PARTITION BY cohort_month, CAST(perc_term_elapsed_approx AS INT64)) as cnt_accounts,\n  FROM downsampling\n),\n\nfiltering as (\n    SELECT \n        *,\n    FROM counting_accounts\n    -- optional - removes the end of cohorts where calculation is not representative of the whole cohort. \n    -- We take 98% and not 100% as otherwise only a few outliers might prevent us from showing the cohort.\n    QUALIFY cnt_accounts >= 0.98 * MAX(cnt_accounts) OVER(PARTITION BY cohort_month) \n),\n\naggregating as (\n    SELECT \n        cohort_month,\n        perc_term_elapsed_approx,\n        SUM(paid_total_lin) / SUM(unlock_price_excl_dp) as amount_paid_percent,\n    FROM filtering\n    GROUP BY ALL \n)\n\nSELECT * FROM aggregating", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`cohorts_advanced`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:36.017903Z", "completed_at": "2024-12-17T08:07:36.033239Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:36.034745Z", "completed_at": "2024-12-17T08:07:38.876640Z"}], "thread_id": "Thread-1", "execution_time": 2.8604202270507812, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "1191e939-9d18-47a9-a7f6-8e1149e0ef55", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.history_defaults", "compiled": true, "compiled_code": "/*\n    This transformations creates a dataset containing one line per account and contains the information if the account has defaulted or not. \n*/\n\nWITH history as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`\n    QUALIFY reporting_date = MAX(reporting_date) OVER()\n),\n\ndetect_defaults as (\n    SELECT \n        account_id,\n        registration_date,\n        perc_paid,\n        CASE \n            WHEN reporting_date_status in ('UNLOCKED') THEN 0\n            WHEN reporting_date_status in ('DETACHED', 'WRITTEN_OFF') THEN 1\n            WHEN days_disabled >= 180 THEN 1\n            ELSE 0\n        END as has_defaulted,\n    FROM history\n)\n\nSELECT * FROM detect_defaults", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`history_defaults`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:38.882289Z", "completed_at": "2024-12-17T08:07:38.887842Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:38.888510Z", "completed_at": "2024-12-17T08:07:41.650133Z"}], "thread_id": "Thread-1", "execution_time": 2.769202947616577, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "af5a7a88-d789-4f53-acd4-97b27e9166b2", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.history_disablements", "compiled": true, "compiled_code": "/*\n    This transformation prepares a dataset in the right format for a survival analysis.\n    The target dataset contains one line per disablement period. \n    Duration represents the duration of the period. Event represents the fact that there was a payment interrupting the period. \n*/\n\nWITH accounts_history as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`\n),\n\nget_disablement_periods as (\n    SELECT \n        account_id,\n        reporting_date,\n        reporting_date_status,\n        perc_paid,\n        LAST_VALUE(last_disablement IGNORE NULLS) OVER(PARTITION BY account_id ORDER BY reporting_day) as last_disablement,\n        days_disabled,\n    FROM accounts_history\n),\n\naggregated_disablement_periods as (\n    SELECT \n        account_id,\n        reporting_date,\n        reporting_date_status,\n        perc_paid,\n        days_disabled as duration,\n    FROM get_disablement_periods\n    QUALIFY days_disabled = MAX(days_disabled) OVER(PARTITION BY account_id, last_disablement)\n)\n\n\nSELECT\n    *,\n    IF(reporting_date = MAX(reporting_date) OVER(), 0, 1) as event,\nFROM aggregated_disablement_periods", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`history_disablements`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:41.656114Z", "completed_at": "2024-12-17T08:07:41.671114Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:41.671872Z", "completed_at": "2024-12-17T08:07:44.374049Z"}], "thread_id": "Thread-1", "execution_time": 2.7193572521209717, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "b6563e40-7f8f-4f22-bc5a-92d5b15cd8d1", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.history_segmentations", "compiled": true, "compiled_code": "/*\n    This transformations generates a table representing the segmentation A, B, C and D\n    for each account depending on the progress on repayment. \n    It will be used to train the model to pick up these segmentations.\n*/\n\nWITH accounts_history as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`\n),\n\nsegmentation_at_0 as (\n  SELECT \n    account_id,\n    0 as perc_paid_current,\n    '0. At registration' as account_segmentation,\n  FROM accounts_history\n  WHERE reporting_day = 1\n),\n\nsegmentation_at_10 as (\n  SELECT \n    account_id,\n    0.1 as perc_paid_current,\n    account_segmentation,\n  FROM accounts_history\n  WHERE perc_paid >= 0.1\n  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1\n),\n\nsegmentation_at_20 as (\n  SELECT \n    account_id,\n    0.2 as perc_paid_current,\n    account_segmentation,\n  FROM accounts_history\n  WHERE perc_paid >= 0.2\n  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1\n),\n\nsegmentation_at_30 as (\n  SELECT \n    account_id,\n    0.3 as perc_paid_current,\n    account_segmentation,\n  FROM accounts_history\n  WHERE perc_paid >= 0.3\n  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1\n),\n\nsegmentation_at_40 as (\n  SELECT \n    account_id,\n    0.4 as perc_paid_current,\n    account_segmentation,\n  FROM accounts_history\n  WHERE perc_paid >= 0.4\n  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1\n),\n\nsegmentation_at_50 as (\n  SELECT \n    account_id,\n    0.5 as perc_paid_current,\n    account_segmentation,\n  FROM accounts_history\n  WHERE perc_paid >= 0.5\n  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1\n),\n\nsegmentation_at_60 as (\n  SELECT \n    account_id,\n    0.6 as perc_paid_current,\n    account_segmentation,\n  FROM accounts_history\n  WHERE perc_paid >= 0.6\n  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1\n),\n\nsegmentation_at_70 as (\n  SELECT \n    account_id,\n    0.7 as perc_paid_current,\n    account_segmentation,\n  FROM accounts_history\n  WHERE perc_paid >= 0.7\n  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1\n),\n\nsegmentation_at_80 as (\n  SELECT \n    account_id,\n    0.8 as perc_paid_current,\n    account_segmentation,\n  FROM accounts_history\n  WHERE perc_paid >= 0.8\n  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1\n),\n\nsegmentation_at_90 as (\n  SELECT \n    account_id,\n    0.9 as perc_paid_current,\n    account_segmentation,\n  FROM accounts_history\n  WHERE perc_paid >= 0.9\n  QUALIFY ROW_NUMBER() OVER (PARTITION BY account_id ORDER BY reporting_day) = 1\n)\n\nSELECT * FROM segmentation_at_0\nUNION ALL\nSELECT * FROM segmentation_at_10\nUNION ALL\nSELECT * FROM segmentation_at_20\nUNION ALL\nSELECT * FROM segmentation_at_30\nUNION ALL\nSELECT * FROM segmentation_at_40\nUNION ALL\nSELECT * FROM segmentation_at_50\nUNION ALL\nSELECT * FROM segmentation_at_60\nUNION ALL\nSELECT * FROM segmentation_at_70\nUNION ALL\nSELECT * FROM segmentation_at_80\nUNION ALL\nSELECT * FROM segmentation_at_90", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`history_segmentations`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:44.378908Z", "completed_at": "2024-12-17T08:07:44.417159Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:44.420535Z", "completed_at": "2024-12-17T08:07:47.002613Z"}], "thread_id": "Thread-1", "execution_time": 2.6249051094055176, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "406bb600-9e5b-42b3-9583-4496fd6f99f8", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.cohort_projection_model", "compiled": true, "compiled_code": "WITH cohorts as (\n    SELECT \n        *, \n        (reporting_day - 1) / 30 as reporting_month, \n        CASE\n            WHEN reporting_day = 1 THEN amount_paid_percent\n            ELSE amount_paid_percent - LAG(amount_paid_percent) OVER(PARTITION BY cohort_month ORDER BY reporting_day)\n        END as amount_paid_percent_incr, \n    FROM\u00a0`steam-outlet-209412`.`oscreditrisk`.`cohorts_beginner`\n),\n\n-- Step 1 : Building a reference dataset : containing for each month, the reference point for the last 6 available cohorts\nlast_6_reference as (\n    SELECT \n        *,\n    FROM cohorts\n    QUALIFY ROW_NUMBER() OVER(PARTITION BY CAST(reporting_month AS INT64) ORDER BY cohort_month DESC) <= 6\n),\n\nlast_6_aggregated as (\n    SELECT \n        reporting_month,\n        AVG(amount_paid_percent_incr)                           as projected_paid_percent_incr,\n        AVG(amount_paid_percent - amount_paid_percent_incr)     as reference_paid_percent, -- this field will serve to apply the scale factor\n    FROM last_6_reference\n    GROUP BY ALL\n),\n\n-- Step 2 : Let's build the full dataset of cohorts including future months\ncohort_months as (\n    SELECT DISTINCT cohort_month FROM cohorts\n),\n\nreporting_months as (\n    SELECT DISTINCT reporting_month FROM cohorts\n),\n\nfull_cohort_spine as (\n    SELECT * FROM cohort_months\n    CROSS JOIN reporting_months\n),\n\n-- Step 3 : Joining the data back in this target dataset\njoint as (\n    SELECT \n        full_cohort_spine.*,\n        cohorts.amount_paid_percent,\n        cohorts.amount_paid_percent_incr,\n    FROM full_cohort_spine \n    LEFT JOIN cohorts USING(cohort_month, reporting_month)\n),\n\njoint_with_projections as (\n    SELECT \n        joint.*,\n        last_6_aggregated.projected_paid_percent_incr,\n        last_6_aggregated.reference_paid_percent,\n        MAX(joint.amount_paid_percent) OVER(PARTITION BY cohort_month) / MIN(last_6_aggregated.reference_paid_percent) OVER(PARTITION BY cohort_month) as scale_factor,\n    FROM joint \n    LEFT JOIN last_6_aggregated\n    ON \n        joint.amount_paid_percent IS NULL AND \n        joint.reporting_month = last_6_aggregated.reporting_month\n),\n\n-- Step 4 : combine actuals and predictions, and calculate cumulative values\nprojected_and_actuals as (\n    SELECT \n    *,\n    COALESCE(amount_paid_percent_incr, projected_paid_percent_incr)                 as projected_and_actual_amount_paid_percent_incr,\n    COALESCE(amount_paid_percent_incr, projected_paid_percent_incr * scale_factor)  as projected_and_actual_amount_paid_percent_incr_with_scale_factor,\n    FROM joint_with_projections \n    GROUP BY ALL\n)\n\nSELECT \n    *,\n    SUM(projected_and_actual_amount_paid_percent_incr) OVER(\n        PARTITION BY cohort_month ORDER BY reporting_month ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n    ) as projected_and_actual_amount_paid_percent,\n    SUM(projected_and_actual_amount_paid_percent_incr_with_scale_factor) OVER(\n        PARTITION BY cohort_month ORDER BY reporting_month ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n    ) as projected_and_actual_amount_paid_percent_with_scale_factor,\nFROM projected_and_actuals\nORDER BY 1, 2", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`cohort_projection_model`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:47.009197Z", "completed_at": "2024-12-17T08:07:47.016798Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:47.018003Z", "completed_at": "2024-12-17T08:07:49.814891Z"}], "thread_id": "Thread-1", "execution_time": 2.807628870010376, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "8924e326-3dd2-4dd0-83ba-ba17336622d3", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.prepare_date_samples", "compiled": true, "compiled_code": "/*\n    This transformation is quite essential to produce an unbiaised model\n    For every chunk of repayment [0-10%], [10-20%], etc... it estimates what is the sample of accounts we can use for estimating probabilities of default.\n    For example, if for 40 - 50% the sample end date is 2020-12-03, it means that we must use only accounts registered prior to this date.\n    Otherwise, we are going to produce biaised (selection bias) estimates, as too many accounts will not have finished paying or will not have defaulted.\n*/\n\nWITH default_history as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`\n),\n\ndate_spine as (\n    SELECT reporting_date as sample_end_date FROM `steam-outlet-209412`.`oscreditrisk`.`date_spine`\n),\n\n-- Generates a table containing 10 rows, representing the different chunks of repayment : 0 to 10%, 10 to 20%, etc...\nsplit_chunks as (\n    SELECT \n        *,\n        index_chunk / 10 as perc_paid_chunk_start,\n        COALESCE(\n            LEAD(index_chunk / 10) OVER(ORDER BY index_chunk),\n            1\n        ) as perc_paid_chunk_end,\n    FROM UNNEST(GENERATE_ARRAY(0, 9)) as index_chunk\n),\n\ncrossjoint as (\n    SELECT \n        *,\n        IF(perc_paid < perc_paid_chunk_end AND has_defaulted = 0, 1, 0) as is_censored,\n    FROM default_history\n    CROSS JOIN split_chunks\n),\n\ngrouped as (\n    SELECT \n        index_chunk,\n        perc_paid_chunk_start,\n        perc_paid_chunk_end,\n        sample_end_date,\n        AVG(is_censored) as censored_percent,\n    FROM crossjoint\n    LEFT JOIN date_spine\n    ON date_spine.sample_end_date >= crossjoint.registration_date\n    GROUP BY ALL\n    HAVING censored_percent <= 0.05 -- Here the tolerance to censoring is 5%.\n),\n\nget_chunck_dates as (\n    SELECT \n        index_chunk,\n        perc_paid_chunk_start,\n        perc_paid_chunk_end,\n        MAX(sample_end_date) as sample_end_date,\n    FROM grouped \n    GROUP BY ALL\n)\n\nSELECT * FROM get_chunck_dates", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`prepare_date_samples`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:49.820908Z", "completed_at": "2024-12-17T08:07:49.834005Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:49.834638Z", "completed_at": "2024-12-17T08:07:52.635485Z"}], "thread_id": "Thread-1", "execution_time": 2.8160159587860107, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "244a01de-3731-46ad-9511-8a9c50eb3242", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.probability_calculation_survival", "compiled": true, "compiled_code": "/*\n    This is a SQL implementation of the Kaplan Meier Survival Analysis.\n    The output is a survival function. \n*/\n\nWITH reactivation_history as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`history_disablements`\n),\n\n-- Split by perc paid bucket and take only last 3 years events observed\nreactivation_history_filtered as (\n    SELECT \n        *, \n        CASE \n            WHEN perc_paid <= 0.1 THEN '0'\n            WHEN perc_paid <= 0.5 THEN '0.1'\n            WHEN perc_paid <= 1 THEN '0.5'\n            ELSE '0.5'\n        END as perc_paid_bucket_start,\n            CASE \n            WHEN perc_paid <= 0.1 THEN '0.1'\n            WHEN perc_paid <= 0.5 THEN '0.5'\n            WHEN perc_paid <= 1 THEN '1'\n            ELSE '1'\n        END as perc_paid_bucket_end\n    FROM reactivation_history\n),\n\ncnt_subjects as (\n  SELECT \n    perc_paid_bucket_start, \n    perc_paid_bucket_end, \n    COUNT(*) as num_subjects \n  FROM reactivation_history_filtered\n  GROUP BY ALL \n),\n\ndaily as (\n  SELECT\n    perc_paid_bucket_start, \n    perc_paid_bucket_end,\n    duration,\n    COUNT(*) as num_obs,\n    SUM(event) as num_events\n  FROM reactivation_history_filtered\n  GROUP BY ALL ORDER BY 1, 2, 3\n),\n\nat_risk_table as (\n  SELECT\n    perc_paid_bucket_start, \n    perc_paid_bucket_end,\n    duration, \n    num_obs,\n    num_events,\n    num_subjects - COALESCE(SUM(num_obs) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end\n      ORDER BY duration ASC ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING), 0)\n     as at_risk\n  FROM daily\n  LEFT JOIN cnt_subjects USING(perc_paid_bucket_start, perc_paid_bucket_end)\n),\n\nsurvival_proba_table as (\n  SELECT\n    perc_paid_bucket_start, \n    perc_paid_bucket_end, \n    duration, \n    at_risk,\n    num_obs,\n    num_events,\n    at_risk - num_events - COALESCE(LEAD(at_risk, 1) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC), 0) as censored,\n    EXP(SUM(SAFE.LN(1 - num_events / at_risk)) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC ROWS BETWEEN UNBOUNDED PRECEDING AND current ROW)) as survival_proba\n  FROM at_risk_table\n),\n\nget_density_proba as (\n  SELECT  \n    survival_proba_table.*,\n    1 - survival_proba as prob_cum,\n    (1 - survival_proba) - COALESCE(1 - LAG(survival_proba) OVER (PARTITION BY perc_paid_bucket_start, perc_paid_bucket_end ORDER BY duration ASC), 0) as prob_dens,\n    ROW_NUMBER() OVER (PARTITION BY perc_paid_bucket_end ORDER BY duration ASC) as row_num\n  FROM survival_proba_table\n)\n\nSELECT \n    * EXCEPT(duration, perc_paid_bucket_start, perc_paid_bucket_end),\n    CAST(perc_paid_bucket_start AS FLOAT64) as perc_paid_bucket_start,\n    CAST(perc_paid_bucket_end AS FLOAT64) as perc_paid_bucket_end,\n    duration as days_since_cutoff \nFROM get_density_proba\nORDER BY perc_paid_bucket_start, duration", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:52.641543Z", "completed_at": "2024-12-17T08:07:52.649537Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:52.650369Z", "completed_at": "2024-12-17T08:07:55.445780Z"}], "thread_id": "Thread-1", "execution_time": 2.805734157562256, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "eb7aa98b-c705-43d0-8c54-76d3cae198d3", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.prepare_model_inputs", "compiled": true, "compiled_code": "/*\n    Simple preparation step joining the various inputs.\n*/\n\nWITH accs as (\n  SELECT \n    *,\n  FROM `steam-outlet-209412`.`oscreditrisk`.`history_defaults`\n  LEFT JOIN `steam-outlet-209412`.`oscreditrisk`.`history_segmentations` USING(account_id)\n),\n\nsamples as (\n  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_date_samples`\n),\n\njoint as (\n  SELECT \n    accs.*,\n    samples.*,\n    RAND() as rnd,\n  FROM accs\n  INNER JOIN samples\n  ON \n    accs.registration_date < CAST(samples.sample_end_date AS TIMESTAMP)\n)\n\nSELECT * FROM joint", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:55.451673Z", "completed_at": "2024-12-17T08:07:55.461086Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:55.462034Z", "completed_at": "2024-12-17T08:07:58.321279Z"}], "thread_id": "Thread-1", "execution_time": 2.871048927307129, "adapter_response": {"_message": "CREATE VIEW (0 processed)", "code": "CREATE VIEW", "bytes_processed": 0, "bytes_billed": 0, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "90de1841-c52d-4d0c-a0bf-7f4edf77ce6d", "slot_ms": 0}, "message": "CREATE VIEW (0 processed)", "failures": null, "unique_id": "model.creditrisk.probability_of_defaulting", "compiled": true, "compiled_code": "/*\n    This transformation uses the output of the survival function to determine the immediate probability of defaulting of a late account\n*/\n\nWITH proba_reactivation as (\n  SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`probability_calculation_survival`\n),\n\nrepayment as (\n  SELECT \n    *,\n    1 - prob_cum as survival_func, -- opposite of probability of reactivation\n    IF(days_since_cutoff = 270, 1 - prob_cum, null) as survival_func_at_PAR270 -- opposite of probability of reactivation at PAR270\n  FROM proba_reactivation\n),\n\nget_survival_limit as (\n  SELECT \n    perc_paid_bucket_start,\n    perc_paid_bucket_end,\n    MAX(survival_func_at_PAR270)  as survival_limit_at_PAR270,\n    MIN(survival_func)            as survival_limit\n  FROM repayment\n  GROUP BY ALL\n),\n\nimmediate_churn_and_repo_act as (\n  SELECT \n    perc_paid_bucket_start,\n    perc_paid_bucket_end,\n    days_since_cutoff,\n    survival_limit_at_PAR270,\n    survival_limit,\n    survival_func,\n    -- probability of non-reactivation before PAR270 knowing there is non-reactivation event at time t\n    SAFE_DIVIDE(IF(survival_limit_at_PAR270 is null, survival_limit, survival_limit_at_PAR270), survival_func) as immediate_prob_churn,\n  FROM repayment\n  LEFT JOIN get_survival_limit\n    USING(perc_paid_bucket_start, perc_paid_bucket_end) \n),\n\nimmediate_churn as (\n  SELECT \n    * EXCEPT(immediate_prob_churn),\n    IF(days_since_cutoff > 270, 1, immediate_prob_churn) as immediate_prob_churn\n  FROM immediate_churn_and_repo_act\n)\n\nSELECT * FROM immediate_churn", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`probability_of_defaulting`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:07:58.331253Z", "completed_at": "2024-12-17T08:07:58.343951Z"}, {"name": "execute", "started_at": "2024-12-17T08:07:58.344956Z", "completed_at": "2024-12-17T08:08:09.289225Z"}], "thread_id": "Thread-1", "execution_time": 10.960042238235474, "adapter_response": {"_message": "CREATE TABLE (369.0 rows, 174.7 MiB processed)", "code": "CREATE TABLE", "rows_affected": 369, "bytes_processed": 183238076, "bytes_billed": 183500800, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "b8b6bdd5-d72a-4e36-93c5-2ddc464f8080", "slot_ms": 784234}, "message": "CREATE TABLE (369.0 rows, 174.7 MiB processed)", "failures": null, "unique_id": "model.creditrisk.prepare_model_outputs", "compiled": true, "compiled_code": "/*\n    This is where the main calculation happens.\n    Calculation of the PDs & PDs * EADs.\n*/\n\n\n\nWITH input as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_inputs`\n),\n\ncalculated as (\n  SELECT \n    perc_paid_current,\n    account_segmentation,\n    sample_end_date, \n    perc_paid_chunk_start,\n    perc_paid_chunk_end,\n    COUNT(*) as number_of_accounts,\n    AVG(\n      CASE \n        WHEN \n            has_defaulted = 1 AND \n            perc_paid >= perc_paid_chunk_start AND \n            perc_paid < perc_paid_chunk_end \n        THEN 1\n        WHEN \n            has_defaulted = 0 \n            AND perc_paid < perc_paid_chunk_start AND \n            -- This formula takes an assumption for future default rates of censored accounts.\n            -- Here we consider the account will have 40% chances of defaulting in the remaining repayment\n            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10) \n        THEN 1\n        ELSE 0\n      END\n    ) as p_churn_incr, -- p_churn represents the probability of default\n    AVG(\n      CASE \n        WHEN \n            has_defaulted = 1 AND \n            perc_paid >= perc_paid_chunk_start AND \n            perc_paid < perc_paid_chunk_end \n        THEN 1 - perc_paid\n        WHEN \n            has_defaulted = 0 AND \n            perc_paid < perc_paid_chunk_end AND \n            -- This formula takes an assumption for future default rates of censored accounts.\n            -- Here we consider the account will have 40% chances of defaulting in the remaining repayment\n            rnd < 0.4 / ((1 - perc_paid_chunk_start) * 10)\n        THEN 1 - perc_paid_chunk_start\n        ELSE 0\n      END\n    ) as r_churn_incr, -- r_churn represents the expected loss in receivable PD * EAD.\n  FROM input\n  GROUP BY ALL\n)\n\nSELECT \n    *,\n\n    SUM(p_churn_incr) OVER(\n        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation \n        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n    ) as p_churn,\n\n    SUM(r_churn_incr) OVER(\n        PARTITION BY CAST(perc_paid_current AS STRING), account_segmentation \n        ORDER BY perc_paid_chunk_start ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n    ) as r_churn, \n\nFROM calculated", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-12-17T08:08:09.295292Z", "completed_at": "2024-12-17T08:08:09.303323Z"}, {"name": "execute", "started_at": "2024-12-17T08:08:09.304085Z", "completed_at": "2024-12-17T08:08:54.974053Z"}], "thread_id": "Thread-1", "execution_time": 45.680230140686035, "adapter_response": {"_message": "CREATE TABLE (2.4m rows, 122.1 MiB processed)", "code": "CREATE TABLE", "rows_affected": 2352412, "bytes_processed": 128074073, "bytes_billed": 128974848, "location": "EU", "project_id": "steam-outlet-209412", "job_id": "44b78f5d-8f66-4c56-b92a-0818e28fe53a", "slot_ms": 5907193}, "message": "CREATE TABLE (2.4m rows, 122.1 MiB processed)", "failures": null, "unique_id": "model.creditrisk.predict_ecls", "compiled": true, "compiled_code": "\n\nWITH accounts_history as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`accounts_history_advanced`\n),\n\nrepo as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`repossession_valuation_parameters`\n),\n\nproba_churn_repayment as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`prepare_model_outputs`\n),\n\nproba_churn_immediate as (\n    SELECT * FROM `steam-outlet-209412`.`oscreditrisk`.`probability_of_defaulting`\n),\n\nbatch_to_compute as (\n    SELECT\n        account_id, \n        reporting_date,\n        reporting_day,\n        portfolio_scope,\n        days_disabled,\n        perc_paid,\n        IF(perc_paid < 0.1, '0. At registration', account_segmentation) as account_segmentation, \n    FROM accounts_history\n    WHERE portfolio_scope\n),\n\njoin_with_churn_model as (\n    SELECT     \n        account_id,\n        reporting_date,\n        SUM(proba_churn_repayment.p_churn_incr)        as p_churn,\n        SUM(proba_churn_repayment.r_churn_incr)        as r_churn,\n    FROM batch_to_compute\n    LEFT JOIN proba_churn_repayment\n    ON \n        batch_to_compute.account_segmentation = proba_churn_repayment.account_segmentation AND\n        batch_to_compute.perc_paid < proba_churn_repayment.perc_paid_chunk_end\n    GROUP BY ALL\n),\n\njoin_with_immediate_churn_model as (\n    SELECT \n        account_id, \n        reporting_date,\n        COALESCE(proba_churn_immediate.immediate_prob_churn, 0) as immediate_prob_churn,\n        COALESCE(proba_churn_immediate.immediate_prob_churn, 0) * (1 - perc_paid) as immediate_loss,\n    FROM batch_to_compute\n    LEFT JOIN proba_churn_immediate\n    ON  \n        batch_to_compute.perc_paid >= proba_churn_immediate.perc_paid_bucket_start AND \n        batch_to_compute.perc_paid < proba_churn_immediate.perc_paid_bucket_end AND \n        batch_to_compute.days_disabled = proba_churn_immediate.days_since_cutoff\n),\n\njoint_together as (\n    SELECT * FROM batch_to_compute\n    LEFT JOIN join_with_churn_model USING(account_id, reporting_date)\n    LEFT JOIN join_with_immediate_churn_model USING(account_id, reporting_date)\n    CROSS JOIN repo\n),\n\ncombine_outputs_1 as (\n    SELECT \n        account_id,\n        reporting_date,\n        reporting_day, \n        days_disabled,\n        perc_paid,\n        account_segmentation,\n\n        p_churn as repayment_prob_churn,\n        r_churn as repayment_loss,\n        p_churn * probability_of_repossession * repossession_value as repayment_recoveries,\n        \n        immediate_prob_churn,\n        immediate_loss,\n        immediate_prob_churn * probability_of_repossession * repossession_value as immediate_recoveries,\n\n    FROM joint_together\n),\n\ncombine_outputs_2 as (\n    SELECT \n        *,\n        IF(immediate_loss - immediate_recoveries < 0, 0, immediate_loss - immediate_recoveries) as immediate_ecl,\n        IF(repayment_loss - repayment_recoveries < 0, 0, repayment_loss - repayment_recoveries) as repayment_ecl,\n    FROM combine_outputs_1\n),\n\ncombine_outputs_3 as (\n    SELECT \n        *,\n        immediate_loss + (1 - immediate_prob_churn) * repayment_loss as total_loss,\n        immediate_prob_churn + (1 - immediate_prob_churn) * repayment_prob_churn as total_pchurn,\n        immediate_ecl + (1 - immediate_prob_churn) * repayment_ecl as total_ecl,\n    FROM combine_outputs_2\n)\n\nSELECT * FROM combine_outputs_3", "relation_name": "`steam-outlet-209412`.`oscreditrisk`.`predict_ecls`"}], "elapsed_time": 153.38106107711792, "args": {"static_parser": true, "version_check": true, "log_file_max_bytes": 10485760, "use_colors": true, "partial_parse": true, "enable_legacy_logger": false, "project_dir": "/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk", "favor_state": false, "invocation_command": "dbt run", "require_explicit_package_overrides_for_builtin_materializations": true, "send_anonymous_usage_stats": true, "select": [], "exclude": [], "log_level": "info", "introspect": true, "warn_error_options": {"include": [], "exclude": []}, "strict_mode": false, "printer_width": 80, "use_colors_file": true, "which": "run", "require_resource_names_without_spaces": false, "quiet": false, "empty": false, "show_resource_report": false, "defer": false, "log_format": "default", "partial_parse_file_diff": true, "indirect_selection": "eager", "write_json": true, "profiles_dir": "/Users/david/.dbt", "log_path": "/Users/david/bbplus-os-credit-risk/bbplus-os-credit-risk/logs", "populate_cache": true, "vars": {}, "macro_debugging": false, "cache_selected_only": false, "log_format_file": "debug", "print": true, "source_freshness_run_project_hooks": false, "log_level_file": "debug"}}